{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-08T16:06:29.796058Z",
     "start_time": "2018-01-08T16:06:29.778565Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/IPython/core/magics/pylab.py:160: UserWarning: pylab import has clobbered these variables: ['random', 'arrow']\n",
      "`%matplotlib` prevents importing * from pylab and numpy\n",
      "  \"\\n`%matplotlib` prevents importing * from pylab and numpy\"\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "import keras\n",
    "import keras.backend as K\n",
    "import kapre\n",
    "import pandas as pd\n",
    "import scipy.io.wavfile as wav\n",
    "import numpy as np\n",
    "import random\n",
    "import arrow\n",
    "import threading\n",
    "import hyperopt\n",
    "import pprint\n",
    "import librosa\n",
    "import samplerate\n",
    "from hyperopt import hp\n",
    "from soph import soph_scaler, center_wave, ex_generator\n",
    "\n",
    "# https://github.com/keunwoochoi/kapre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-08T16:10:53.257182Z",
     "start_time": "2018-01-08T16:10:53.252510Z"
    }
   },
   "outputs": [],
   "source": [
    "from lsuv_init import LSUVinit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-01-06T03:07:11.904Z"
    }
   },
   "outputs": [],
   "source": [
    "delta_kernel = np.arange(-self.n,self.n+1)\n",
    "delta_kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-05T23:31:43.561558Z",
     "start_time": "2018-01-05T23:31:43.555409Z"
    }
   },
   "outputs": [],
   "source": [
    "num_classes = 12\n",
    "num_ex = 32\n",
    "\n",
    "y_pred = np.random.randint(0,num_classes,num_ex)\n",
    "y_zo = -np.ones((num_ex,num_classes))\n",
    "y_zo[np.arange(32),y_pred] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-05T23:31:49.327047Z",
     "start_time": "2018-01-05T23:31:49.311518Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,  1.],\n",
       "       [-1., -1., -1., -1.,  1., -1., -1., -1., -1., -1., -1., -1.],\n",
       "       [-1., -1., -1., -1., -1.,  1., -1., -1., -1., -1., -1., -1.],\n",
       "       [-1., -1., -1., -1., -1., -1., -1., -1., -1.,  1., -1., -1.],\n",
       "       [-1.,  1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.],\n",
       "       [-1., -1.,  1., -1., -1., -1., -1., -1., -1., -1., -1., -1.],\n",
       "       [-1., -1., -1., -1., -1.,  1., -1., -1., -1., -1., -1., -1.],\n",
       "       [-1., -1., -1., -1., -1.,  1., -1., -1., -1., -1., -1., -1.],\n",
       "       [-1., -1., -1., -1., -1.,  1., -1., -1., -1., -1., -1., -1.],\n",
       "       [-1.,  1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.],\n",
       "       [-1., -1., -1., -1., -1., -1., -1.,  1., -1., -1., -1., -1.],\n",
       "       [-1., -1., -1., -1., -1., -1., -1., -1., -1.,  1., -1., -1.],\n",
       "       [-1., -1., -1., -1.,  1., -1., -1., -1., -1., -1., -1., -1.],\n",
       "       [-1., -1., -1., -1., -1., -1., -1., -1., -1.,  1., -1., -1.],\n",
       "       [-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,  1.],\n",
       "       [-1., -1., -1., -1., -1., -1., -1.,  1., -1., -1., -1., -1.],\n",
       "       [-1., -1., -1.,  1., -1., -1., -1., -1., -1., -1., -1., -1.],\n",
       "       [-1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,  1., -1.],\n",
       "       [-1.,  1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.],\n",
       "       [-1.,  1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.],\n",
       "       [-1., -1., -1., -1., -1., -1., -1., -1., -1.,  1., -1., -1.],\n",
       "       [-1., -1.,  1., -1., -1., -1., -1., -1., -1., -1., -1., -1.],\n",
       "       [-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,  1.],\n",
       "       [ 1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.],\n",
       "       [-1., -1., -1., -1., -1., -1.,  1., -1., -1., -1., -1., -1.],\n",
       "       [-1., -1.,  1., -1., -1., -1., -1., -1., -1., -1., -1., -1.],\n",
       "       [-1., -1., -1., -1., -1., -1., -1., -1.,  1., -1., -1., -1.],\n",
       "       [ 1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.],\n",
       "       [-1., -1., -1., -1., -1., -1.,  1., -1., -1., -1., -1., -1.],\n",
       "       [-1., -1., -1., -1., -1.,  1., -1., -1., -1., -1., -1., -1.],\n",
       "       [-1., -1., -1., -1., -1., -1., -1.,  1., -1., -1., -1., -1.],\n",
       "       [-1., -1.,  1., -1., -1., -1., -1., -1., -1., -1., -1., -1.]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_zo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test resamplers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-05T22:21:32.634708Z",
     "start_time": "2018-01-05T22:21:32.467465Z"
    }
   },
   "outputs": [],
   "source": [
    "src_cute, orig_sr = librosa.load(\"kapre/srcs/bensound-cute.mp3\", sr=None, mono=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-05T22:21:36.373722Z",
     "start_time": "2018-01-05T22:21:33.240623Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391 ms ± 1.23 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "_ =librosa.core.resample(src_cute,orig_sr=orig_sr, target_sr=8000,res_type='kaiser_best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-05T22:21:43.365157Z",
     "start_time": "2018-01-05T22:21:36.388579Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86 ms ± 151 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "_ =librosa.core.resample(src_cute,orig_sr=orig_sr, target_sr=8000,res_type='kaiser_fast')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-05T22:21:52.483452Z",
     "start_time": "2018-01-05T22:21:43.380760Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.14 s ± 1.88 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "_ =librosa.core.resample(src_cute,orig_sr=orig_sr, target_sr=8000,res_type='scipy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-05T22:21:58.428343Z",
     "start_time": "2018-01-05T22:21:52.498184Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "740 ms ± 1.34 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "_ = samplerate.resample(src_cute, 8000/orig_sr, \"sinc_best\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-05T22:22:09.655742Z",
     "start_time": "2018-01-05T22:21:58.442757Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "138 ms ± 151 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "_ = samplerate.resample(src_cute, 8000/orig_sr, \"sinc_medium\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-05T22:22:14.098563Z",
     "start_time": "2018-01-05T22:22:09.670141Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54.6 ms ± 102 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "_ = samplerate.resample(src_cute, 8000/orig_sr, \"sinc_fastest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-05T22:22:21.378270Z",
     "start_time": "2018-01-05T22:22:14.112889Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "895 µs ± 1.23 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "_ = samplerate.resample(src_cute, 8000/orig_sr, \"zero_order_hold\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-05T22:22:30.660467Z",
     "start_time": "2018-01-05T22:22:21.392896Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.14 ms ± 1.08 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "_ = samplerate.resample(src_cute, 8000/orig_sr, \"linear\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-04T19:36:03.434781Z",
     "start_time": "2018-01-04T19:36:03.316493Z"
    }
   },
   "outputs": [],
   "source": [
    "ex_df = pd.read_pickle(\"data/ex_df.pkl\")\n",
    "current_time = arrow.now().to('US/Eastern').format('YYYY-MM-DD-HH-mm')\n",
    "\n",
    "src_space = {\n",
    "    \"dropout_prob\": hp.uniform(\"dropout_prob\",0,1), #[0,1]\n",
    "    \"activation\": hp.choice(\"activation\", (\"elu\", \"relu\")), #{ elu, relu}\n",
    "    \"batch_size\": 64, #2^int[1,7]\n",
    "    \"regularize\": hp.choice(\"regularize\", (True, False)), #{T,F}\n",
    "    \"l2_reg\": hp.loguniform(\"l2_reg\",-10,-1), #log([e-8,e-1])\n",
    "    \"init_stdd\": hp.loguniform(\"init_stdd\",-10,-1), #log([e-8,e-1])\n",
    "    \"filters_start\": hp.quniform(\"filters_start\",40,200,10), #[40,200]\n",
    "    \"filters_step\": hp.quniform(\"filters_step\",0,200,10), #[0,60]\n",
    "    \"kernel_size\": hp.quniform(\"kernel_size\",2,10,1), #[1,10]\n",
    "    \"cnn_pad\": hp.choice(\"cnn_pad\", (\"same\", \"valid\")), #{same,valid}\n",
    "    \"cnn_stride\": hp.quniform(\"cnn_stride\",1,5,1), #{1,2}\n",
    "    \"n_mfcc\": hp.quniform(\"n_mfcc\",16,100,2), #int[16,100]\n",
    "    \"n_mels\": hp.quniform(\"n_mels\",16,200,4), #int[16,200]\n",
    "    \"n_dft\": 512, #2^int[8,12]\n",
    "    \"n_hop\": 256, #2^int[7,12]\n",
    "    \"pool\": hp.choice(\"pool\", (\"max\", \"avg\")), #{max,avg}\n",
    "    \"pool_pad\": hp.choice(\"pool_pad\", (\"same\", \"valid\")), #{same,valid}\n",
    "    \"batch_normalize\": hp.choice(\"batch_normalize\", (True, False)), #{T,F}\n",
    "    \"train_state\": [\"train\"],\n",
    "    \"val_state\": [\"val\", \"test\"],\n",
    "    \"p_transform\": hp.uniform(\"p_transform\",0,1), #[0,1]\n",
    "    \"vol_range\": hp.uniform(\"vol_range\",0,1), #[0,1]\n",
    "    \"displacement\": hp.uniform(\"displacement\",0,1), #[0,1]\n",
    "}\n",
    "num_cat = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-04T19:36:03.459405Z",
     "start_time": "2018-01-04T19:36:03.437296Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation': 'elu',\n",
      " 'batch_normalize': True,\n",
      " 'batch_size': 64,\n",
      " 'cnn_pad': 'same',\n",
      " 'cnn_stride': 3.0,\n",
      " 'displacement': 0.31403276194871466,\n",
      " 'dropout_prob': 0.8486683100963217,\n",
      " 'filters_start': 70.0,\n",
      " 'filters_step': 140.0,\n",
      " 'init_stdd': 0.0005752235462514456,\n",
      " 'kernel_size': 6.0,\n",
      " 'l2_reg': 0.00011094305866935931,\n",
      " 'n_dft': 512,\n",
      " 'n_hop': 256,\n",
      " 'n_mels': 176.0,\n",
      " 'n_mfcc': 52.0,\n",
      " 'p_transform': 0.3941505447463889,\n",
      " 'pool': 'max',\n",
      " 'pool_pad': 'valid',\n",
      " 'regularize': False,\n",
      " 'train_state': ('train',),\n",
      " 'val_state': ('val', 'test'),\n",
      " 'vol_range': 0.8130972187337495}\n"
     ]
    }
   ],
   "source": [
    "src_args = hyperopt.pyll.stochastic.sample(src_space)\n",
    "pprint.pprint(src_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-04T19:59:38.572481Z",
     "start_time": "2018-01-04T19:59:37.870040Z"
    }
   },
   "outputs": [],
   "source": [
    "input_layer = keras.layers.Input(shape=(1, 16000))\n",
    "input_block = kapre.time_frequency.MFCC(n_mfcc=int(src_args[\"n_mfcc\"]),\n",
    "                              n_mels=int(src_args[\"n_mels\"]),\n",
    "                              n_dft=int(src_args[\"n_dft\"]),\n",
    "                              power_melgram=2.0,\n",
    "                              return_decibel_melgram=True,)(input_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-04T19:59:39.428829Z",
     "start_time": "2018-01-04T19:59:39.423758Z"
    }
   },
   "outputs": [],
   "source": [
    "def pool(x):\n",
    "    if src_args[\"pool\"] == \"max\":\n",
    "        return keras.layers.MaxPool2D(padding=src_args[\"pool_pad\"])(x)\n",
    "    elif src_args[\"pool\"] == \"avg\":\n",
    "        return keras.layers.AvgPool2D(padding=src_args[\"pool_pad\"])(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-04T19:59:40.262599Z",
     "start_time": "2018-01-04T19:59:40.251843Z"
    }
   },
   "outputs": [],
   "source": [
    "drop = src_args[\"dropout_prob\"]\n",
    "init = keras.initializers.TruncatedNormal(stddev=src_args[\"init_stdd\"])\n",
    "if src_args[\"regularize\"]:\n",
    "    reg = keras.regularizers.l2(src_args[\"l2_reg\"])\n",
    "else:\n",
    "    reg = None\n",
    "    \n",
    "def cnn(x, i=0):\n",
    "    return keras.layers.Conv2D(\n",
    "        filters=int(src_args[\"filters_start\"] + i*src_args[\"filters_step\"]),\n",
    "        kernel_size=int(src_args[\"kernel_size\"]),\n",
    "        padding=src_args[\"cnn_pad\"],\n",
    "        strides=int(src_args[\"cnn_stride\"]),\n",
    "        activation=src_args[\"activation\"],\n",
    "        kernel_initializer=init,\n",
    "        kernel_regularizer=reg,\n",
    "        bias_regularizer=reg)(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-04T19:59:41.136568Z",
     "start_time": "2018-01-04T19:59:41.103123Z"
    }
   },
   "outputs": [],
   "source": [
    "def calc_cnn_dim(nin):\n",
    "    k = src_args[\"kernel_size\"]\n",
    "    if src_args[\"cnn_pad\"] == \"valid\":\n",
    "        p = 0\n",
    "    else:\n",
    "        p = k\n",
    "    s = src_args[\"cnn_stride\"]\n",
    "\n",
    "    return int(((nin + 2 * p - k) / s) + 1)\n",
    "\n",
    "\n",
    "def calc_cnn_size(layer, layer_type):\n",
    "    if layer_type == \"cnn\":\n",
    "        k = src_args[\"kernel_size\"]\n",
    "        if src_args[\"cnn_pad\"] == \"valid\":\n",
    "            p = 0\n",
    "        else:\n",
    "            p = k\n",
    "        s = src_args[\"cnn_stride\"]\n",
    "    elif layer_type == \"pool\":\n",
    "        k = 2\n",
    "        if src_args[\"pool_pad\"] == \"valid\":\n",
    "            p = 0\n",
    "        else:\n",
    "            p = k\n",
    "        s = 2\n",
    "    calc_dim = lambda x: int(((x + 2 * p - k) / s) + 1)\n",
    "    layer_in = np.array(layer.shape.as_list())\n",
    "    layer_out = (layer_in[0], \n",
    "                 calc_dim(layer_in[1]),\n",
    "                 calc_dim(layer_in[2]),\n",
    "                 layer_in[3])\n",
    "                 \n",
    "    return np.array(layer_out)[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-04T19:59:42.016716Z",
     "start_time": "2018-01-04T19:59:41.952339Z"
    }
   },
   "outputs": [],
   "source": [
    "cnn_block = input_block\n",
    "continue_flag = True\n",
    "cnn_i = 0\n",
    "while continue_flag:\n",
    "    \n",
    "    cnn_size_flag = np.all(calc_cnn_size(cnn_block, \"cnn\") > 0)\n",
    "    \n",
    "    cnn_size_flag = cnn_size_flag & (sum(cnn_block.shape.as_list()[1:3]) > 2)\n",
    "    if cnn_size_flag:\n",
    "        cnn_block = cnn(cnn_block, cnn_i)\n",
    "        cnn_i += 1\n",
    "    else:\n",
    "        continue_flag = False\n",
    "        break\n",
    "    \n",
    "#     print(calc_cnn_size(cnn_block, \"pool\"))\n",
    "    pool_size_flag = np.all(calc_cnn_size(cnn_block, \"pool\") > 0)\n",
    "    if pool_size_flag:\n",
    "        cnn_block = pool(cnn_block)\n",
    "        \n",
    "    if src_args[\"batch_normalize\"]:\n",
    "        cnn_block = keras.layers.BatchNormalization()(cnn_block)\n",
    "    \n",
    "    cnn_block = keras.layers.Dropout(src_args[\"dropout_prob\"])(cnn_block)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-04T19:59:42.890921Z",
     "start_time": "2018-01-04T19:59:42.868826Z"
    }
   },
   "outputs": [],
   "source": [
    "out_block = cnn_block\n",
    "out_block = keras.layers.Flatten()(out_block)\n",
    "output_layer = keras.layers.Dense(num_cat, activation=\"softmax\")(out_block)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-04T19:59:43.762155Z",
     "start_time": "2018-01-04T19:59:43.751260Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_5 (InputLayer)         (None, 1, 16000)          0         \n",
      "_________________________________________________________________\n",
      "mfcc_5 (MFCC)                (None, 16, 63, 1)         311216    \n",
      "_________________________________________________________________\n",
      "conv2d_17 (Conv2D)           (None, 3, 18, 50)         5050      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_14 (MaxPooling (None, 1, 9, 50)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_15 (Batc (None, 1, 9, 50)          200       \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 1, 9, 50)          0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 450)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 12)                5412      \n",
      "=================================================================\n",
      "Total params: 321,878\n",
      "Trainable params: 10,562\n",
      "Non-trainable params: 311,316\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "cnn_model = keras.Model(inputs=input_layer, outputs=output_layer)\n",
    "cnn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-04T19:59:49.181113Z",
     "start_time": "2018-01-04T19:59:44.618786Z"
    }
   },
   "outputs": [],
   "source": [
    "log_base = \"logs/cnn/{}/\".format(current_time)\n",
    "callbacks = [\n",
    "    keras.callbacks.TensorBoard(\n",
    "        log_dir=log_base + 'tb',\n",
    "        batch_size=src_args[\"batch_size\"],\n",
    "        histogram_freq=0,\n",
    "        write_grads=False,\n",
    "        write_images=True\n",
    "    ),\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        filepath=log_base + 'model-checkpoint.hdf5',\n",
    "        monitor='val_loss',\n",
    "        verbose=1,\n",
    "        save_best_only=True,\n",
    "        save_weights_only=False,\n",
    "        mode='auto',\n",
    "        period=1),\n",
    "    keras.callbacks.CSVLogger(log_base + 'training.log'),\n",
    "    keras.callbacks.EarlyStopping(patience=4, verbose=1),\n",
    "    keras.callbacks.ReduceLROnPlateau(\n",
    "        factor=0.5, patience=1, verbose=1, min_lr=1e-8)\n",
    "]\n",
    "\n",
    "cnn_model.compile(\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    optimizer='nadam',\n",
    "    metrics=['accuracy'])\n",
    "\n",
    "\n",
    "def launchTensorBoard():\n",
    "    import os\n",
    "    os.system('pkill tensorboard')\n",
    "    os.system('tensorboard --logdir=' + log_base + 'tb')\n",
    "    return\n",
    "\n",
    "\n",
    "t = threading.Thread(target=launchTensorBoard, args=([]))\n",
    "t.start()\n",
    "\n",
    "val_data = next(ex_generator(\n",
    "    batch_size=sum(ex_df.state.isin(src_args[\"val_state\"])),\n",
    "    shuffle=False,\n",
    "    state=src_args[\"val_state\"],\n",
    "    vol_range=0,\n",
    "    displacement=0,\n",
    "    p_transform=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-04T20:10:03.303446Z",
     "start_time": "2018-01-04T19:59:49.963647Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "825/826 [============================>.] - ETA: 0s - loss: 1.3441 - acc: 0.3923Epoch 00001: val_loss improved from inf to 1.97829, saving model to logs/cnn/2018-01-04-14-36/model-checkpoint.hdf5\n",
      "827/826 [==============================] - 23s 28ms/step - loss: 1.3425 - acc: 0.3926 - val_loss: 1.9783 - val_acc: 0.4116\n",
      "Epoch 2/200\n",
      "824/826 [============================>.] - ETA: 0s - loss: 0.8419 - acc: 0.5604- ETA: 0s - loss: 0.8475Epoch 00002: val_loss did not improve\n",
      "827/826 [==============================] - 21s 25ms/step - loss: 0.8423 - acc: 0.5604 - val_loss: 2.3756 - val_acc: 0.2985\n",
      "Epoch 3/200\n",
      "824/826 [============================>.] - ETA: 0s - loss: 0.6620 - acc: 0.6289Epoch 00003: val_loss did not improve\n",
      "\n",
      "Epoch 00003: reducing learning rate to 0.0010000000474974513.\n",
      "827/826 [==============================] - 21s 26ms/step - loss: 0.6623 - acc: 0.6286 - val_loss: 2.0609 - val_acc: 0.3424\n",
      "Epoch 4/200\n",
      "826/826 [============================>.] - ETA: 0s - loss: 0.5338 - acc: 0.6818Epoch 00004: val_loss improved from 1.97829 to 1.43442, saving model to logs/cnn/2018-01-04-14-36/model-checkpoint.hdf5\n",
      "827/826 [==============================] - 21s 26ms/step - loss: 0.5341 - acc: 0.6818 - val_loss: 1.4344 - val_acc: 0.6202\n",
      "Epoch 5/200\n",
      "826/826 [============================>.] - ETA: 0s - loss: 0.4964 - acc: 0.6963Epoch 00005: val_loss improved from 1.43442 to 1.08734, saving model to logs/cnn/2018-01-04-14-36/model-checkpoint.hdf5\n",
      "827/826 [==============================] - 21s 25ms/step - loss: 0.4969 - acc: 0.6961 - val_loss: 1.0873 - val_acc: 0.7198\n",
      "Epoch 6/200\n",
      "825/826 [============================>.] - ETA: 0s - loss: 0.4682 - acc: 0.7111Epoch 00006: val_loss did not improve\n",
      "827/826 [==============================] - 21s 26ms/step - loss: 0.4679 - acc: 0.7111 - val_loss: 1.1660 - val_acc: 0.5330\n",
      "Epoch 7/200\n",
      "825/826 [============================>.] - ETA: 0s - loss: 0.4484 - acc: 0.7217Epoch 00007: val_loss improved from 1.08734 to 0.78760, saving model to logs/cnn/2018-01-04-14-36/model-checkpoint.hdf5\n",
      "827/826 [==============================] - 21s 26ms/step - loss: 0.4483 - acc: 0.7218 - val_loss: 0.7876 - val_acc: 0.6259\n",
      "Epoch 8/200\n",
      "826/826 [============================>.] - ETA: 0s - loss: 0.4269 - acc: 0.7294Epoch 00008: val_loss improved from 0.78760 to 0.74997, saving model to logs/cnn/2018-01-04-14-36/model-checkpoint.hdf5\n",
      "827/826 [==============================] - 21s 26ms/step - loss: 0.4272 - acc: 0.7294 - val_loss: 0.7500 - val_acc: 0.6545\n",
      "Epoch 9/200\n",
      "826/826 [============================>.] - ETA: 0s - loss: 0.4101 - acc: 0.7393Epoch 00009: val_loss did not improve\n",
      "827/826 [==============================] - 21s 26ms/step - loss: 0.4110 - acc: 0.7393 - val_loss: 0.8961 - val_acc: 0.6436\n",
      "Epoch 10/200\n",
      "824/826 [============================>.] - ETA: 0s - loss: 0.4032 - acc: 0.7465Epoch 00010: val_loss did not improve\n",
      "\n",
      "Epoch 00010: reducing learning rate to 0.0005000000237487257.\n",
      "827/826 [==============================] - 21s 26ms/step - loss: 0.4027 - acc: 0.7468 - val_loss: 1.1009 - val_acc: 0.4449\n",
      "Epoch 11/200\n",
      "826/826 [============================>.] - ETA: 0s - loss: 0.3462 - acc: 0.7704Epoch 00011: val_loss improved from 0.74997 to 0.58267, saving model to logs/cnn/2018-01-04-14-36/model-checkpoint.hdf5\n",
      "827/826 [==============================] - 21s 26ms/step - loss: 0.3460 - acc: 0.7703 - val_loss: 0.5827 - val_acc: 0.6496\n",
      "Epoch 12/200\n",
      "825/826 [============================>.] - ETA: 0s - loss: 0.3359 - acc: 0.7767Epoch 00012: val_loss did not improve\n",
      "827/826 [==============================] - 21s 25ms/step - loss: 0.3373 - acc: 0.7766 - val_loss: 0.7108 - val_acc: 0.7417\n",
      "Epoch 13/200\n",
      "826/826 [============================>.] - ETA: 0s - loss: 0.3271 - acc: 0.7809Epoch 00013: val_loss did not improve\n",
      "\n",
      "Epoch 00013: reducing learning rate to 0.0002500000118743628.\n",
      "827/826 [==============================] - 21s 25ms/step - loss: 0.3268 - acc: 0.7808 - val_loss: 0.6820 - val_acc: 0.7087\n",
      "Epoch 14/200\n",
      "826/826 [============================>.] - ETA: 0s - loss: 0.3041 - acc: 0.7947Epoch 00014: val_loss did not improve\n",
      "\n",
      "Epoch 00014: reducing learning rate to 0.0001250000059371814.\n",
      "827/826 [==============================] - 21s 25ms/step - loss: 0.3040 - acc: 0.7948 - val_loss: 0.5911 - val_acc: 0.6523\n",
      "Epoch 15/200\n",
      "824/826 [============================>.] - ETA: 0s - loss: 0.2850 - acc: 0.8030- Epoch 00015: val_loss improved from 0.58267 to 0.51538, saving model to logs/cnn/2018-01-04-14-36/model-checkpoint.hdf5\n",
      "827/826 [==============================] - 21s 26ms/step - loss: 0.2852 - acc: 0.8029 - val_loss: 0.5154 - val_acc: 0.7460\n",
      "Epoch 16/200\n",
      "825/826 [============================>.] - ETA: 0s - loss: 0.2841 - acc: 0.8026Epoch 00016: val_loss did not improve\n",
      "827/826 [==============================] - 21s 25ms/step - loss: 0.2838 - acc: 0.8026 - val_loss: 0.5206 - val_acc: 0.7536\n",
      "Epoch 17/200\n",
      "826/826 [============================>.] - ETA: 0s - loss: 0.2816 - acc: 0.8035Epoch 00017: val_loss did not improve\n",
      "\n",
      "Epoch 00017: reducing learning rate to 6.25000029685907e-05.\n",
      "827/826 [==============================] - 21s 25ms/step - loss: 0.2817 - acc: 0.8035 - val_loss: 0.5230 - val_acc: 0.7310\n",
      "Epoch 18/200\n",
      "826/826 [============================>.] - ETA: 0s - loss: 0.2744 - acc: 0.8076Epoch 00018: val_loss did not improve\n",
      "\n",
      "Epoch 00018: reducing learning rate to 3.125000148429535e-05.\n",
      "827/826 [==============================] - 21s 25ms/step - loss: 0.2744 - acc: 0.8076 - val_loss: 0.5223 - val_acc: 0.7798\n",
      "Epoch 19/200\n",
      "825/826 [============================>.] - ETA: 0s - loss: 0.2683 - acc: 0.8074- ETA: 1s - loEpoch 00019: val_loss improved from 0.51538 to 0.50811, saving model to logs/cnn/2018-01-04-14-36/model-checkpoint.hdf5\n",
      "827/826 [==============================] - 21s 25ms/step - loss: 0.2685 - acc: 0.8074 - val_loss: 0.5081 - val_acc: 0.7790\n",
      "Epoch 20/200\n",
      "826/826 [============================>.] - ETA: 0s - loss: 0.2694 - acc: 0.8087Epoch 00020: val_loss did not improve\n",
      "827/826 [==============================] - 21s 25ms/step - loss: 0.2693 - acc: 0.8086 - val_loss: 0.5126 - val_acc: 0.7844\n",
      "Epoch 21/200\n",
      "825/826 [============================>.] - ETA: 0s - loss: 0.2697 - acc: 0.8094Epoch 00021: val_loss improved from 0.50811 to 0.50631, saving model to logs/cnn/2018-01-04-14-36/model-checkpoint.hdf5\n",
      "827/826 [==============================] - 21s 25ms/step - loss: 0.2699 - acc: 0.8094 - val_loss: 0.5063 - val_acc: 0.7803\n",
      "Epoch 22/200\n",
      "824/826 [============================>.] - ETA: 0s - loss: 0.2698 - acc: 0.8111- ETA: 1s - Epoch 00022: val_loss did not improve\n",
      "827/826 [==============================] - 21s 25ms/step - loss: 0.2697 - acc: 0.8110 - val_loss: 0.5082 - val_acc: 0.7699\n",
      "Epoch 23/200\n",
      "825/826 [============================>.] - ETA: 0s - loss: 0.2673 - acc: 0.8114Epoch 00023: val_loss did not improve\n",
      "\n",
      "Epoch 00023: reducing learning rate to 1.5625000742147677e-05.\n",
      "827/826 [==============================] - 21s 26ms/step - loss: 0.2674 - acc: 0.8115 - val_loss: 0.5168 - val_acc: 0.7744\n",
      "Epoch 24/200\n",
      "826/826 [============================>.] - ETA: 0s - loss: 0.2655 - acc: 0.8113Epoch 00024: val_loss did not improve\n",
      "\n",
      "Epoch 00024: reducing learning rate to 7.812500371073838e-06.\n",
      "827/826 [==============================] - 21s 25ms/step - loss: 0.2655 - acc: 0.8113 - val_loss: 0.5127 - val_acc: 0.7877\n",
      "Epoch 25/200\n",
      "825/826 [============================>.] - ETA: 0s - loss: 0.2648 - acc: 0.8120Epoch 00025: val_loss improved from 0.50631 to 0.50434, saving model to logs/cnn/2018-01-04-14-36/model-checkpoint.hdf5\n",
      "827/826 [==============================] - 21s 25ms/step - loss: 0.2647 - acc: 0.8121 - val_loss: 0.5043 - val_acc: 0.7714\n",
      "Epoch 26/200\n",
      "824/826 [============================>.] - ETA: 0s - loss: 0.2623 - acc: 0.8133Epoch 00026: val_loss did not improve\n",
      "827/826 [==============================] - 21s 25ms/step - loss: 0.2625 - acc: 0.8132 - val_loss: 0.5064 - val_acc: 0.7829\n",
      "Epoch 27/200\n",
      "824/826 [============================>.] - ETA: 0s - loss: 0.2650 - acc: 0.8131Epoch 00027: val_loss did not improve\n",
      "\n",
      "Epoch 00027: reducing learning rate to 3.906250185536919e-06.\n",
      "827/826 [==============================] - 21s 25ms/step - loss: 0.2647 - acc: 0.8131 - val_loss: 0.5067 - val_acc: 0.7827\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/200\n",
      "824/826 [============================>.] - ETA: 0s - loss: 0.2618 - acc: 0.8116Epoch 00028: val_loss did not improve\n",
      "\n",
      "Epoch 00028: reducing learning rate to 1.9531250927684596e-06.\n",
      "827/826 [==============================] - 21s 25ms/step - loss: 0.2619 - acc: 0.8114 - val_loss: 0.5054 - val_acc: 0.7827\n",
      "Epoch 29/200\n",
      "825/826 [============================>.] - ETA: 0s - loss: 0.2625 - acc: 0.8130Epoch 00029: val_loss did not improve\n",
      "\n",
      "Epoch 00029: reducing learning rate to 9.765625463842298e-07.\n",
      "827/826 [==============================] - 21s 25ms/step - loss: 0.2623 - acc: 0.8130 - val_loss: 0.5046 - val_acc: 0.7807\n",
      "Epoch 00029: early stopping\n"
     ]
    }
   ],
   "source": [
    "history = cnn_model.fit_generator(\n",
    "    generator=ex_generator(\n",
    "        batch_size=src_args[\"batch_size\"],\n",
    "        shuffle=True,\n",
    "        state=src_args[\"train_state\"],\n",
    "        vol_range=src_args[\"vol_range\"],\n",
    "        displacement=src_args[\"displacement\"],\n",
    "        p_transform=src_args[\"p_transform\"]),\n",
    "    steps_per_epoch=sum(ex_df.state.isin(\n",
    "        src_args[\"train_state\"])) / src_args[\"batch_size\"],\n",
    "    epochs=200,\n",
    "    verbose=1,\n",
    "    max_queue_size=100,\n",
    "    callbacks=callbacks,\n",
    "    validation_data=val_data\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-04T20:14:26.323581Z",
     "start_time": "2018-01-04T20:14:26.320221Z"
    }
   },
   "outputs": [],
   "source": [
    "objective = np.min(history.history[\"val_loss\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-04T20:14:14.224354Z",
     "start_time": "2018-01-04T20:14:14.219825Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2018-01-04-14-36'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-04T20:17:50.602566Z",
     "start_time": "2018-01-04T20:17:50.598636Z"
    }
   },
   "outputs": [],
   "source": [
    "with open(\"logs/opt-log\", \"w\") as f:\n",
    "    f.writelines(\"{}, {}\".format(current_time, objective))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperopt.fmin()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
