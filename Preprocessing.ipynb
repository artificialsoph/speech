{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO\n",
    "\n",
    "- fix classes according to kaggle rules: add unk and silence\n",
    "- add hyperas optimization\n",
    "- experiment with other kinds of data synthesis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-13T21:47:49.287970Z",
     "start_time": "2018-01-13T21:47:49.227670Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "\n",
    "import scipy.io.wavfile as wav\n",
    "import scipy.signal\n",
    "import pandas\n",
    "from tqdm import tqdm, trange\n",
    "from IPython.display import Audio\n",
    "import pickle\n",
    "import seaborn\n",
    "from scipy.ndimage.interpolation import shift\n",
    "# from soph import center_wave\n",
    "seaborn.set_style(\"whitegrid\")\n",
    "\n",
    "%pylab inline\n",
    "\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build an index dataframe\n",
    "\n",
    "Read in the files and build labels and weights\n",
    "\n",
    "- `raw_label`: 32 labels including those not in the target category.\n",
    "- `label`: 12 labels including target labels, \"silence\" and \"unknown\"\n",
    "- `raw_labels_i`: index for raw labels\n",
    "- `labels_i`: index for labels\n",
    "- `class_weight`: balanced class weights for examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-13T21:47:56.873658Z",
     "start_time": "2018-01-13T21:47:55.216877Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64727"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_files = glob.glob(\"data/**/*.wav\", recursive=True)\n",
    "len(all_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-13T21:47:57.877385Z",
     "start_time": "2018-01-13T21:47:57.807436Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>data/train/audio/right/988e2f9a_nohash_0.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>data/train/audio/right/1eddce1d_nohash_3.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>data/train/audio/right/93ec8b84_nohash_0.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>data/train/audio/right/6272b231_nohash_1.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>data/train/audio/right/439c84f4_nohash_1.wav</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             fn\n",
       "0  data/train/audio/right/988e2f9a_nohash_0.wav\n",
       "1  data/train/audio/right/1eddce1d_nohash_3.wav\n",
       "2  data/train/audio/right/93ec8b84_nohash_0.wav\n",
       "3  data/train/audio/right/6272b231_nohash_1.wav\n",
       "4  data/train/audio/right/439c84f4_nohash_1.wav"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex_df = pandas.DataFrame()\n",
    "ex_df[\"fn\"] = all_files\n",
    "ex_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-13T21:47:58.785708Z",
     "start_time": "2018-01-13T21:47:58.754867Z"
    }
   },
   "outputs": [],
   "source": [
    "with open(\"data/train/validation_list.txt\") as f:\n",
    "    val_list = [\"data/train/audio/\"+fn.strip() for fn in f.readlines()]\n",
    "with open(\"data/train/testing_list.txt\") as f:\n",
    "    test_list = [\"data/train/audio/\"+fn.strip() for fn in f.readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-13T21:48:00.303013Z",
     "start_time": "2018-01-13T21:48:00.293704Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'data/train/audio/bed/026290a7_nohash_0.wav'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-13T21:48:01.721362Z",
     "start_time": "2018-01-13T21:48:01.256871Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "train    51088\n",
       "test      6835\n",
       "val       6798\n",
       "bg           6\n",
       "Name: state, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex_df[\"state\"] = \"train\"\n",
    "ex_df.state[ex_df.fn.str.contains(\"_background_noise_\")]=\"bg\"\n",
    "ex_df.state[ex_df.fn.str.contains(\"test\")]=\"submission\"\n",
    "ex_df.state[ex_df.fn.isin(val_list)]=\"val\"\n",
    "ex_df.state[ex_df.fn.isin(test_list)]=\"test\"\n",
    "ex_df.state.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-13T21:48:04.628113Z",
     "start_time": "2018-01-13T21:48:04.115890Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "stop       2380\n",
       "seven      2377\n",
       "yes        2377\n",
       "zero       2376\n",
       "up         2375\n",
       "no         2375\n",
       "two        2373\n",
       "go         2372\n",
       "four       2372\n",
       "one        2370\n",
       "six        2369\n",
       "on         2367\n",
       "right      2367\n",
       "nine       2364\n",
       "down       2359\n",
       "five       2357\n",
       "off        2357\n",
       "three      2356\n",
       "left       2353\n",
       "eight      2352\n",
       "silence    2320\n",
       "house      1750\n",
       "dog        1746\n",
       "marvin     1746\n",
       "wow        1745\n",
       "happy      1742\n",
       "sheila     1734\n",
       "cat        1733\n",
       "tree       1733\n",
       "bird       1731\n",
       "bed        1713\n",
       "Name: raw_label, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex_df[\"raw_label\"] = np.nan\n",
    "label_bool = ex_df.state.isin([\"test\", \"train\", \"val\"])\n",
    "ex_df.loc[label_bool,\"raw_label\"] = ex_df.loc[label_bool,\"fn\"].str.split('/').str[3]\n",
    "\n",
    "val_df = pandas.DataFrame([{\"fn\":\"silence\", \"state\":\"val\", \"raw_label\":\"silence\"}]*260)\n",
    "test_df = pandas.DataFrame([{\"fn\":\"silence\", \"state\":\"test\", \"raw_label\":\"silence\"}]*260)\n",
    "train_df = pandas.DataFrame([{\"fn\":\"silence\", \"state\":\"train\", \"raw_label\":\"silence\"}]*1800)\n",
    "ex_df = pandas.concat((ex_df,val_df,test_df,train_df))\n",
    "label_bool = ex_df.state.isin([\"test\", \"train\", \"val\"])\n",
    "\n",
    "ex_df.raw_label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-13T21:48:07.693519Z",
     "start_time": "2018-01-13T21:48:07.551624Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "unknown    41039\n",
       "stop        2380\n",
       "yes         2377\n",
       "no          2375\n",
       "up          2375\n",
       "go          2372\n",
       "on          2367\n",
       "right       2367\n",
       "down        2359\n",
       "off         2357\n",
       "left        2353\n",
       "silence     2320\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex_df[\"label\"] = np.nan\n",
    "target_classes = [\"yes\", \"no\", \"up\", \"down\", \"left\", \"right\", \"on\", \"off\", \"stop\", \"go\", \"silence\"]\n",
    "target_bool = ex_df.raw_label.isin(target_classes)\n",
    "ex_df.loc[target_bool,\"label\"] = ex_df.loc[target_bool,\"raw_label\"]\n",
    "ex_df.loc[label_bool&(-target_bool),\"label\"] = \"unknown\"\n",
    "ex_df.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-13T21:48:10.387978Z",
     "start_time": "2018-01-13T21:48:10.350765Z"
    }
   },
   "outputs": [],
   "source": [
    "counts = ex_df.label.value_counts()\n",
    "cw = dict(zip(counts.index,counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-13T21:48:11.272678Z",
     "start_time": "2018-01-13T21:48:11.180575Z"
    }
   },
   "outputs": [],
   "source": [
    "num_ex = sum(label_bool)\n",
    "num_labels = len(ex_df.label.unique()) -1\n",
    "mean_n = num_ex/num_labels\n",
    "counts = ex_df.label.value_counts()\n",
    "cw = dict(zip(counts.index,counts))\n",
    "for k,v in cw.items():\n",
    "    cw[k] = mean_n/v\n",
    "ex_df[\"label_weight\"] = ex_df.label.map(cw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-13T21:48:12.103180Z",
     "start_time": "2018-01-13T21:48:12.014268Z"
    }
   },
   "outputs": [],
   "source": [
    "label_list = target_classes + [\"unknown\"]\n",
    "raw_label_list = ex_df.raw_label.unique()\n",
    "raw_label_list = [lb for lb in raw_label_list if lb not in label_list]\n",
    "raw_label_list.remove(np.nan)\n",
    "raw_label_list = label_list + raw_label_list\n",
    "raw_label_dict = dict(zip(raw_label_list, arange(len(raw_label_list))) )\n",
    "ex_df[\"label_i\"] = ex_df.label.map(raw_label_dict)\n",
    "ex_df[\"raw_label_i\"] = ex_df.raw_label.map(raw_label_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-13T21:48:12.984164Z",
     "start_time": "2018-01-13T21:48:12.840493Z"
    }
   },
   "outputs": [],
   "source": [
    "ex_df.to_pickle(\"data/ex_df.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-07T01:57:57.472476Z",
     "start_time": "2017-12-07T01:52:33.633Z"
    }
   },
   "outputs": [],
   "source": [
    "with open(\"data/bg_list.txt\") as f:\n",
    "    bg_files = [fn.strip() for fn in f.readlines()]\n",
    "bg_files\n",
    "ex_df = pandas.concat([ex_df, pandas.DataFrame(\n",
    "    [{\"fn\":fn, \"state\":\"bg\"} for fn in bg_files]\n",
    ")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-07T01:57:57.473294Z",
     "start_time": "2017-12-07T01:52:33.638Z"
    }
   },
   "outputs": [],
   "source": [
    "ex_df.state.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-07T01:57:57.474046Z",
     "start_time": "2017-12-07T01:52:33.643Z"
    }
   },
   "outputs": [],
   "source": [
    "4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-07T01:57:57.474794Z",
     "start_time": "2017-12-07T01:52:33.647Z"
    }
   },
   "outputs": [],
   "source": [
    "ex_df.to_pickle(\"data/ex_df.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-07T01:57:57.475969Z",
     "start_time": "2017-12-07T01:52:33.650Z"
    }
   },
   "outputs": [],
   "source": [
    "ex_df = pandas.read_pickle(\"data/ex_df.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-07T01:57:57.477288Z",
     "start_time": "2017-12-07T01:52:33.653Z"
    }
   },
   "outputs": [],
   "source": [
    "len(ex_df.label.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-07T01:57:57.478778Z",
     "start_time": "2017-12-07T01:52:33.656Z"
    }
   },
   "outputs": [],
   "source": [
    "len(ex_df.label_raw.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Everything below this is old code!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-07T01:57:57.480186Z",
     "start_time": "2017-12-07T01:52:33.660Z"
    }
   },
   "outputs": [],
   "source": [
    "train_files = train_files - set(validation_files) - set(testing_files)\n",
    "\n",
    "print(\"{} total files: {} train, {} validation, {} test\".format(\n",
    "    total_n_files, len(train_files), len(validation_files), len(testing_files)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-07T01:57:57.482224Z",
     "start_time": "2017-12-07T01:52:33.664Z"
    }
   },
   "outputs": [],
   "source": [
    "ex_df = pandas.DataFrame()\n",
    "ex_df[\"fn\"] = train_files + validation_files + testing_files\n",
    "ex_df[\"state\"] = [\"train\"] * len(train_files) + [\"val\"] * len(\n",
    "    validation_files) + [\"test\"] * len(testing_files)\n",
    "ex_df[\"cat\"] = ex_df.fn.map(lambda x: x.split(\"/\")[3])\n",
    "\n",
    "ex_df.state[ex_df.cat == \"_background_noise_\"] = \"bg\"\n",
    "\n",
    "\n",
    "# unk_cat = set(ex_df.cat.unique()) - set(target_cat)\n",
    "# ex_df.cat[ex_df.cat.isin(unk_cat)] = \"unknown\"\n",
    "\n",
    "val_df = pandas.DataFrame([{\"fn\":\"silence\", \"state\":\"val\", \"cat\":\"silence\"}]*260)\n",
    "test_df = pandas.DataFrame([{\"fn\":\"silence\", \"state\":\"test\", \"cat\":\"silence\"}]*260)\n",
    "train_df = pandas.DataFrame([{\"fn\":\"silence\", \"state\":\"train\", \"cat\":\"silence\"}]*1800)\n",
    "ex_df = pandas.concat((ex_df,val_df,test_df,train_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-07T01:57:57.483624Z",
     "start_time": "2017-12-07T01:52:33.667Z"
    }
   },
   "outputs": [],
   "source": [
    "ex_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-07T01:57:57.485101Z",
     "start_time": "2017-12-07T01:52:33.670Z"
    }
   },
   "outputs": [],
   "source": [
    "# build indices\n",
    "unique_cat = ex_df.cat.unique()\n",
    "cat_dict = dict(zip(unique_cat, range(len(unique_cat))))\n",
    "with open(\"logs/cat_dict.pkl\", \"wb\") as f:\n",
    "    pickle.dump(cat_dict, f)\n",
    "print(cat_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-07T01:57:57.486341Z",
     "start_time": "2017-12-07T01:52:33.677Z"
    }
   },
   "outputs": [],
   "source": [
    "ex_df[\"cat_i\"] = ex_df.cat.map(cat_dict)\n",
    "ex_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-07T01:57:57.488724Z",
     "start_time": "2017-12-07T01:52:33.681Z"
    }
   },
   "outputs": [],
   "source": [
    "ex_df.to_pickle(\"data/ex_df.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-07T01:57:57.490394Z",
     "start_time": "2017-12-07T01:52:33.684Z"
    }
   },
   "outputs": [],
   "source": [
    "ex_df.state.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-07T01:57:57.491784Z",
     "start_time": "2017-12-07T01:52:33.686Z"
    }
   },
   "outputs": [],
   "source": [
    "num_cat = len(ex_df.cat.unique())\n",
    "print(num_cat)\n",
    "ex_df[ex_df.state==\"train\"].cat.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-07T01:57:57.493130Z",
     "start_time": "2017-12-07T01:52:33.690Z"
    }
   },
   "outputs": [],
   "source": [
    "def scaler(wave):\n",
    "    return 2*(0.+ wave - wave.min())/(.0 + wave.max() - wave.min() + 1e-4) - 1\n",
    "\n",
    "bg_waves = [scaler(wav.read(fn)[1]) for fn in ex_df[ex_df.state == \"bg\"].fn]\n",
    "\n",
    "def center_wave(wav_fn, maxlen=16000, vol_range=.3):\n",
    "    \n",
    "    if wav_fn == \"silence\":\n",
    "        bg_wave = random.choice(bg_waves)\n",
    "        bg_len = len(bg_wave)-maxlen\n",
    "        bg_start = np.random.randint(bg_len)\n",
    "        wave = bg_wave[bg_start:bg_start+maxlen]\n",
    "\n",
    "    else:\n",
    "        wave = scaler(wav.read(wav_fn)[1])\n",
    "\n",
    "        if wave.shape[0] < maxlen:\n",
    "            left_pad = (maxlen - wave.shape[0]) // 2\n",
    "            right_pad = maxlen - wave.shape[0] - left_pad\n",
    "            wave = np.pad(\n",
    "                wave, (left_pad, right_pad), 'constant', constant_values=0)\n",
    "        \n",
    "        if vol_range > 0:\n",
    "            bg_wave = center_wave(\"silence\", maxlen)\n",
    "            bg_vol = vol_range * np.random.rand(1)\n",
    "            wave_vol = 1 - bg_vol\n",
    "            wave = wave_vol*wave + bg_vol * bg_wave\n",
    "            wave = np.clip(wave, -1, 1)\n",
    "            \n",
    "\n",
    "    return wave\n",
    "\n",
    "\n",
    "## wave2mfcc parameters:\n",
    "## numcep should be equal to numfilt\n",
    "## windows can overlap (ie winlen can be greater than winstep)\n",
    "\n",
    "def wave2mfcc(wav_fn, vol_range=.3):\n",
    "\n",
    "    rate = 16000\n",
    "    \n",
    "    wave = center_wave(wav_fn, vol_range=vol_range)\n",
    "\n",
    "    \n",
    "    mfcc_feat = mfcc(\n",
    "        wave,\n",
    "        rate,\n",
    "        numcep=160,\n",
    "        winlen=100 / 16000,\n",
    "        winstep=100 / 16000,\n",
    "        nfilt=160,\n",
    "#         lowfreq=100,\n",
    "#         highfreq=5000\n",
    "    )\n",
    "\n",
    "    return mfcc_feat\n",
    "\n",
    "def wave2melspec(wav_fn):\n",
    "    wave = center_wave(wav_fn)\n",
    "    S = librosa.feature.melspectrogram(wave, sr=16000, n_mels=128)\n",
    "\n",
    "    # Convert to log scale (dB). We'll use the peak power (max) as reference.\n",
    "    log_S = librosa.power_to_db(S, ref=np.max)\n",
    "    return log_S\n",
    "\n",
    "def wave2spec(wav_fn):\n",
    "    wave = center_wave(wav_fn)\n",
    "    \n",
    "    spec = np.log(np.abs(scipy.signal.stft(wave, fs=16000)[2])+1e-6)\n",
    "\n",
    "\n",
    "    return spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-07T01:57:57.494436Z",
     "start_time": "2017-12-07T01:52:33.693Z"
    }
   },
   "outputs": [],
   "source": [
    "len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-07T01:57:57.495913Z",
     "start_time": "2017-12-07T01:52:33.696Z"
    }
   },
   "outputs": [],
   "source": [
    "for fn in tqdm(glob.glob(\"data/**/*.wav\", recursive=True)):\n",
    "    wav.write(fn, 16000,scaler(wav.read(fn)[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-07T01:57:57.497258Z",
     "start_time": "2017-12-07T01:52:33.698Z"
    }
   },
   "outputs": [],
   "source": [
    "wave_out = wav.read(train_files[1])[1]\n",
    "wave_out = scaler(wave_out)\n",
    "wav.write(\"test.wav\", 16000,wave_out)\n",
    "wave2 = wav.read(\"test.wav\")[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-07T01:57:57.498762Z",
     "start_time": "2017-12-07T01:52:33.701Z"
    }
   },
   "outputs": [],
   "source": [
    "all(wave2 == wave_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-07T01:57:57.500120Z",
     "start_time": "2017-12-07T01:52:33.708Z"
    }
   },
   "outputs": [],
   "source": [
    "out = center_wave(train_files[1], vol_range=.1)\n",
    "Audio(data=out, rate=16000, embed=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-07T01:57:57.501385Z",
     "start_time": "2017-12-07T01:52:33.711Z"
    }
   },
   "outputs": [],
   "source": [
    "figsize(3,3)\n",
    "plt.imshow(wave2mfcc(train_files[1]).T, aspect='auto');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-07T01:57:57.502903Z",
     "start_time": "2017-12-07T01:52:33.715Z"
    }
   },
   "outputs": [],
   "source": [
    "MFCC = True\n",
    "if MFCC:\n",
    "    x = []\n",
    "\n",
    "    # example loop\n",
    "    for fn in tqdm(ex_df[ex_df.state == \"train\"].fn):\n",
    "\n",
    "        #get the wave data w/o noise\n",
    "#         mfcc_feat = wave2mfcc(fn, vol_range=0)\n",
    "\n",
    "#         x.append(mfcc_feat[np.newaxis, :, :, np.newaxis])\n",
    "        \n",
    "        # get the wave data w/ noise\n",
    "        mfcc_feat = wave2mfcc(fn, vol_range=.1)\n",
    "\n",
    "        x.append(mfcc_feat[np.newaxis, :, :, np.newaxis])\n",
    "        \n",
    "\n",
    "    x = np.concatenate(x, axis=0)\n",
    "    y = ex_df[ex_df.state == \"train\"].cat_i.values[:, np.newaxis]\n",
    "    \n",
    "    x_val = []\n",
    "\n",
    "    # example loop\n",
    "    for fn in tqdm(ex_df[ex_df.state == \"val\"].fn):\n",
    "\n",
    "        #get the wave data\n",
    "        row = wave2mfcc(fn, vol_range=0)\n",
    "\n",
    "        x_val.append(row[np.newaxis, :, :, np.newaxis])\n",
    "\n",
    "    x_val = np.concatenate(x_val, axis=0)\n",
    "    y_val = ex_df[ex_df.state == \"val\"].cat_i.values[:, np.newaxis]\n",
    "    \n",
    "    \n",
    "    np.savez('data/xy-mfcc', x=x, y=y, x_val=x_val, y_val=y_val)\n",
    "    \n",
    "MS = False\n",
    "if MS:\n",
    "    x = []\n",
    "\n",
    "    # example loop\n",
    "    for fn in tqdm(ex_df[ex_df.state == \"train\"].fn):\n",
    "\n",
    "        #get the wave data\n",
    "        mfcc_feat = wave2melspec(fn)\n",
    "\n",
    "        x.append(mfcc_feat[np.newaxis, :, :, np.newaxis])\n",
    "\n",
    "    x = np.concatenate(x, axis=0)\n",
    "    y = ex_df[ex_df.state == \"train\"].cat_i.values[:, np.newaxis]\n",
    "    \n",
    "    x_val = []\n",
    "\n",
    "    # example loop\n",
    "    for fn in tqdm(ex_df[ex_df.state == \"val\"].fn):\n",
    "\n",
    "        #get the wave data\n",
    "        mfcc_feat = wave2melspec(fn)\n",
    "\n",
    "        x_val.append(mfcc_feat[np.newaxis, :, :, np.newaxis])\n",
    "\n",
    "    x_val = np.concatenate(x_val, axis=0)\n",
    "    y_val = ex_df[ex_df.state == \"val\"].cat_i.values[:, np.newaxis]\n",
    "    \n",
    "    \n",
    "    np.savez('data/xy-ms', x=x, y=y, x_val=x_val, y_val=y_val)\n",
    "    \n",
    "SPEC = False\n",
    "if SPEC:\n",
    "    x = []\n",
    "\n",
    "    # example loop\n",
    "    for fn in tqdm(ex_df[ex_df.state == \"train\"].fn):\n",
    "\n",
    "        #get the wave data\n",
    "        mfcc_feat = wave2spec(fn)\n",
    "\n",
    "        x.append(mfcc_feat[np.newaxis, :, :, np.newaxis])\n",
    "\n",
    "    x = np.concatenate(x, axis=0)\n",
    "    y = ex_df[ex_df.state == \"train\"].cat_i.values[:, np.newaxis]\n",
    "    \n",
    "    x_val = []\n",
    "\n",
    "    # example loop\n",
    "    for fn in tqdm(ex_df[ex_df.state == \"val\"].fn):\n",
    "\n",
    "        #get the wave data\n",
    "        mfcc_feat = wave2spec(fn)\n",
    "\n",
    "        x_val.append(mfcc_feat[np.newaxis, :, :, np.newaxis])\n",
    "\n",
    "    x_val = np.concatenate(x_val, axis=0)\n",
    "    y_val = ex_df[ex_df.state == \"val\"].cat_i.values[:, np.newaxis]\n",
    "    \n",
    "    print(x.nbytes/1e9)\n",
    "    np.savez('data/xy-spec', x=x, y=y, x_val=x_val, y_val=y_val)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-07T01:57:57.504594Z",
     "start_time": "2017-12-07T01:52:33.719Z"
    }
   },
   "outputs": [],
   "source": [
    "ex_df[ex_df.state==\"val\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-07T01:57:57.506006Z",
     "start_time": "2017-12-07T01:52:33.722Z"
    }
   },
   "outputs": [],
   "source": [
    "y_val[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-07T01:57:57.507404Z",
     "start_time": "2017-12-07T01:52:33.729Z"
    }
   },
   "outputs": [],
   "source": [
    "Audio(center_wave(\"data/train/audio/bed/099d52ad_nohash_0.wav\", vol_range=0), rate=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-07T01:57:57.508928Z",
     "start_time": "2017-12-07T01:52:33.731Z"
    }
   },
   "outputs": [],
   "source": [
    "list(zip(np.unique(y),np.bincount(y.flat)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-07T01:57:57.510513Z",
     "start_time": "2017-12-07T01:52:33.734Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-07T01:57:57.511767Z",
     "start_time": "2017-12-07T01:52:33.737Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "classes = np.arange(num_cat)\n",
    "\n",
    "cw = utils.class_weight.compute_class_weight(\"balanced\",classes.flat, y.flat)\n",
    "cw = dict(zip(classes,cw))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-07T01:57:57.513357Z",
     "start_time": "2017-12-07T01:52:33.741Z"
    }
   },
   "outputs": [],
   "source": [
    "x.nbytes/1e9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-07T01:57:57.514777Z",
     "start_time": "2017-12-07T01:52:33.744Z"
    }
   },
   "outputs": [],
   "source": [
    "PROCESS_BG = False\n",
    "if PROCESS_BG:\n",
    "    x = []\n",
    "\n",
    "    # example loop\n",
    "    for fn in tqdm(ex_df[ex_df.state == \"train\"].fn):\n",
    "\n",
    "        #get the wave data\n",
    "        mfcc_feat = wave2mfcc(fn, bg=True)\n",
    "\n",
    "        x.append(mfcc_feat[np.newaxis, :, :, np.newaxis])\n",
    "\n",
    "    x = np.concatenate(x, axis=0)\n",
    "    y = ex_df[ex_df.state == \"train\"].cat_i.values[:, np.newaxis]\n",
    "    \n",
    "    \n",
    "    \n",
    "    np.savez_compressed('data/xy_bg', x=x, y=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-07T01:57:57.516674Z",
     "start_time": "2017-12-07T01:52:33.747Z"
    }
   },
   "outputs": [],
   "source": [
    "PROCESS_BG = True\n",
    "if PROCESS_BG:\n",
    "    x_val = []\n",
    "\n",
    "    # example loop\n",
    "    for fn in tqdm(ex_df[ex_df.state == \"val\"].fn):\n",
    "\n",
    "        #get the wave data\n",
    "        mfcc_feat = wave2mfcc(fn, bg=True)\n",
    "\n",
    "        x_val.append(mfcc_feat[np.newaxis, :, :, np.newaxis])\n",
    "\n",
    "    x_val = np.concatenate(x_val, axis=0)\n",
    "    y_val = ex_df[ex_df.state == \"val\"].cat_i.values[:, np.newaxis]\n",
    "    np.savez_compressed('data/xy_val', x=x_val, y=y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-07T01:57:57.519056Z",
     "start_time": "2017-12-07T01:52:33.750Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_generator(batch_size=32, shuffle=True, state=\"train\", maxlen = 16000):\n",
    "    \n",
    "    maxlen = 16000\n",
    "    \n",
    "    epoch_df = ex_df[ex_df.state == state]\n",
    "    num_ex = len(epoch_df)\n",
    "    indices = np.arange(num_ex)\n",
    "    \n",
    "    # epoch loop runs\n",
    "    while True:\n",
    "        \n",
    "        # shuffle anew every epoch\n",
    "        if shuffle:\n",
    "            epoch_df = epoch_df.sample(frac=1)\n",
    "        \n",
    "        # batch loop\n",
    "        for i in np.arange(0, num_ex, batch_size):\n",
    "            \n",
    "            x = []\n",
    "            \n",
    "            batch_df = epoch_df.iloc[i:i+batch_size:,:]\n",
    "            \n",
    "            # example loop\n",
    "            for fn in batch_df.fn:\n",
    "                                \n",
    "                #get the processed file\n",
    "                item = wave2spec(fn)\n",
    "                \n",
    "                x.append(item[np.newaxis,:,:,np.newaxis])\n",
    "            \n",
    "            x = np.concatenate(x,axis=0)\n",
    "            y = batch_df.cat_i.values[:,np.newaxis]\n",
    "            yield x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-07T01:57:57.520549Z",
     "start_time": "2017-12-07T01:52:33.752Z"
    }
   },
   "outputs": [],
   "source": [
    "x.shape[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-07T01:57:57.521848Z",
     "start_time": "2017-12-07T01:52:33.755Z"
    }
   },
   "outputs": [],
   "source": [
    "dropout_prob = .4\n",
    "init_stddev = 0.01\n",
    "\n",
    "ff_layers = [\n",
    "    keras.layers.InputLayer(input_shape=x.shape[1:]),\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dropout(dropout_prob),\n",
    "    keras.layers.Dense(1000, activation=\"relu\"),\n",
    "    keras.layers.Dense(500, activation=\"relu\"),\n",
    "    keras.layers.Dropout(dropout_prob),\n",
    "\n",
    "    # Classification\n",
    "    keras.layers.Dense(\n",
    "        num_cat,\n",
    "        activation=\"softmax\",\n",
    "        kernel_initializer=keras.initializers.TruncatedNormal(\n",
    "            stddev=init_stddev)),\n",
    "]\n",
    "ff_model = keras.Sequential(ff_layers)\n",
    "ff_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-07T01:57:57.523357Z",
     "start_time": "2017-12-07T01:52:33.758Z"
    }
   },
   "outputs": [],
   "source": [
    "x.shape[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-07T01:57:57.524724Z",
     "start_time": "2017-12-07T01:52:33.761Z"
    }
   },
   "outputs": [],
   "source": [
    "dropout_prob = .4\n",
    "init_stddev = 0.01\n",
    "\n",
    "cnn_layers =[\n",
    "    keras.layers.InputLayer(input_shape=x.shape[1:]),\n",
    "\n",
    "    # Conv layer\n",
    "    keras.layers.Conv2D(\n",
    "        64,\n",
    "        kernel_size=(8, 20),\n",
    "        padding=\"same\",\n",
    "        activation=\"relu\",\n",
    "        kernel_initializer=keras.initializers.TruncatedNormal(\n",
    "            stddev=init_stddev)),\n",
    "    keras.layers.AvgPool2D(pool_size=(2, 2), padding=\"same\"),\n",
    "    keras.layers.Dropout(dropout_prob),\n",
    "    \n",
    "    # Conv layer\n",
    "    keras.layers.Conv2D(\n",
    "        64,\n",
    "        kernel_size=(4, 10),\n",
    "        padding=\"same\",\n",
    "        activation=\"relu\",\n",
    "        kernel_initializer=keras.initializers.TruncatedNormal(\n",
    "            stddev=init_stddev)),\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dropout(dropout_prob),\n",
    "\n",
    "\n",
    "    \n",
    "    # Class Layer 2\n",
    "    keras.layers.Dense(\n",
    "        num_cat,\n",
    "        activation=\"softmax\",\n",
    "        kernel_initializer=keras.initializers.TruncatedNormal(\n",
    "            stddev=init_stddev)),\n",
    "]\n",
    "cnn_layers = keras.Sequential(cnn_layers)\n",
    "cnn_layers.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-07T01:57:57.526126Z",
     "start_time": "2017-12-07T01:52:33.764Z"
    }
   },
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        filepath='weights.{epoch:02d}-{val_loss:.2f}.hdf5',\n",
    "        monitor='val_loss',\n",
    "        verbose=1,\n",
    "        save_best_only=False,\n",
    "        save_weights_only=False,\n",
    "        mode='auto',\n",
    "        period=1),\n",
    "    keras.callbacks.EarlyStopping(patience=4, verbose=1),\n",
    "    keras.callbacks.ReduceLROnPlateau(\n",
    "        factor=0.1, patience=2, verbose=1, min_lr=1e-6)\n",
    "]\n",
    "\n",
    "cnn_layers.compile(\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    optimizer=keras.optimizers.Nadam(lr=0.001),\n",
    "    metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-07T01:57:57.527659Z",
     "start_time": "2017-12-07T01:52:33.772Z"
    }
   },
   "outputs": [],
   "source": [
    "cnn_layers.fit(\n",
    "    x=np.concatenate((x,x_bg)),\n",
    "    y=np.concatenate((y,y)),\n",
    "    validation_data=(x_val, y_val),\n",
    "    epochs=100,\n",
    "    verbose=1,\n",
    "    callbacks=callbacks,\n",
    "    initial_epoch=0)\n",
    "\n",
    "# cnn_layers.fit_generator(\n",
    "#     generator=train_generator(\n",
    "#         batch_size=batch_size, shuffle=True, state=\"train\", maxlen=16000),\n",
    "#     steps_per_epoch=num_steps,\n",
    "#     epochs=100,\n",
    "#     verbose=1,\n",
    "#     callbacks=callbacks,\n",
    "#     validation_data=train_generator(\n",
    "#         batch_size=batch_size, shuffle=True, state=\"val\", maxlen=16000),\n",
    "#     validation_steps=val_steps,\n",
    "#     shuffle=False,\n",
    "#     initial_epoch=0,\n",
    "#     max_queue_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "428px",
    "left": "1068px",
    "right": "20px",
    "top": "118px",
    "width": "350px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
