{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-09T03:26:18.997052Z",
     "start_time": "2018-01-09T03:26:18.982667Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/IPython/core/magics/pylab.py:160: UserWarning: pylab import has clobbered these variables: ['arrow', 'random']\n",
      "`%matplotlib` prevents importing * from pylab and numpy\n",
      "  \"\\n`%matplotlib` prevents importing * from pylab and numpy\"\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "import keras\n",
    "import keras.backend as K\n",
    "import kapre\n",
    "import pandas as pd\n",
    "import scipy.io.wavfile as wav\n",
    "import numpy as np\n",
    "import random\n",
    "import arrow\n",
    "import threading\n",
    "import pprint\n",
    "from soph import ex_generator, center_wave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-09T03:26:19.936184Z",
     "start_time": "2018-01-09T03:26:19.818246Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation': 'elu',\n",
      " 'batch_normalize': True,\n",
      " 'batch_size': 512,\n",
      " 'cnn_pad': 'same',\n",
      " 'cnn_stack': 2,\n",
      " 'cnn_stride': 1,\n",
      " 'delta_delta': True,\n",
      " 'dropout_prob': 0.1,\n",
      " 'early_patience': 4,\n",
      " 'filters_start': 50,\n",
      " 'filters_step': 25,\n",
      " 'init': 'glorot_normal',\n",
      " 'init_param': 0.05,\n",
      " 'kernel_size': 10,\n",
      " 'l2_reg': 0.0005,\n",
      " 'lr_patience': 1,\n",
      " 'lr_step': 0.5,\n",
      " 'n_dft': 1024,\n",
      " 'n_hop': 160,\n",
      " 'n_mels': 80,\n",
      " 'n_mfcc': 40,\n",
      " 'p_transform': 1,\n",
      " 'pool': 'max',\n",
      " 'pool_pad': 'same',\n",
      " 'power_melgram': 2.0,\n",
      " 'regularize': True,\n",
      " 'return_decibel_melgram': True,\n",
      " 'shift': 1,\n",
      " 'train_state': ['train'],\n",
      " 'trainable_fb': False,\n",
      " 'trainable_kernel': False,\n",
      " 'val_state': ['val', 'test'],\n",
      " 'vol_range': 0.1}\n"
     ]
    }
   ],
   "source": [
    "ex_df = pd.read_pickle(\"data/ex_df.pkl\")\n",
    "\n",
    "src_args = {\n",
    "    \"dropout_prob\": .1,\n",
    "    \"activation\": \"elu\",\n",
    "    \"batch_size\": 512,\n",
    "    \"regularize\": True,\n",
    "    \"l2_reg\": 0.0005,\n",
    "    \"init\": \"glorot_normal\",                   # glorot, tnormal, lsuv\n",
    "    \"init_param\": 0.05,\n",
    "    \"filters_start\": 50,\n",
    "    \"filters_step\": 25,\n",
    "    \"kernel_size\": 10,\n",
    "    \"cnn_pad\": \"same\",\n",
    "    \"cnn_stride\": 1,\n",
    "    \"cnn_stack\": 2,\n",
    "    \"n_mfcc\": 40,\n",
    "    \"n_mels\": 80,\n",
    "    \"n_dft\": 1024,\n",
    "    \"n_hop\": 160,\n",
    "    \"pool\": \"max\",\n",
    "    \"pool_pad\": \"same\",\n",
    "    \"batch_normalize\": True,\n",
    "    \"train_state\": [\"train\"],\n",
    "    \"val_state\": [\"val\", \"test\"],\n",
    "    \"p_transform\": 1,\n",
    "    \"vol_range\": .1,\n",
    "    \"shift\": 1,\n",
    "    \"delta_delta\": True,\n",
    "    \"lr_step\": .5,\n",
    "    \"lr_patience\": 1,\n",
    "    \"power_melgram\": 2.0,\n",
    "    \"return_decibel_melgram\": True,\n",
    "    \"trainable_fb\": False,\n",
    "    \"trainable_kernel\": False,\n",
    "    \"early_patience\": 4\n",
    "}\n",
    "pprint.pprint(src_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-09T03:26:20.734920Z",
     "start_time": "2018-01-09T03:26:20.716527Z"
    }
   },
   "outputs": [],
   "source": [
    "num_cat = 12\n",
    "start_time = arrow.now()\n",
    "current_time = start_time.to('US/Eastern').format('YYYY-MM-DD-HH-mm')\n",
    "\n",
    "drop = src_args[\"dropout_prob\"]\n",
    "\n",
    "init = src_args[\"init\"]\n",
    "\n",
    "if init == None:\n",
    "    init = 'glorot_uniform'\n",
    "elif init == \"tnormal\":\n",
    "    init_param = src_args[\"init_param\"] if src_args[\"init_param\"] else 0.01\n",
    "    init = keras.initializers.TruncatedNormal(stddev=src_args[\"init_stdd\"])\n",
    "elif init == \"lsuv\":\n",
    "    init = keras.initializers.RandomNormal(stddev=1)\n",
    "\n",
    "if src_args[\"regularize\"]:\n",
    "    reg = keras.regularizers.l2(src_args[\"l2_reg\"])\n",
    "else:\n",
    "    reg = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-09T03:26:24.307999Z",
     "start_time": "2018-01-09T03:26:21.431960Z"
    }
   },
   "outputs": [],
   "source": [
    "input_layer = keras.layers.Input(shape=(1, 16000))\n",
    "input_block = kapre.time_frequency.MFCC(\n",
    "    n_mfcc=int(src_args[\"n_mfcc\"]),\n",
    "    n_mels=int(src_args[\"n_mels\"]),\n",
    "    n_dft=int(src_args[\"n_dft\"]),\n",
    "    n_hop=int(src_args[\"n_hop\"]),\n",
    "    power_melgram=src_args[\"power_melgram\"],\n",
    "    return_decibel_melgram=src_args[\"return_decibel_melgram\"],\n",
    "    trainable_kernel=src_args[\"trainable_kernel\"],\n",
    "    trainable_fb=src_args[\"trainable_fb\"],\n",
    ")(input_layer)\n",
    "if src_args[\"delta_delta\"]:\n",
    "    input_block = kapre.utils.DeltaDelta(n=2)(input_block)\n",
    "    input_block = keras.layers.Permute((1, 3, 2))(input_block)\n",
    "    input_block = keras.layers.Reshape((src_args[\"n_mfcc\"]*3*10,10))(input_block)\n",
    "else:\n",
    "    input_block = keras.layers.Permute((1, 3, 2))(input_block)\n",
    "    input_block = keras.layers.Reshape((src_args[\"n_mfcc\"]*10,10))(input_block)\n",
    "    \n",
    "input_block = keras.layers.Permute((2, 1))(input_block)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-09T03:26:25.235393Z",
     "start_time": "2018-01-09T03:26:25.232120Z"
    }
   },
   "outputs": [],
   "source": [
    "time = lambda x, y:  keras.layers.TimeDistributed(x)(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-09T03:30:49.402926Z",
     "start_time": "2018-01-09T03:30:48.232816Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:19: UserWarning: The `merge` function is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "/usr/local/lib/python3.5/dist-packages/keras/legacy/layers.py:458: UserWarning: The `Merge` layer is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "  name=name)\n"
     ]
    }
   ],
   "source": [
    "rnn_block = time(keras.layers.Dense(100, activation=src_args[\"activation\"]), input_block)\n",
    "rnn_block = time(keras.layers.BatchNormalization(), rnn_block)\n",
    "rnn_block = time(keras.layers.Dropout(drop), rnn_block)\n",
    "rnn_block = time(keras.layers.Dense(100, activation=src_args[\"activation\"]), rnn_block)\n",
    "rnn_block = time(keras.layers.BatchNormalization(), rnn_block)\n",
    "rnn_block = time(keras.layers.Dropout(drop), rnn_block)\n",
    "\n",
    "att_layer = keras.layers.Bidirectional(\n",
    "    keras.layers.GRU(\n",
    "        10,\n",
    "        activation=src_args[\"activation\"],\n",
    "        dropout=drop,\n",
    "        recurrent_dropout=drop,\n",
    "        return_sequences=True,\n",
    "#         return_state=True,\n",
    "    ), merge_mode='mul')(rnn_block)\n",
    "att_layer = keras.layers.BatchNormalization()(att_layer)\n",
    "\n",
    "rnn_block = keras.layers.merge((rnn_block, att_layer), concat_axis=2, mode='concat')\n",
    "\n",
    "rnn_block = keras.layers.Bidirectional(\n",
    "    keras.layers.GRU(\n",
    "        50,\n",
    "        activation=src_args[\"activation\"],\n",
    "        dropout=drop,\n",
    "        recurrent_dropout=drop,\n",
    "    ))(rnn_block)\n",
    "rnn_block = keras.layers.BatchNormalization()(rnn_block)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-09T03:30:50.114932Z",
     "start_time": "2018-01-09T03:30:50.109900Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None, 100]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn_block.shape.as_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-09T03:30:51.135190Z",
     "start_time": "2018-01-09T03:30:51.121291Z"
    }
   },
   "outputs": [],
   "source": [
    "output_layer = keras.layers.Dense(num_cat, activation=\"softmax\")(rnn_block)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-09T03:30:51.904261Z",
     "start_time": "2018-01-09T03:30:51.889445Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            (None, 1, 16000)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "mfcc_2 (MFCC)                   (None, 40, 100, 1)   1094864     input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "delta_delta_2 (DeltaDelta)      (None, 40, 100, 3)   5           mfcc_2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "permute_3 (Permute)             (None, 40, 3, 100)   0           delta_delta_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "reshape_2 (Reshape)             (None, 1200, 10)     0           permute_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "permute_4 (Permute)             (None, 10, 1200)     0           reshape_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_13 (TimeDistri (None, 10, 100)      120100      permute_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_14 (TimeDistri (None, 10, 100)      400         time_distributed_13[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_15 (TimeDistri (None, 10, 100)      0           time_distributed_14[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_16 (TimeDistri (None, 10, 100)      10100       time_distributed_15[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_17 (TimeDistri (None, 10, 100)      400         time_distributed_16[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_18 (TimeDistri (None, 10, 100)      0           time_distributed_17[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_13 (Bidirectional (None, 10, 10)       6660        time_distributed_18[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 10, 10)       40          bidirectional_13[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "merge_8 (Merge)                 (None, 10, 110)      0           time_distributed_18[0][0]        \n",
      "                                                                 batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_14 (Bidirectional (None, 100)          48300       merge_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 100)          400         bidirectional_14[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 12)           1212        batch_normalization_19[0][0]     \n",
      "==================================================================================================\n",
      "Total params: 1,282,481\n",
      "Trainable params: 186,992\n",
      "Non-trainable params: 1,095,489\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "rnn_model = keras.Model(inputs=input_layer, outputs=output_layer)\n",
    "rnn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-01-09T03:31:48.910Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "104/103 [==============================] - 47s 450ms/step - loss: 1.6673 - acc: 0.2732 - val_loss: 2.1272 - val_acc: 0.3821\n",
      "Epoch 2/200\n",
      "104/103 [==============================] - 40s 388ms/step - loss: 1.0711 - acc: 0.4521 - val_loss: 1.8747 - val_acc: 0.3865\n",
      "Epoch 3/200\n",
      "104/103 [==============================] - 41s 397ms/step - loss: 0.8916 - acc: 0.5349 - val_loss: 1.1124 - val_acc: 0.5392\n",
      "Epoch 4/200\n",
      "104/103 [==============================] - 41s 397ms/step - loss: 0.7931 - acc: 0.5836 - val_loss: 1.0387 - val_acc: 0.5816\n",
      "Epoch 5/200\n",
      "104/103 [==============================] - 41s 399ms/step - loss: 0.7277 - acc: 0.6071 - val_loss: 1.5160 - val_acc: 0.5196\n",
      "Epoch 6/200\n",
      "104/103 [==============================] - 41s 396ms/step - loss: 0.6969 - acc: 0.6194 - val_loss: 0.8754 - val_acc: 0.6845\n",
      "Epoch 7/200\n",
      "104/103 [==============================] - 41s 396ms/step - loss: 0.6472 - acc: 0.6483 - val_loss: 0.8089 - val_acc: 0.6628\n",
      "Epoch 8/200\n",
      "104/103 [==============================] - 41s 393ms/step - loss: 0.6261 - acc: 0.6542 - val_loss: 0.8811 - val_acc: 0.6920\n",
      "Epoch 9/200\n",
      "103/103 [============================>.] - ETA: 0s - loss: 0.5986 - acc: 0.6655\n",
      "Epoch 00009: reducing learning rate to 0.0010000000474974513.\n",
      "104/103 [==============================] - 42s 405ms/step - loss: 0.5990 - acc: 0.6661 - val_loss: 0.8151 - val_acc: 0.6480\n",
      "Epoch 10/200\n",
      "104/103 [==============================] - 41s 390ms/step - loss: 0.5542 - acc: 0.6812 - val_loss: 0.7183 - val_acc: 0.7309\n",
      "Epoch 11/200\n",
      "104/103 [==============================] - 41s 392ms/step - loss: 0.5315 - acc: 0.6929 - val_loss: 0.6893 - val_acc: 0.7084\n",
      "Epoch 12/200\n",
      "104/103 [==============================] - 40s 389ms/step - loss: 0.5223 - acc: 0.6991 - val_loss: 0.5332 - val_acc: 0.7521\n",
      "Epoch 13/200\n",
      "104/103 [==============================] - 40s 387ms/step - loss: 0.5103 - acc: 0.7070 - val_loss: 0.7641 - val_acc: 0.6753\n",
      "Epoch 14/200\n",
      "103/103 [============================>.] - ETA: 0s - loss: 0.5127 - acc: 0.7085\n",
      "Epoch 00014: reducing learning rate to 0.0005000000237487257.\n",
      "104/103 [==============================] - 41s 391ms/step - loss: 0.5141 - acc: 0.7079 - val_loss: 0.6522 - val_acc: 0.7539\n",
      "Epoch 15/200\n",
      "104/103 [==============================] - 40s 388ms/step - loss: 0.4814 - acc: 0.7199 - val_loss: 0.4785 - val_acc: 0.7613\n",
      "Epoch 16/200\n",
      " 69/103 [===================>..........] - ETA: 10s - loss: 0.4674 - acc: 0.7257"
     ]
    }
   ],
   "source": [
    "log_base = \"logs/rnn/{}/\".format(current_time)\n",
    "callbacks = [\n",
    "    keras.callbacks.TensorBoard(\n",
    "        log_dir=log_base + 'tb',\n",
    "        batch_size=src_args[\"batch_size\"],\n",
    "        histogram_freq=0,\n",
    "        write_grads=False,\n",
    "        write_images=True\n",
    "    ),\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        filepath=log_base + 'model-checkpoint.hdf5',\n",
    "        monitor='val_acc',\n",
    "        verbose=0,\n",
    "        save_best_only=True,\n",
    "        save_weights_only=False,\n",
    "        mode='auto',\n",
    "        period=1),\n",
    "    keras.callbacks.CSVLogger(log_base + 'training.log'),\n",
    "    keras.callbacks.EarlyStopping(\n",
    "        patience=src_args[\"early_patience\"], verbose=1),\n",
    "    keras.callbacks.ReduceLROnPlateau(\n",
    "        factor=src_args[\"lr_step\"], patience=src_args[\"lr_patience\"], verbose=1, min_lr=1e-7)\n",
    "]\n",
    "\n",
    "rnn_model.compile(\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    optimizer='nadam',\n",
    "    metrics=['accuracy'])\n",
    "\n",
    "\n",
    "def launchTensorBoard():\n",
    "    import os\n",
    "    os.system('pkill tensorboard')\n",
    "    os.system('tensorboard --logdir=' + log_base + 'tb')\n",
    "    return\n",
    "\n",
    "\n",
    "t = threading.Thread(target=launchTensorBoard, args=([]))\n",
    "t.start()\n",
    "\n",
    "val_data = next(ex_generator(\n",
    "    batch_size=sum(ex_df.state.isin(src_args[\"val_state\"])),\n",
    "    shuffle=False,\n",
    "    state=src_args[\"val_state\"],\n",
    "    vol_range=0,\n",
    "    displacement=0,\n",
    "    p_transform=0))\n",
    "\n",
    "traing_gen = ex_generator(\n",
    "    batch_size=src_args[\"batch_size\"],\n",
    "    shuffle=True,\n",
    "    state=src_args[\"train_state\"],\n",
    "    vol_range=src_args[\"vol_range\"],\n",
    "    shift=src_args[\"shift\"],\n",
    "    p_transform=src_args[\"p_transform\"])\n",
    "\n",
    "history = rnn_model.fit_generator(\n",
    "    generator=traing_gen,\n",
    "    steps_per_epoch=sum(ex_df.state.isin(\n",
    "        src_args[\"train_state\"])) / src_args[\"batch_size\"],\n",
    "    epochs=200,\n",
    "    verbose=1,\n",
    "    max_queue_size=100,\n",
    "    callbacks=callbacks,\n",
    "    validation_data=val_data\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-16T01:56:59.749577Z",
     "start_time": "2017-12-16T01:56:59.742438Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[1 2 3 4]\n",
      "  [1 2 3 4]\n",
      "  [1 2 3 4]\n",
      "  [1 2 3 4]\n",
      "  [1 2 3 4]\n",
      "  [1 2 3 4]]] (1, 6, 4)\n"
     ]
    }
   ],
   "source": [
    "a = array([\n",
    "    [1,2,3,4],\n",
    "    [1,2,3,4],\n",
    "    [1,2,3,4],\n",
    "    [1,2,3,4],\n",
    "    [1,2,3,4],\n",
    "    [1,2,3,4],\n",
    "])\n",
    "a = a.reshape(1,6,4)\n",
    "print(a,a.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-16T01:56:59.755751Z",
     "start_time": "2017-12-16T01:56:59.751287Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[1 2 3 4]\n",
      "  [1 2 3 4]]\n",
      "\n",
      " [[1 2 3 4]\n",
      "  [1 2 3 4]]\n",
      "\n",
      " [[1 2 3 4]\n",
      "  [1 2 3 4]]] (3, 2, 4)\n"
     ]
    }
   ],
   "source": [
    "b = a.reshape((3,-1,4))\n",
    "print(b,b.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-16T01:56:59.779870Z",
     "start_time": "2017-12-16T01:56:59.757584Z"
    }
   },
   "outputs": [],
   "source": [
    "input_block = [\n",
    "    keras.layers.InputLayer(input_shape=(1, maxlen)), # None, 1, 16000\n",
    "    kapre.time_frequency.Melspectrogram(\n",
    "            sr=16000,\n",
    "            n_mels=n_mels,\n",
    "            n_dft=256,\n",
    "            n_hop=int(n_hop),\n",
    "            power_melgram=2.0,\n",
    "            trainable_kernel=False,\n",
    "            return_decibel_melgram=True),             # None, n_mels, n_steps, 1\n",
    "    keras.layers.Permute((3,2,1)),                    # None, 1, n_steps, n_mels\n",
    "    keras.layers.Reshape((n_seq,-1,n_mels)),          # None, n_seq, n_steps, n_mels\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-16T01:56:59.794263Z",
     "start_time": "2017-12-16T01:56:59.781703Z"
    }
   },
   "outputs": [],
   "source": [
    "cnn_block = []\n",
    "\n",
    "for i, block in enumerate(src_args[\"cnn_blocks\"]):\n",
    "    for n, k in block:\n",
    "        cnn_block.extend([\n",
    "            keras.layers.TimeDistributed(\n",
    "                keras.layers.Conv1D(\n",
    "                    n,\n",
    "                    kernel_size=k,\n",
    "                    padding=\"same\",\n",
    "                    activation=act,\n",
    "                    kernel_initializer=init)),\n",
    "            keras.layers.TimeDistributed(keras.layers.BatchNormalization()),\n",
    "        ])\n",
    "    cnn_block.extend([\n",
    "        keras.layers.TimeDistributed(\n",
    "            keras.layers.MaxPooling1D(pool_size=2, padding='same')),\n",
    "        keras.layers.TimeDistributed(keras.layers.Dropout(drop)),\n",
    "    ])\n",
    "\n",
    "cnn_block.append(keras.layers.TimeDistributed(keras.layers.Flatten()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-16T01:57:00.867268Z",
     "start_time": "2017-12-16T01:56:59.796103Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 1, 16000)          0         \n",
      "_________________________________________________________________\n",
      "melspectrogram_1 (Melspectro (None, 40, 160, 1)        71208     \n",
      "_________________________________________________________________\n",
      "permute_1 (Permute)          (None, 1, 160, 40)        0         \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 16, 10, 40)        0         \n",
      "_________________________________________________________________\n",
      "time_distributed_1 (TimeDist (None, 16, 10, 128)       15488     \n",
      "_________________________________________________________________\n",
      "time_distributed_2 (TimeDist (None, 16, 10, 128)       512       \n",
      "_________________________________________________________________\n",
      "time_distributed_3 (TimeDist (None, 16, 5, 128)        0         \n",
      "_________________________________________________________________\n",
      "time_distributed_4 (TimeDist (None, 16, 5, 128)        0         \n",
      "_________________________________________________________________\n",
      "time_distributed_5 (TimeDist (None, 16, 5, 128)        49280     \n",
      "_________________________________________________________________\n",
      "time_distributed_6 (TimeDist (None, 16, 5, 128)        512       \n",
      "_________________________________________________________________\n",
      "time_distributed_7 (TimeDist (None, 16, 3, 128)        0         \n",
      "_________________________________________________________________\n",
      "time_distributed_8 (TimeDist (None, 16, 3, 128)        0         \n",
      "_________________________________________________________________\n",
      "time_distributed_9 (TimeDist (None, 16, 3, 128)        49280     \n",
      "_________________________________________________________________\n",
      "time_distributed_10 (TimeDis (None, 16, 3, 128)        512       \n",
      "_________________________________________________________________\n",
      "time_distributed_11 (TimeDis (None, 16, 2, 128)        0         \n",
      "_________________________________________________________________\n",
      "time_distributed_12 (TimeDis (None, 16, 2, 128)        0         \n",
      "_________________________________________________________________\n",
      "time_distributed_13 (TimeDis (None, 16, 2, 128)        49280     \n",
      "_________________________________________________________________\n",
      "time_distributed_14 (TimeDis (None, 16, 2, 128)        512       \n",
      "_________________________________________________________________\n",
      "time_distributed_15 (TimeDis (None, 16, 1, 128)        0         \n",
      "_________________________________________________________________\n",
      "time_distributed_16 (TimeDis (None, 16, 1, 128)        0         \n",
      "_________________________________________________________________\n",
      "time_distributed_17 (TimeDis (None, 16, 128)           0         \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 256)               197376    \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 12)                3084      \n",
      "=================================================================\n",
      "Total params: 438,068\n",
      "Trainable params: 365,324\n",
      "Non-trainable params: 72,744\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "rnn_cnn_model = keras.Sequential(input_block + \n",
    "                                 cnn_block + \n",
    "[\n",
    "    keras.layers.Bidirectional(\n",
    "        keras.layers.GRU(\n",
    "            128,\n",
    "            activation=act,\n",
    "            dropout=drop,\n",
    "            recurrent_dropout=drop)),\n",
    "    keras.layers.BatchNormalization(),\n",
    "#     keras.layers.Dropout(drop),\n",
    "    keras.layers.Dense(num_cat, activation=\"softmax\"),\n",
    "])\n",
    "rnn_cnn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-16T01:57:11.530143Z",
     "start_time": "2017-12-16T01:57:00.869165Z"
    }
   },
   "outputs": [],
   "source": [
    "log_base = \"logs/rnn_cnn/{}/\".format(current_time)\n",
    "callbacks = [\n",
    "    keras.callbacks.TensorBoard(\n",
    "        log_dir= log_base+'tb',\n",
    "        histogram_freq=0,\n",
    "        batch_size=src_args[\"batch_size\"],\n",
    "        write_graph=True,\n",
    "        write_grads=True,\n",
    "        write_images=True,\n",
    "    ),\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        filepath=log_base+'model-checkpoint.hdf5',\n",
    "        monitor='val_loss',\n",
    "        verbose=1,\n",
    "        save_best_only=True,\n",
    "        save_weights_only=False,\n",
    "        mode='auto',\n",
    "        period=1),\n",
    "    keras.callbacks.CSVLogger(log_base+'training.log'),\n",
    "    keras.callbacks.EarlyStopping(patience=10, verbose=1),\n",
    "    keras.callbacks.ReduceLROnPlateau(\n",
    "        factor=0.5, patience=1, verbose=1, min_lr=1e-8)\n",
    "]\n",
    "\n",
    "rnn_cnn_model.compile(\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    optimizer='nadam',\n",
    "    metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-16T01:57:11.546792Z",
     "start_time": "2017-12-16T01:57:11.531984Z"
    }
   },
   "outputs": [],
   "source": [
    "def launchTensorBoard():\n",
    "    import os\n",
    "    os.system('pkill tensorboard')\n",
    "    os.system('tensorboard --logdir=' + log_base+'tb')\n",
    "    return\n",
    "\n",
    "import threading\n",
    "t = threading.Thread(target=launchTensorBoard, args=([]))\n",
    "t.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-16T01:57:13.898824Z",
     "start_time": "2017-12-16T01:57:11.549779Z"
    }
   },
   "outputs": [],
   "source": [
    "val_data = next(ex_generator(\n",
    "        batch_size=sum(ex_df.state.isin(src_args[\"val_state\"])),\n",
    "        shuffle=False,\n",
    "        state=src_args[\"val_state\"],\n",
    "        vol_range=0,\n",
    "        displacement=0,\n",
    "        p_transform=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-16T02:06:21.016503Z",
     "start_time": "2017-12-16T01:57:13.900754Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "826/826 [============================>.] - ETA: 0s - loss: 2.2449 - acc: 0.1491Epoch 00001: val_loss improved from inf to 1.73895, saving model to logs/rnn_cnn/2017-12-15-20-56/model-checkpoint.hdf5\n",
      "827/826 [==============================] - 76s 92ms/step - loss: 2.2445 - acc: 0.1493 - val_loss: 1.7390 - val_acc: 0.3637\n",
      "Epoch 2/200\n",
      "826/826 [============================>.] - ETA: 0s - loss: 1.7774 - acc: 0.2536Epoch 00002: val_loss did not improve\n",
      "827/826 [==============================] - 73s 89ms/step - loss: 1.7779 - acc: 0.2535 - val_loss: 2.1118 - val_acc: 0.1499\n",
      "Epoch 3/200\n",
      "826/826 [============================>.] - ETA: 0s - loss: 2.4347 - acc: 0.0887Epoch 00003: val_loss did not improve\n",
      "\n",
      "Epoch 00003: reducing learning rate to 0.0010000000474974513.\n",
      "827/826 [==============================] - 74s 89ms/step - loss: 2.4354 - acc: 0.0886 - val_loss: 2.5258 - val_acc: 0.0361\n",
      "Epoch 4/200\n",
      "826/826 [============================>.] - ETA: 0s - loss: 2.4232 - acc: 0.0654Epoch 00004: val_loss did not improve\n",
      "\n",
      "Epoch 00004: reducing learning rate to 0.0005000000237487257.\n",
      "827/826 [==============================] - 74s 89ms/step - loss: 2.4245 - acc: 0.0656 - val_loss: 2.5347 - val_acc: 0.0812\n",
      "Epoch 5/200\n",
      "826/826 [============================>.] - ETA: 0s - loss: 2.4121 - acc: 0.0674Epoch 00005: val_loss did not improve\n",
      "\n",
      "Epoch 00005: reducing learning rate to 0.0002500000118743628.\n",
      "827/826 [==============================] - 74s 90ms/step - loss: 2.4115 - acc: 0.0673 - val_loss: 2.5385 - val_acc: 0.0429\n",
      "Epoch 6/200\n",
      "826/826 [============================>.] - ETA: 0s - loss: 2.4028 - acc: 0.0718Epoch 00006: val_loss did not improve\n",
      "\n",
      "Epoch 00006: reducing learning rate to 0.0001250000059371814.\n",
      "827/826 [==============================] - 74s 90ms/step - loss: 2.4038 - acc: 0.0718 - val_loss: 2.5298 - val_acc: 0.4610\n",
      "Epoch 7/200\n",
      "826/826 [============================>.] - ETA: 0s - loss: 2.3983 - acc: 0.0673Epoch 00007: val_loss did not improve\n",
      "\n",
      "Epoch 00007: reducing learning rate to 6.25000029685907e-05.\n",
      "827/826 [==============================] - 74s 89ms/step - loss: 2.3982 - acc: 0.0672 - val_loss: 2.5383 - val_acc: 0.5958\n",
      "Epoch 8/200\n",
      "274/826 [========>.....................] - ETA: 45s - loss: 2.4075 - acc: 0.0791"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-1625da0eb0c4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m )\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     85\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     86\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 87\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/models.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1225\u001b[0m                                         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1226\u001b[0m                                         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1227\u001b[0;31m                                         initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1228\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1229\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     85\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     86\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 87\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   2145\u001b[0m                     outs = self.train_on_batch(x, y,\n\u001b[1;32m   2146\u001b[0m                                                \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2147\u001b[0;31m                                                class_weight=class_weight)\n\u001b[0m\u001b[1;32m   2148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2149\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1837\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1838\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1839\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1840\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1841\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2355\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2356\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2357\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2358\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    893\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 895\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    896\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1122\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1124\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1125\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1126\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1319\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1321\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1322\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1323\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1325\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1327\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1328\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1329\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1304\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1305\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1306\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1307\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1308\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "rnn_cnn_model.fit_generator(\n",
    "    generator=ex_generator(\n",
    "        batch_size=src_args[\"batch_size\"],\n",
    "        shuffle=True,\n",
    "        state=src_args[\"train_state\"],\n",
    "        shift=src_args[\"shift\"],\n",
    "        vol_range=src_args[\"vol_range\"],\n",
    "        displacement=src_args[\"displacement\"],\n",
    "        p_transform=src_args[\"p_transform\"]),\n",
    "    steps_per_epoch=sum(ex_df.state.isin(src_args[\"train_state\"])) / src_args[\"batch_size\"],\n",
    "    epochs=200,\n",
    "    verbose=1,\n",
    "    max_queue_size=100,\n",
    "    callbacks=callbacks,\n",
    "    validation_data=val_data\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
