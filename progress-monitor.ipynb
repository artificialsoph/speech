{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-08T17:25:53.015820Z",
     "start_time": "2018-01-08T17:25:53.007026Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/IPython/core/magics/pylab.py:160: UserWarning: pylab import has clobbered these variables: ['f']\n",
      "`%matplotlib` prevents importing * from pylab and numpy\n",
      "  \"\\n`%matplotlib` prevents importing * from pylab and numpy\"\n"
     ]
    }
   ],
   "source": [
    "import pandas\n",
    "import seaborn\n",
    "%pylab inline\n",
    "seaborn.set_style(\"whitegrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-08T21:05:14.079488Z",
     "start_time": "2018-01-08T21:05:14.068606Z"
    }
   },
   "outputs": [],
   "source": [
    "runs = []\n",
    "with open(\"logs/cnn-log\") as f:\n",
    "    runs_text = f.readlines()\n",
    "runs = [eval(r) for r in runs_text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-08T21:05:14.694208Z",
     "start_time": "2018-01-08T21:05:14.685369Z"
    }
   },
   "outputs": [],
   "source": [
    "runs_df = pandas.DataFrame(runs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-08T21:05:15.332592Z",
     "start_time": "2018-01-08T21:05:15.209720Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>11</th>\n",
       "      <th>26</th>\n",
       "      <th>14</th>\n",
       "      <th>4</th>\n",
       "      <th>8</th>\n",
       "      <th>13</th>\n",
       "      <th>20</th>\n",
       "      <th>25</th>\n",
       "      <th>16</th>\n",
       "      <th>15</th>\n",
       "      <th>...</th>\n",
       "      <th>9</th>\n",
       "      <th>3</th>\n",
       "      <th>1</th>\n",
       "      <th>5</th>\n",
       "      <th>0</th>\n",
       "      <th>23</th>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <th>12</th>\n",
       "      <th>19</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>activation</th>\n",
       "      <td>elu</td>\n",
       "      <td>elu</td>\n",
       "      <td>elu</td>\n",
       "      <td>elu</td>\n",
       "      <td>elu</td>\n",
       "      <td>elu</td>\n",
       "      <td>elu</td>\n",
       "      <td>elu</td>\n",
       "      <td>elu</td>\n",
       "      <td>elu</td>\n",
       "      <td>...</td>\n",
       "      <td>elu</td>\n",
       "      <td>elu</td>\n",
       "      <td>elu</td>\n",
       "      <td>elu</td>\n",
       "      <td>elu</td>\n",
       "      <td>elu</td>\n",
       "      <td>elu</td>\n",
       "      <td>elu</td>\n",
       "      <td>elu</td>\n",
       "      <td>elu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>batch_normalize</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>batch_size</th>\n",
       "      <td>128</td>\n",
       "      <td>512</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>64</td>\n",
       "      <td>512</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>...</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>64</td>\n",
       "      <td>128</td>\n",
       "      <td>512</td>\n",
       "      <td>128</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cnn_pad</th>\n",
       "      <td>same</td>\n",
       "      <td>same</td>\n",
       "      <td>same</td>\n",
       "      <td>same</td>\n",
       "      <td>same</td>\n",
       "      <td>same</td>\n",
       "      <td>same</td>\n",
       "      <td>same</td>\n",
       "      <td>same</td>\n",
       "      <td>same</td>\n",
       "      <td>...</td>\n",
       "      <td>same</td>\n",
       "      <td>same</td>\n",
       "      <td>same</td>\n",
       "      <td>same</td>\n",
       "      <td>same</td>\n",
       "      <td>same</td>\n",
       "      <td>same</td>\n",
       "      <td>same</td>\n",
       "      <td>same</td>\n",
       "      <td>same</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cnn_stack</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cnn_stride</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>current_time</th>\n",
       "      <td>2018-01-06-00-47</td>\n",
       "      <td>2018-01-08-13-50</td>\n",
       "      <td>2018-01-06-12-01</td>\n",
       "      <td>2018-01-05-18-40</td>\n",
       "      <td>2018-01-05-21-44</td>\n",
       "      <td>2018-01-06-10-46</td>\n",
       "      <td>2018-01-07-20-36</td>\n",
       "      <td>2018-01-08-12-35</td>\n",
       "      <td>2018-01-06-23-16</td>\n",
       "      <td>2018-01-06-16-53</td>\n",
       "      <td>...</td>\n",
       "      <td>2018-01-05-23-52</td>\n",
       "      <td>2018-01-05-18-05</td>\n",
       "      <td>2018-01-05-14-21</td>\n",
       "      <td>2018-01-05-19-42</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-01-08-10-32</td>\n",
       "      <td>2018-01-05-17-41</td>\n",
       "      <td>2018-01-08-11-56</td>\n",
       "      <td>2018-01-06-10-17</td>\n",
       "      <td>2018-01-07-11-45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>delta_delta</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dropout_prob</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.15</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>early_patience</th>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>elapsed</th>\n",
       "      <td>3047</td>\n",
       "      <td>3081</td>\n",
       "      <td>5186</td>\n",
       "      <td>2958</td>\n",
       "      <td>4538</td>\n",
       "      <td>3099</td>\n",
       "      <td>4061</td>\n",
       "      <td>1593</td>\n",
       "      <td>3133</td>\n",
       "      <td>11757</td>\n",
       "      <td>...</td>\n",
       "      <td>1385</td>\n",
       "      <td>1802</td>\n",
       "      <td>8094</td>\n",
       "      <td>1944</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1459</td>\n",
       "      <td>1008</td>\n",
       "      <td>1011</td>\n",
       "      <td>1425</td>\n",
       "      <td>659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>end_time</th>\n",
       "      <td>2018-01-06-01-38</td>\n",
       "      <td>2018-01-08-14-41</td>\n",
       "      <td>2018-01-06-13-28</td>\n",
       "      <td>2018-01-05-19-30</td>\n",
       "      <td>2018-01-05-22-59</td>\n",
       "      <td>2018-01-06-11-38</td>\n",
       "      <td>2018-01-07-21-44</td>\n",
       "      <td>2018-01-08-13-01</td>\n",
       "      <td>2018-01-07-00-08</td>\n",
       "      <td>2018-01-06-20-09</td>\n",
       "      <td>...</td>\n",
       "      <td>2018-01-06-00-15</td>\n",
       "      <td>2018-01-05-18-35</td>\n",
       "      <td>2018-01-05-16-35</td>\n",
       "      <td>2018-01-05-20-14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-01-08-10-56</td>\n",
       "      <td>2018-01-05-17-58</td>\n",
       "      <td>2018-01-08-12-13</td>\n",
       "      <td>2018-01-06-10-41</td>\n",
       "      <td>2018-01-07-11-56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>epoch_dur</th>\n",
       "      <td>70.8605</td>\n",
       "      <td>81.0789</td>\n",
       "      <td>117.864</td>\n",
       "      <td>NaN</td>\n",
       "      <td>90.76</td>\n",
       "      <td>70.4318</td>\n",
       "      <td>116.029</td>\n",
       "      <td>56.8929</td>\n",
       "      <td>130.542</td>\n",
       "      <td>132.101</td>\n",
       "      <td>...</td>\n",
       "      <td>53.2692</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>62.7097</td>\n",
       "      <td>NaN</td>\n",
       "      <td>42.9118</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37.4444</td>\n",
       "      <td>71.25</td>\n",
       "      <td>94.1429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>epochs</th>\n",
       "      <td>43</td>\n",
       "      <td>38</td>\n",
       "      <td>44</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50</td>\n",
       "      <td>44</td>\n",
       "      <td>35</td>\n",
       "      <td>28</td>\n",
       "      <td>24</td>\n",
       "      <td>89</td>\n",
       "      <td>...</td>\n",
       "      <td>26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27</td>\n",
       "      <td>20</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>filters_start</th>\n",
       "      <td>50</td>\n",
       "      <td>40</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>60</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>40</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>...</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>50</td>\n",
       "      <td>40</td>\n",
       "      <td>30</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>filters_step</th>\n",
       "      <td>25</td>\n",
       "      <td>20</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>60</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>20</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>...</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>50</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>init</th>\n",
       "      <td>NaN</td>\n",
       "      <td>glorot_normal</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>lsuv</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>lsuv</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>init_param</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>init_stdd</th>\n",
       "      <td>0.01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>...</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kernel_size</th>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>l2_reg</th>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lr_patience</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lr_step</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n_dft</th>\n",
       "      <td>512</td>\n",
       "      <td>512</td>\n",
       "      <td>512</td>\n",
       "      <td>512</td>\n",
       "      <td>512</td>\n",
       "      <td>512</td>\n",
       "      <td>512</td>\n",
       "      <td>1024</td>\n",
       "      <td>512</td>\n",
       "      <td>512</td>\n",
       "      <td>...</td>\n",
       "      <td>512</td>\n",
       "      <td>512</td>\n",
       "      <td>256</td>\n",
       "      <td>512</td>\n",
       "      <td>256</td>\n",
       "      <td>1024</td>\n",
       "      <td>1024</td>\n",
       "      <td>1024</td>\n",
       "      <td>512</td>\n",
       "      <td>512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n_hop</th>\n",
       "      <td>256</td>\n",
       "      <td>256</td>\n",
       "      <td>256</td>\n",
       "      <td>256</td>\n",
       "      <td>256</td>\n",
       "      <td>256</td>\n",
       "      <td>256</td>\n",
       "      <td>512</td>\n",
       "      <td>256</td>\n",
       "      <td>256</td>\n",
       "      <td>...</td>\n",
       "      <td>256</td>\n",
       "      <td>256</td>\n",
       "      <td>128</td>\n",
       "      <td>256</td>\n",
       "      <td>128</td>\n",
       "      <td>512</td>\n",
       "      <td>512</td>\n",
       "      <td>512</td>\n",
       "      <td>256</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n_mels</th>\n",
       "      <td>80</td>\n",
       "      <td>126</td>\n",
       "      <td>120</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>126</td>\n",
       "      <td>64</td>\n",
       "      <td>120</td>\n",
       "      <td>120</td>\n",
       "      <td>...</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>250</td>\n",
       "      <td>80</td>\n",
       "      <td>120</td>\n",
       "      <td>64</td>\n",
       "      <td>80</td>\n",
       "      <td>64</td>\n",
       "      <td>80</td>\n",
       "      <td>126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n_mfcc</th>\n",
       "      <td>40</td>\n",
       "      <td>63</td>\n",
       "      <td>60</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>63</td>\n",
       "      <td>32</td>\n",
       "      <td>60</td>\n",
       "      <td>60</td>\n",
       "      <td>...</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>125</td>\n",
       "      <td>40</td>\n",
       "      <td>125</td>\n",
       "      <td>32</td>\n",
       "      <td>40</td>\n",
       "      <td>32</td>\n",
       "      <td>40</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p_transform</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pool</th>\n",
       "      <td>max</td>\n",
       "      <td>max</td>\n",
       "      <td>max</td>\n",
       "      <td>max</td>\n",
       "      <td>max</td>\n",
       "      <td>max</td>\n",
       "      <td>max</td>\n",
       "      <td>max</td>\n",
       "      <td>max</td>\n",
       "      <td>max</td>\n",
       "      <td>...</td>\n",
       "      <td>max</td>\n",
       "      <td>max</td>\n",
       "      <td>max</td>\n",
       "      <td>max</td>\n",
       "      <td>max</td>\n",
       "      <td>avg</td>\n",
       "      <td>max</td>\n",
       "      <td>max</td>\n",
       "      <td>max</td>\n",
       "      <td>max</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pool_pad</th>\n",
       "      <td>same</td>\n",
       "      <td>same</td>\n",
       "      <td>same</td>\n",
       "      <td>same</td>\n",
       "      <td>same</td>\n",
       "      <td>same</td>\n",
       "      <td>same</td>\n",
       "      <td>same</td>\n",
       "      <td>same</td>\n",
       "      <td>same</td>\n",
       "      <td>...</td>\n",
       "      <td>same</td>\n",
       "      <td>same</td>\n",
       "      <td>same</td>\n",
       "      <td>same</td>\n",
       "      <td>same</td>\n",
       "      <td>same</td>\n",
       "      <td>same</td>\n",
       "      <td>same</td>\n",
       "      <td>same</td>\n",
       "      <td>same</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>power_melgram</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>regularize</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>return_decibel_melgram</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shift</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_acc</th>\n",
       "      <td>0.949005</td>\n",
       "      <td>0.94373</td>\n",
       "      <td>0.945092</td>\n",
       "      <td>0.939022</td>\n",
       "      <td>0.937717</td>\n",
       "      <td>0.941442</td>\n",
       "      <td>0.933231</td>\n",
       "      <td>0.938814</td>\n",
       "      <td>0.935864</td>\n",
       "      <td>0.928642</td>\n",
       "      <td>...</td>\n",
       "      <td>0.923196</td>\n",
       "      <td>0.920568</td>\n",
       "      <td>0.929209</td>\n",
       "      <td>0.927299</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.906576</td>\n",
       "      <td>0.885683</td>\n",
       "      <td>0.872674</td>\n",
       "      <td>0.625548</td>\n",
       "      <td>0.615452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_loss</th>\n",
       "      <td>0.200943</td>\n",
       "      <td>0.216248</td>\n",
       "      <td>0.226688</td>\n",
       "      <td>0.24595</td>\n",
       "      <td>0.256859</td>\n",
       "      <td>0.223383</td>\n",
       "      <td>0.123511</td>\n",
       "      <td>0.248933</td>\n",
       "      <td>0.11611</td>\n",
       "      <td>0.21844</td>\n",
       "      <td>...</td>\n",
       "      <td>0.260596</td>\n",
       "      <td>0.241976</td>\n",
       "      <td>0.228661</td>\n",
       "      <td>0.25069</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.16299</td>\n",
       "      <td>0.326288</td>\n",
       "      <td>0.22116</td>\n",
       "      <td>0.88137</td>\n",
       "      <td>6.3797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_state</th>\n",
       "      <td>[train]</td>\n",
       "      <td>[train]</td>\n",
       "      <td>[train]</td>\n",
       "      <td>[train]</td>\n",
       "      <td>[train]</td>\n",
       "      <td>[train]</td>\n",
       "      <td>[train, test]</td>\n",
       "      <td>[train]</td>\n",
       "      <td>[train]</td>\n",
       "      <td>[train]</td>\n",
       "      <td>...</td>\n",
       "      <td>[train]</td>\n",
       "      <td>[train]</td>\n",
       "      <td>[train]</td>\n",
       "      <td>[train]</td>\n",
       "      <td>[train]</td>\n",
       "      <td>[train]</td>\n",
       "      <td>[train]</td>\n",
       "      <td>[train]</td>\n",
       "      <td>[train]</td>\n",
       "      <td>[train]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trainable_fb</th>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trainable_kernel</th>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>val_acc</th>\n",
       "      <td>0.962481</td>\n",
       "      <td>0.958666</td>\n",
       "      <td>0.958525</td>\n",
       "      <td>0.958313</td>\n",
       "      <td>0.957324</td>\n",
       "      <td>0.956829</td>\n",
       "      <td>0.954661</td>\n",
       "      <td>0.954144</td>\n",
       "      <td>0.953791</td>\n",
       "      <td>0.953649</td>\n",
       "      <td>...</td>\n",
       "      <td>0.948703</td>\n",
       "      <td>0.948492</td>\n",
       "      <td>0.947432</td>\n",
       "      <td>0.94616</td>\n",
       "      <td>0.940366</td>\n",
       "      <td>0.936197</td>\n",
       "      <td>0.920441</td>\n",
       "      <td>0.919522</td>\n",
       "      <td>0.61676</td>\n",
       "      <td>0.599802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>val_loss</th>\n",
       "      <td>0.233833</td>\n",
       "      <td>0.247485</td>\n",
       "      <td>0.266385</td>\n",
       "      <td>0.267767</td>\n",
       "      <td>0.283327</td>\n",
       "      <td>0.25919</td>\n",
       "      <td>0.143841</td>\n",
       "      <td>0.291373</td>\n",
       "      <td>0.140824</td>\n",
       "      <td>0.222573</td>\n",
       "      <td>...</td>\n",
       "      <td>0.263299</td>\n",
       "      <td>0.244494</td>\n",
       "      <td>0.269057</td>\n",
       "      <td>0.265458</td>\n",
       "      <td>0.302892</td>\n",
       "      <td>0.167513</td>\n",
       "      <td>0.307334</td>\n",
       "      <td>0.173672</td>\n",
       "      <td>1.58544</td>\n",
       "      <td>15.2463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>val_state</th>\n",
       "      <td>[val, test]</td>\n",
       "      <td>[val, test]</td>\n",
       "      <td>[val, test]</td>\n",
       "      <td>[val, test]</td>\n",
       "      <td>[val, test]</td>\n",
       "      <td>[val, test]</td>\n",
       "      <td>[val]</td>\n",
       "      <td>[val, test]</td>\n",
       "      <td>[val, test]</td>\n",
       "      <td>[val, test]</td>\n",
       "      <td>...</td>\n",
       "      <td>[val, test]</td>\n",
       "      <td>[val, test]</td>\n",
       "      <td>[val, test]</td>\n",
       "      <td>[val, test]</td>\n",
       "      <td>[val, test]</td>\n",
       "      <td>[val, test]</td>\n",
       "      <td>[val, test]</td>\n",
       "      <td>[val, test]</td>\n",
       "      <td>[val, test]</td>\n",
       "      <td>[val, test]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vol_range</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>43 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      11                26                14  \\\n",
       "activation                           elu               elu               elu   \n",
       "batch_normalize                     True              True              True   \n",
       "batch_size                           128               512               128   \n",
       "cnn_pad                             same              same              same   \n",
       "cnn_stack                            NaN                 1               NaN   \n",
       "cnn_stride                             1                 1                 1   \n",
       "current_time            2018-01-06-00-47  2018-01-08-13-50  2018-01-06-12-01   \n",
       "delta_delta                         True              True              True   \n",
       "dropout_prob                         0.1               0.1               0.1   \n",
       "early_patience                       NaN                 5               NaN   \n",
       "elapsed                             3047              3081              5186   \n",
       "end_time                2018-01-06-01-38  2018-01-08-14-41  2018-01-06-13-28   \n",
       "epoch_dur                        70.8605           81.0789           117.864   \n",
       "epochs                                43                38                44   \n",
       "filters_start                         50                40                50   \n",
       "filters_step                          25                20                50   \n",
       "init                                 NaN     glorot_normal               NaN   \n",
       "init_param                           NaN              0.05               NaN   \n",
       "init_stdd                           0.01               NaN              0.01   \n",
       "kernel_size                           10                10                10   \n",
       "l2_reg                            0.0005            0.0005            0.0005   \n",
       "lr_patience                            2                 1                 2   \n",
       "lr_step                              0.2               0.5               0.2   \n",
       "n_dft                                512               512               512   \n",
       "n_hop                                256               256               256   \n",
       "n_mels                                80               126               120   \n",
       "n_mfcc                                40                63                60   \n",
       "p_transform                            1                 1                 1   \n",
       "pool                                 max               max               max   \n",
       "pool_pad                            same              same              same   \n",
       "power_melgram                          2                 2                 2   \n",
       "regularize                          True              True              True   \n",
       "return_decibel_melgram              True              True              True   \n",
       "shift                                  1                 1                 1   \n",
       "train_acc                       0.949005           0.94373          0.945092   \n",
       "train_loss                      0.200943          0.216248          0.226688   \n",
       "train_state                      [train]           [train]           [train]   \n",
       "trainable_fb                         NaN             False               NaN   \n",
       "trainable_kernel                     NaN             False               NaN   \n",
       "val_acc                         0.962481          0.958666          0.958525   \n",
       "val_loss                        0.233833          0.247485          0.266385   \n",
       "val_state                    [val, test]       [val, test]       [val, test]   \n",
       "vol_range                            0.1               0.1               0.1   \n",
       "\n",
       "                                      4                 8                 13  \\\n",
       "activation                           elu               elu               elu   \n",
       "batch_normalize                     True              True              True   \n",
       "batch_size                           128               128               128   \n",
       "cnn_pad                             same              same              same   \n",
       "cnn_stack                            NaN               NaN               NaN   \n",
       "cnn_stride                             1                 1                 1   \n",
       "current_time            2018-01-05-18-40  2018-01-05-21-44  2018-01-06-10-46   \n",
       "delta_delta                          NaN               NaN              True   \n",
       "dropout_prob                         0.1               0.2               0.1   \n",
       "early_patience                       NaN               NaN               NaN   \n",
       "elapsed                             2958              4538              3099   \n",
       "end_time                2018-01-05-19-30  2018-01-05-22-59  2018-01-06-11-38   \n",
       "epoch_dur                            NaN             90.76           70.4318   \n",
       "epochs                               NaN                50                44   \n",
       "filters_start                         50                60                50   \n",
       "filters_step                          50                60                25   \n",
       "init                                 NaN               NaN               NaN   \n",
       "init_param                           NaN               NaN               NaN   \n",
       "init_stdd                           0.01              0.01              0.01   \n",
       "kernel_size                           10                10                10   \n",
       "l2_reg                            0.0005            0.0005            0.0005   \n",
       "lr_patience                          NaN               NaN                 2   \n",
       "lr_step                              NaN               NaN               0.2   \n",
       "n_dft                                512               512               512   \n",
       "n_hop                                256               256               256   \n",
       "n_mels                                80                80                80   \n",
       "n_mfcc                                40                40                40   \n",
       "p_transform                            1                 1                 1   \n",
       "pool                                 max               max               max   \n",
       "pool_pad                            same              same              same   \n",
       "power_melgram                        NaN               NaN                 1   \n",
       "regularize                          True              True              True   \n",
       "return_decibel_melgram               NaN               NaN              True   \n",
       "shift                                  1                 1                 1   \n",
       "train_acc                       0.939022          0.937717          0.941442   \n",
       "train_loss                       0.24595          0.256859          0.223383   \n",
       "train_state                      [train]           [train]           [train]   \n",
       "trainable_fb                         NaN               NaN               NaN   \n",
       "trainable_kernel                     NaN               NaN               NaN   \n",
       "val_acc                         0.958313          0.957324          0.956829   \n",
       "val_loss                        0.267767          0.283327           0.25919   \n",
       "val_state                    [val, test]       [val, test]       [val, test]   \n",
       "vol_range                            0.1               0.1               0.1   \n",
       "\n",
       "                                      20                25                16  \\\n",
       "activation                           elu               elu               elu   \n",
       "batch_normalize                     True              True              True   \n",
       "batch_size                            64               512                64   \n",
       "cnn_pad                             same              same              same   \n",
       "cnn_stack                            NaN                 2               NaN   \n",
       "cnn_stride                             1                 1                 1   \n",
       "current_time            2018-01-07-20-36  2018-01-08-12-35  2018-01-06-23-16   \n",
       "delta_delta                         True              True              True   \n",
       "dropout_prob                         0.2               0.1              0.15   \n",
       "early_patience                       NaN                 4               NaN   \n",
       "elapsed                             4061              1593              3133   \n",
       "end_time                2018-01-07-21-44  2018-01-08-13-01  2018-01-07-00-08   \n",
       "epoch_dur                        116.029           56.8929           130.542   \n",
       "epochs                                35                28                24   \n",
       "filters_start                         50                40                50   \n",
       "filters_step                          25                20                50   \n",
       "init                                 NaN              lsuv               NaN   \n",
       "init_param                           NaN               0.1               NaN   \n",
       "init_stdd                           0.01               NaN              0.01   \n",
       "kernel_size                           10                 8                10   \n",
       "l2_reg                            0.0005            0.0001            0.0005   \n",
       "lr_patience                            2                 1                 2   \n",
       "lr_step                              0.2               0.5               0.2   \n",
       "n_dft                                512              1024               512   \n",
       "n_hop                                256               512               256   \n",
       "n_mels                               126                64               120   \n",
       "n_mfcc                                63                32                60   \n",
       "p_transform                            1                 1                 1   \n",
       "pool                                 max               max               max   \n",
       "pool_pad                            same              same              same   \n",
       "power_melgram                          2                 2                 2   \n",
       "regularize                         False              True             False   \n",
       "return_decibel_melgram              True              True              True   \n",
       "shift                                  1                 1                 1   \n",
       "train_acc                       0.933231          0.938814          0.935864   \n",
       "train_loss                      0.123511          0.248933           0.11611   \n",
       "train_state                [train, test]           [train]           [train]   \n",
       "trainable_fb                         NaN             False               NaN   \n",
       "trainable_kernel                     NaN             False               NaN   \n",
       "val_acc                         0.954661          0.954144          0.953791   \n",
       "val_loss                        0.143841          0.291373          0.140824   \n",
       "val_state                          [val]       [val, test]       [val, test]   \n",
       "vol_range                            0.1               0.1               0.1   \n",
       "\n",
       "                                      15        ...                       9   \\\n",
       "activation                           elu        ...                      elu   \n",
       "batch_normalize                     True        ...                     True   \n",
       "batch_size                            64        ...                      128   \n",
       "cnn_pad                             same        ...                     same   \n",
       "cnn_stack                            NaN        ...                      NaN   \n",
       "cnn_stride                             1        ...                        1   \n",
       "current_time            2018-01-06-16-53        ...         2018-01-05-23-52   \n",
       "delta_delta                         True        ...                      NaN   \n",
       "dropout_prob                        0.15        ...                      0.1   \n",
       "early_patience                       NaN        ...                      NaN   \n",
       "elapsed                            11757        ...                     1385   \n",
       "end_time                2018-01-06-20-09        ...         2018-01-06-00-15   \n",
       "epoch_dur                        132.101        ...                  53.2692   \n",
       "epochs                                89        ...                       26   \n",
       "filters_start                         50        ...                       40   \n",
       "filters_step                          50        ...                       10   \n",
       "init                                 NaN        ...                      NaN   \n",
       "init_param                           NaN        ...                      NaN   \n",
       "init_stdd                           0.01        ...                     0.01   \n",
       "kernel_size                           10        ...                       10   \n",
       "l2_reg                            0.0005        ...                   0.0005   \n",
       "lr_patience                            2        ...                      NaN   \n",
       "lr_step                              0.2        ...                      NaN   \n",
       "n_dft                                512        ...                      512   \n",
       "n_hop                                256        ...                      256   \n",
       "n_mels                               120        ...                       80   \n",
       "n_mfcc                                60        ...                       40   \n",
       "p_transform                            1        ...                        1   \n",
       "pool                                 max        ...                      max   \n",
       "pool_pad                            same        ...                     same   \n",
       "power_melgram                          2        ...                      NaN   \n",
       "regularize                          True        ...                     True   \n",
       "return_decibel_melgram              True        ...                      NaN   \n",
       "shift                                  1        ...                        1   \n",
       "train_acc                       0.928642        ...                 0.923196   \n",
       "train_loss                       0.21844        ...                 0.260596   \n",
       "train_state                      [train]        ...                  [train]   \n",
       "trainable_fb                         NaN        ...                      NaN   \n",
       "trainable_kernel                     NaN        ...                      NaN   \n",
       "val_acc                         0.953649        ...                 0.948703   \n",
       "val_loss                        0.222573        ...                 0.263299   \n",
       "val_state                    [val, test]        ...              [val, test]   \n",
       "vol_range                            0.1        ...                      0.1   \n",
       "\n",
       "                                      3                 1                 5   \\\n",
       "activation                           elu               elu               elu   \n",
       "batch_normalize                     True              True              True   \n",
       "batch_size                           128               128               128   \n",
       "cnn_pad                             same              same              same   \n",
       "cnn_stack                            NaN               NaN               NaN   \n",
       "cnn_stride                             1                 1                 1   \n",
       "current_time            2018-01-05-18-05  2018-01-05-14-21  2018-01-05-19-42   \n",
       "delta_delta                          NaN               NaN               NaN   \n",
       "dropout_prob                         0.1               0.1               0.1   \n",
       "early_patience                       NaN               NaN               NaN   \n",
       "elapsed                             1802              8094              1944   \n",
       "end_time                2018-01-05-18-35  2018-01-05-16-35  2018-01-05-20-14   \n",
       "epoch_dur                            NaN               NaN           62.7097   \n",
       "epochs                               NaN               NaN                31   \n",
       "filters_start                         40                40                50   \n",
       "filters_step                          10                10                20   \n",
       "init                                 NaN               NaN               NaN   \n",
       "init_param                           NaN               NaN               NaN   \n",
       "init_stdd                           0.01              0.01              0.01   \n",
       "kernel_size                           10                 6                10   \n",
       "l2_reg                            0.0005            0.0005            0.0005   \n",
       "lr_patience                          NaN               NaN               NaN   \n",
       "lr_step                              NaN               NaN               NaN   \n",
       "n_dft                                512               256               512   \n",
       "n_hop                                256               128               256   \n",
       "n_mels                                80               250                80   \n",
       "n_mfcc                                40               125                40   \n",
       "p_transform                            1                 1                 1   \n",
       "pool                                 max               max               max   \n",
       "pool_pad                            same              same              same   \n",
       "power_melgram                        NaN               NaN               NaN   \n",
       "regularize                          True              True              True   \n",
       "return_decibel_melgram               NaN               NaN               NaN   \n",
       "shift                                  1               0.3                 1   \n",
       "train_acc                       0.920568          0.929209          0.927299   \n",
       "train_loss                      0.241976          0.228661           0.25069   \n",
       "train_state                      [train]           [train]           [train]   \n",
       "trainable_fb                         NaN               NaN               NaN   \n",
       "trainable_kernel                     NaN               NaN               NaN   \n",
       "val_acc                         0.948492          0.947432           0.94616   \n",
       "val_loss                        0.244494          0.269057          0.265458   \n",
       "val_state                    [val, test]       [val, test]       [val, test]   \n",
       "vol_range                            0.1               0.1               0.1   \n",
       "\n",
       "                                 0                 23                2   \\\n",
       "activation                      elu               elu               elu   \n",
       "batch_normalize                True              True              True   \n",
       "batch_size                      128                64               128   \n",
       "cnn_pad                        same              same              same   \n",
       "cnn_stack                       NaN               NaN               NaN   \n",
       "cnn_stride                        1                 1                 1   \n",
       "current_time                    NaN  2018-01-08-10-32  2018-01-05-17-41   \n",
       "delta_delta                     NaN              True               NaN   \n",
       "dropout_prob                    0.1               0.1               0.1   \n",
       "early_patience                  NaN               NaN               NaN   \n",
       "elapsed                         NaN              1459              1008   \n",
       "end_time                        NaN  2018-01-08-10-56  2018-01-05-17-58   \n",
       "epoch_dur                       NaN           42.9118               NaN   \n",
       "epochs                          NaN                34               NaN   \n",
       "filters_start                    40                30                40   \n",
       "filters_step                     10                50                10   \n",
       "init                            NaN               NaN               NaN   \n",
       "init_param                      NaN               NaN               NaN   \n",
       "init_stdd                      0.01              0.01              0.01   \n",
       "kernel_size                       4                10                10   \n",
       "l2_reg                       0.0005            0.0005            0.0005   \n",
       "lr_patience                     NaN                 2               NaN   \n",
       "lr_step                         NaN               0.2               NaN   \n",
       "n_dft                           256              1024              1024   \n",
       "n_hop                           128               512               512   \n",
       "n_mels                          120                64                80   \n",
       "n_mfcc                          125                32                40   \n",
       "p_transform                       1                 1                 1   \n",
       "pool                            max               avg               max   \n",
       "pool_pad                       same              same              same   \n",
       "power_melgram                   NaN                 2               NaN   \n",
       "regularize                     True             False              True   \n",
       "return_decibel_melgram          NaN              True               NaN   \n",
       "shift                           0.3                 1                 1   \n",
       "train_acc                       NaN          0.906576          0.885683   \n",
       "train_loss                      NaN           0.16299          0.326288   \n",
       "train_state                 [train]           [train]           [train]   \n",
       "trainable_fb                    NaN               NaN               NaN   \n",
       "trainable_kernel                NaN               NaN               NaN   \n",
       "val_acc                    0.940366          0.936197          0.920441   \n",
       "val_loss                   0.302892          0.167513          0.307334   \n",
       "val_state               [val, test]       [val, test]       [val, test]   \n",
       "vol_range                       0.1               0.1               0.1   \n",
       "\n",
       "                                      24                12                19  \n",
       "activation                           elu               elu               elu  \n",
       "batch_normalize                     True              True             False  \n",
       "batch_size                           512               128                64  \n",
       "cnn_pad                             same              same              same  \n",
       "cnn_stack                            NaN               NaN               NaN  \n",
       "cnn_stride                             1                 1                 1  \n",
       "current_time            2018-01-08-11-56  2018-01-06-10-17  2018-01-07-11-45  \n",
       "delta_delta                         True              True              True  \n",
       "dropout_prob                        0.15              0.15               0.2  \n",
       "early_patience                         4               NaN               NaN  \n",
       "elapsed                             1011              1425               659  \n",
       "end_time                2018-01-08-12-13  2018-01-06-10-41  2018-01-07-11-56  \n",
       "epoch_dur                        37.4444             71.25           94.1429  \n",
       "epochs                                27                20                 7  \n",
       "filters_start                         40                50                50  \n",
       "filters_step                          10                25                25  \n",
       "init                                lsuv               NaN               NaN  \n",
       "init_param                           0.1               NaN               NaN  \n",
       "init_stdd                            NaN              0.01              0.01  \n",
       "kernel_size                            8                10                10  \n",
       "l2_reg                            0.0001            0.0005            0.0005  \n",
       "lr_patience                            2                 2                 2  \n",
       "lr_step                              0.2               0.2               0.2  \n",
       "n_dft                               1024               512               512  \n",
       "n_hop                                512               256               256  \n",
       "n_mels                                64                80               126  \n",
       "n_mfcc                                32                40                63  \n",
       "p_transform                            1                 1                 1  \n",
       "pool                                 max               max               max  \n",
       "pool_pad                            same              same              same  \n",
       "power_melgram                          2                 2                 2  \n",
       "regularize                         False              True             False  \n",
       "return_decibel_melgram              True             False              True  \n",
       "shift                                  1                 1                 1  \n",
       "train_acc                       0.872674          0.625548          0.615452  \n",
       "train_loss                       0.22116           0.88137            6.3797  \n",
       "train_state                      [train]           [train]           [train]  \n",
       "trainable_fb                       False               NaN               NaN  \n",
       "trainable_kernel                   False               NaN               NaN  \n",
       "val_acc                         0.919522           0.61676          0.599802  \n",
       "val_loss                        0.173672           1.58544           15.2463  \n",
       "val_state                    [val, test]       [val, test]       [val, test]  \n",
       "vol_range                            0.1               0.1               0.1  \n",
       "\n",
       "[43 rows x 27 columns]"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "runs_df.sort_values(\"val_acc\", ascending=False).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-08T17:25:54.641727Z",
     "start_time": "2018-01-08T17:25:54.602722Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>20</th>\n",
       "      <th>16</th>\n",
       "      <th>22</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>21</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>19</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>activation</th>\n",
       "      <td>elu</td>\n",
       "      <td>elu</td>\n",
       "      <td>elu</td>\n",
       "      <td>elu</td>\n",
       "      <td>elu</td>\n",
       "      <td>elu</td>\n",
       "      <td>elu</td>\n",
       "      <td>elu</td>\n",
       "      <td>elu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>batch_normalize</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>batch_size</th>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>512</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cnn_pad</th>\n",
       "      <td>same</td>\n",
       "      <td>same</td>\n",
       "      <td>same</td>\n",
       "      <td>same</td>\n",
       "      <td>same</td>\n",
       "      <td>same</td>\n",
       "      <td>same</td>\n",
       "      <td>same</td>\n",
       "      <td>same</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cnn_stride</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>current_time</th>\n",
       "      <td>2018-01-07-20-36</td>\n",
       "      <td>2018-01-06-23-16</td>\n",
       "      <td>2018-01-08-09-23</td>\n",
       "      <td>2018-01-07-01-39</td>\n",
       "      <td>2018-01-07-10-38</td>\n",
       "      <td>2018-01-08-08-23</td>\n",
       "      <td>2018-01-08-10-32</td>\n",
       "      <td>2018-01-08-11-56</td>\n",
       "      <td>2018-01-07-11-45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>delta_delta</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dropout_prob</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>early_patience</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>elapsed</th>\n",
       "      <td>4061</td>\n",
       "      <td>3133</td>\n",
       "      <td>2209</td>\n",
       "      <td>3290</td>\n",
       "      <td>3236</td>\n",
       "      <td>3264</td>\n",
       "      <td>1459</td>\n",
       "      <td>1011</td>\n",
       "      <td>659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>end_time</th>\n",
       "      <td>2018-01-07-21-44</td>\n",
       "      <td>2018-01-07-00-08</td>\n",
       "      <td>2018-01-08-10-00</td>\n",
       "      <td>2018-01-07-02-34</td>\n",
       "      <td>2018-01-07-11-32</td>\n",
       "      <td>2018-01-08-09-18</td>\n",
       "      <td>2018-01-08-10-56</td>\n",
       "      <td>2018-01-08-12-13</td>\n",
       "      <td>2018-01-07-11-56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>epoch_dur</th>\n",
       "      <td>116.029</td>\n",
       "      <td>130.542</td>\n",
       "      <td>84.9615</td>\n",
       "      <td>94</td>\n",
       "      <td>87.4595</td>\n",
       "      <td>93.2571</td>\n",
       "      <td>42.9118</td>\n",
       "      <td>37.4444</td>\n",
       "      <td>94.1429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>epochs</th>\n",
       "      <td>35</td>\n",
       "      <td>24</td>\n",
       "      <td>26</td>\n",
       "      <td>35</td>\n",
       "      <td>37</td>\n",
       "      <td>35</td>\n",
       "      <td>34</td>\n",
       "      <td>27</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>filters_start</th>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>40</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>filters_step</th>\n",
       "      <td>25</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>40</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>10</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>init</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>lsuv</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>init_param</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>init_stdd</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kernel_size</th>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>l2_reg</th>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lr_patience</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lr_step</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n_dft</th>\n",
       "      <td>512</td>\n",
       "      <td>512</td>\n",
       "      <td>512</td>\n",
       "      <td>512</td>\n",
       "      <td>512</td>\n",
       "      <td>512</td>\n",
       "      <td>1024</td>\n",
       "      <td>1024</td>\n",
       "      <td>512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n_hop</th>\n",
       "      <td>256</td>\n",
       "      <td>256</td>\n",
       "      <td>256</td>\n",
       "      <td>256</td>\n",
       "      <td>256</td>\n",
       "      <td>256</td>\n",
       "      <td>512</td>\n",
       "      <td>512</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n_mels</th>\n",
       "      <td>126</td>\n",
       "      <td>120</td>\n",
       "      <td>126</td>\n",
       "      <td>126</td>\n",
       "      <td>126</td>\n",
       "      <td>126</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n_mfcc</th>\n",
       "      <td>63</td>\n",
       "      <td>60</td>\n",
       "      <td>63</td>\n",
       "      <td>63</td>\n",
       "      <td>63</td>\n",
       "      <td>63</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p_transform</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pool</th>\n",
       "      <td>max</td>\n",
       "      <td>max</td>\n",
       "      <td>avg</td>\n",
       "      <td>max</td>\n",
       "      <td>max</td>\n",
       "      <td>avg</td>\n",
       "      <td>avg</td>\n",
       "      <td>max</td>\n",
       "      <td>max</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pool_pad</th>\n",
       "      <td>same</td>\n",
       "      <td>same</td>\n",
       "      <td>valid</td>\n",
       "      <td>same</td>\n",
       "      <td>same</td>\n",
       "      <td>same</td>\n",
       "      <td>same</td>\n",
       "      <td>same</td>\n",
       "      <td>same</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>power_melgram</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>regularize</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>return_decibel_melgram</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shift</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_acc</th>\n",
       "      <td>0.933231</td>\n",
       "      <td>0.935864</td>\n",
       "      <td>0.937396</td>\n",
       "      <td>0.930816</td>\n",
       "      <td>0.931043</td>\n",
       "      <td>0.930457</td>\n",
       "      <td>0.906576</td>\n",
       "      <td>0.872674</td>\n",
       "      <td>0.615452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_loss</th>\n",
       "      <td>0.123511</td>\n",
       "      <td>0.11611</td>\n",
       "      <td>0.113927</td>\n",
       "      <td>0.12139</td>\n",
       "      <td>0.122794</td>\n",
       "      <td>0.122492</td>\n",
       "      <td>0.16299</td>\n",
       "      <td>0.22116</td>\n",
       "      <td>6.3797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_state</th>\n",
       "      <td>[train, test]</td>\n",
       "      <td>[train]</td>\n",
       "      <td>[train]</td>\n",
       "      <td>[train]</td>\n",
       "      <td>[train]</td>\n",
       "      <td>[train]</td>\n",
       "      <td>[train]</td>\n",
       "      <td>[train]</td>\n",
       "      <td>[train]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trainable_fb</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trainable_kernel</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>val_acc</th>\n",
       "      <td>0.954661</td>\n",
       "      <td>0.953791</td>\n",
       "      <td>0.952872</td>\n",
       "      <td>0.952872</td>\n",
       "      <td>0.952448</td>\n",
       "      <td>0.952024</td>\n",
       "      <td>0.936197</td>\n",
       "      <td>0.919522</td>\n",
       "      <td>0.599802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>val_loss</th>\n",
       "      <td>0.143841</td>\n",
       "      <td>0.140824</td>\n",
       "      <td>0.140272</td>\n",
       "      <td>0.134524</td>\n",
       "      <td>0.13635</td>\n",
       "      <td>0.131799</td>\n",
       "      <td>0.167513</td>\n",
       "      <td>0.173672</td>\n",
       "      <td>15.2463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>val_state</th>\n",
       "      <td>[val]</td>\n",
       "      <td>[val, test]</td>\n",
       "      <td>[val, test]</td>\n",
       "      <td>[val, test]</td>\n",
       "      <td>[val, test]</td>\n",
       "      <td>[val, test]</td>\n",
       "      <td>[val, test]</td>\n",
       "      <td>[val, test]</td>\n",
       "      <td>[val, test]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vol_range</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      20                16                22  \\\n",
       "activation                           elu               elu               elu   \n",
       "batch_normalize                     True              True              True   \n",
       "batch_size                            64                64                64   \n",
       "cnn_pad                             same              same              same   \n",
       "cnn_stride                             1                 1                 1   \n",
       "current_time            2018-01-07-20-36  2018-01-06-23-16  2018-01-08-09-23   \n",
       "delta_delta                         True              True              True   \n",
       "dropout_prob                         0.2              0.15               0.1   \n",
       "early_patience                       NaN               NaN               NaN   \n",
       "elapsed                             4061              3133              2209   \n",
       "end_time                2018-01-07-21-44  2018-01-07-00-08  2018-01-08-10-00   \n",
       "epoch_dur                        116.029           130.542           84.9615   \n",
       "epochs                                35                24                26   \n",
       "filters_start                         50                50                30   \n",
       "filters_step                          25                50                50   \n",
       "init                                 NaN               NaN               NaN   \n",
       "init_param                           NaN               NaN               NaN   \n",
       "init_stdd                           0.01              0.01              0.01   \n",
       "kernel_size                           10                10                10   \n",
       "l2_reg                            0.0005            0.0005            0.0005   \n",
       "lr_patience                            2                 2                 2   \n",
       "lr_step                              0.2               0.2               0.2   \n",
       "n_dft                                512               512               512   \n",
       "n_hop                                256               256               256   \n",
       "n_mels                               126               120               126   \n",
       "n_mfcc                                63                60                63   \n",
       "p_transform                            1                 1                 1   \n",
       "pool                                 max               max               avg   \n",
       "pool_pad                            same              same             valid   \n",
       "power_melgram                          2                 2                 2   \n",
       "regularize                         False             False             False   \n",
       "return_decibel_melgram              True              True              True   \n",
       "shift                                  1                 1                 1   \n",
       "train_acc                       0.933231          0.935864          0.937396   \n",
       "train_loss                      0.123511           0.11611          0.113927   \n",
       "train_state                [train, test]           [train]           [train]   \n",
       "trainable_fb                         NaN               NaN               NaN   \n",
       "trainable_kernel                     NaN               NaN               NaN   \n",
       "val_acc                         0.954661          0.953791          0.952872   \n",
       "val_loss                        0.143841          0.140824          0.140272   \n",
       "val_state                          [val]       [val, test]       [val, test]   \n",
       "vol_range                            0.1               0.1               0.1   \n",
       "\n",
       "                                      17                18                21  \\\n",
       "activation                           elu               elu               elu   \n",
       "batch_normalize                     True              True              True   \n",
       "batch_size                            64                64                64   \n",
       "cnn_pad                             same              same              same   \n",
       "cnn_stride                             1                 1                 1   \n",
       "current_time            2018-01-07-01-39  2018-01-07-10-38  2018-01-08-08-23   \n",
       "delta_delta                         True              True              True   \n",
       "dropout_prob                         0.2               0.2               0.2   \n",
       "early_patience                       NaN               NaN               NaN   \n",
       "elapsed                             3290              3236              3264   \n",
       "end_time                2018-01-07-02-34  2018-01-07-11-32  2018-01-08-09-18   \n",
       "epoch_dur                             94           87.4595           93.2571   \n",
       "epochs                                35                37                35   \n",
       "filters_start                         30                30                30   \n",
       "filters_step                          50                40                50   \n",
       "init                                 NaN               NaN               NaN   \n",
       "init_param                           NaN               NaN               NaN   \n",
       "init_stdd                           0.01              0.01              0.01   \n",
       "kernel_size                           10                10                10   \n",
       "l2_reg                            0.0005            0.0005            0.0005   \n",
       "lr_patience                            2                 2                 2   \n",
       "lr_step                              0.2               0.2               0.2   \n",
       "n_dft                                512               512               512   \n",
       "n_hop                                256               256               256   \n",
       "n_mels                               126               126               126   \n",
       "n_mfcc                                63                63                63   \n",
       "p_transform                            1                 1                 1   \n",
       "pool                                 max               max               avg   \n",
       "pool_pad                            same              same              same   \n",
       "power_melgram                          2                 2                 2   \n",
       "regularize                         False             False             False   \n",
       "return_decibel_melgram              True              True              True   \n",
       "shift                                  1                 1                 1   \n",
       "train_acc                       0.930816          0.931043          0.930457   \n",
       "train_loss                       0.12139          0.122794          0.122492   \n",
       "train_state                      [train]           [train]           [train]   \n",
       "trainable_fb                         NaN               NaN               NaN   \n",
       "trainable_kernel                     NaN               NaN               NaN   \n",
       "val_acc                         0.952872          0.952448          0.952024   \n",
       "val_loss                        0.134524           0.13635          0.131799   \n",
       "val_state                    [val, test]       [val, test]       [val, test]   \n",
       "vol_range                            0.1               0.1               0.1   \n",
       "\n",
       "                                      23                24                19  \n",
       "activation                           elu               elu               elu  \n",
       "batch_normalize                     True              True             False  \n",
       "batch_size                            64               512                64  \n",
       "cnn_pad                             same              same              same  \n",
       "cnn_stride                             1                 1                 1  \n",
       "current_time            2018-01-08-10-32  2018-01-08-11-56  2018-01-07-11-45  \n",
       "delta_delta                         True              True              True  \n",
       "dropout_prob                         0.1              0.15               0.2  \n",
       "early_patience                       NaN                 4               NaN  \n",
       "elapsed                             1459              1011               659  \n",
       "end_time                2018-01-08-10-56  2018-01-08-12-13  2018-01-07-11-56  \n",
       "epoch_dur                        42.9118           37.4444           94.1429  \n",
       "epochs                                34                27                 7  \n",
       "filters_start                         30                40                50  \n",
       "filters_step                          50                10                25  \n",
       "init                                 NaN              lsuv               NaN  \n",
       "init_param                           NaN               0.1               NaN  \n",
       "init_stdd                           0.01               NaN              0.01  \n",
       "kernel_size                           10                 8                10  \n",
       "l2_reg                            0.0005            0.0001            0.0005  \n",
       "lr_patience                            2                 2                 2  \n",
       "lr_step                              0.2               0.2               0.2  \n",
       "n_dft                               1024              1024               512  \n",
       "n_hop                                512               512               256  \n",
       "n_mels                                64                64               126  \n",
       "n_mfcc                                32                32                63  \n",
       "p_transform                            1                 1                 1  \n",
       "pool                                 avg               max               max  \n",
       "pool_pad                            same              same              same  \n",
       "power_melgram                          2                 2                 2  \n",
       "regularize                         False             False             False  \n",
       "return_decibel_melgram              True              True              True  \n",
       "shift                                  1                 1                 1  \n",
       "train_acc                       0.906576          0.872674          0.615452  \n",
       "train_loss                       0.16299           0.22116            6.3797  \n",
       "train_state                      [train]           [train]           [train]  \n",
       "trainable_fb                         NaN             False               NaN  \n",
       "trainable_kernel                     NaN             False               NaN  \n",
       "val_acc                         0.936197          0.919522          0.599802  \n",
       "val_loss                        0.167513          0.173672           15.2463  \n",
       "val_state                    [val, test]       [val, test]       [val, test]  \n",
       "vol_range                            0.1               0.1               0.1  "
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "runs_df[runs_df.regularize==False].sort_values(\"val_acc\", ascending=False).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-08T15:39:48.006845Z",
     "start_time": "2018-01-08T15:39:47.888406Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>11</th>\n",
       "      <th>14</th>\n",
       "      <th>4</th>\n",
       "      <th>8</th>\n",
       "      <th>13</th>\n",
       "      <th>20</th>\n",
       "      <th>16</th>\n",
       "      <th>15</th>\n",
       "      <th>22</th>\n",
       "      <th>17</th>\n",
       "      <th>...</th>\n",
       "      <th>7</th>\n",
       "      <th>6</th>\n",
       "      <th>9</th>\n",
       "      <th>3</th>\n",
       "      <th>1</th>\n",
       "      <th>5</th>\n",
       "      <th>0</th>\n",
       "      <th>2</th>\n",
       "      <th>12</th>\n",
       "      <th>19</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>activation</th>\n",
       "      <td>elu</td>\n",
       "      <td>elu</td>\n",
       "      <td>elu</td>\n",
       "      <td>elu</td>\n",
       "      <td>elu</td>\n",
       "      <td>elu</td>\n",
       "      <td>elu</td>\n",
       "      <td>elu</td>\n",
       "      <td>elu</td>\n",
       "      <td>elu</td>\n",
       "      <td>...</td>\n",
       "      <td>elu</td>\n",
       "      <td>elu</td>\n",
       "      <td>elu</td>\n",
       "      <td>elu</td>\n",
       "      <td>elu</td>\n",
       "      <td>elu</td>\n",
       "      <td>elu</td>\n",
       "      <td>elu</td>\n",
       "      <td>elu</td>\n",
       "      <td>elu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>batch_normalize</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>batch_size</th>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>...</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cnn_pad</th>\n",
       "      <td>same</td>\n",
       "      <td>same</td>\n",
       "      <td>same</td>\n",
       "      <td>same</td>\n",
       "      <td>same</td>\n",
       "      <td>same</td>\n",
       "      <td>same</td>\n",
       "      <td>same</td>\n",
       "      <td>same</td>\n",
       "      <td>same</td>\n",
       "      <td>...</td>\n",
       "      <td>same</td>\n",
       "      <td>same</td>\n",
       "      <td>same</td>\n",
       "      <td>same</td>\n",
       "      <td>same</td>\n",
       "      <td>same</td>\n",
       "      <td>same</td>\n",
       "      <td>same</td>\n",
       "      <td>same</td>\n",
       "      <td>same</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cnn_stride</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>current_time</th>\n",
       "      <td>2018-01-06-00-47</td>\n",
       "      <td>2018-01-06-12-01</td>\n",
       "      <td>2018-01-05-18-40</td>\n",
       "      <td>2018-01-05-21-44</td>\n",
       "      <td>2018-01-06-10-46</td>\n",
       "      <td>2018-01-07-20-36</td>\n",
       "      <td>2018-01-06-23-16</td>\n",
       "      <td>2018-01-06-16-53</td>\n",
       "      <td>2018-01-08-09-23</td>\n",
       "      <td>2018-01-07-01-39</td>\n",
       "      <td>...</td>\n",
       "      <td>2018-01-05-20-59</td>\n",
       "      <td>2018-01-05-20-21</td>\n",
       "      <td>2018-01-05-23-52</td>\n",
       "      <td>2018-01-05-18-05</td>\n",
       "      <td>2018-01-05-14-21</td>\n",
       "      <td>2018-01-05-19-42</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-01-05-17-41</td>\n",
       "      <td>2018-01-06-10-17</td>\n",
       "      <td>2018-01-07-11-45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>delta_delta</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dropout_prob</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>elapsed</th>\n",
       "      <td>3047</td>\n",
       "      <td>5186</td>\n",
       "      <td>2958</td>\n",
       "      <td>4538</td>\n",
       "      <td>3099</td>\n",
       "      <td>4061</td>\n",
       "      <td>3133</td>\n",
       "      <td>11757</td>\n",
       "      <td>2209</td>\n",
       "      <td>3290</td>\n",
       "      <td>...</td>\n",
       "      <td>2491</td>\n",
       "      <td>1831</td>\n",
       "      <td>1385</td>\n",
       "      <td>1802</td>\n",
       "      <td>8094</td>\n",
       "      <td>1944</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1008</td>\n",
       "      <td>1425</td>\n",
       "      <td>659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>end_time</th>\n",
       "      <td>2018-01-06-01-38</td>\n",
       "      <td>2018-01-06-13-28</td>\n",
       "      <td>2018-01-05-19-30</td>\n",
       "      <td>2018-01-05-22-59</td>\n",
       "      <td>2018-01-06-11-38</td>\n",
       "      <td>2018-01-07-21-44</td>\n",
       "      <td>2018-01-07-00-08</td>\n",
       "      <td>2018-01-06-20-09</td>\n",
       "      <td>2018-01-08-10-00</td>\n",
       "      <td>2018-01-07-02-34</td>\n",
       "      <td>...</td>\n",
       "      <td>2018-01-05-21-40</td>\n",
       "      <td>2018-01-05-20-51</td>\n",
       "      <td>2018-01-06-00-15</td>\n",
       "      <td>2018-01-05-18-35</td>\n",
       "      <td>2018-01-05-16-35</td>\n",
       "      <td>2018-01-05-20-14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-01-05-17-58</td>\n",
       "      <td>2018-01-06-10-41</td>\n",
       "      <td>2018-01-07-11-56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>epoch_dur</th>\n",
       "      <td>70.8605</td>\n",
       "      <td>117.864</td>\n",
       "      <td>NaN</td>\n",
       "      <td>90.76</td>\n",
       "      <td>70.4318</td>\n",
       "      <td>116.029</td>\n",
       "      <td>130.542</td>\n",
       "      <td>132.101</td>\n",
       "      <td>84.9615</td>\n",
       "      <td>94</td>\n",
       "      <td>...</td>\n",
       "      <td>73.2647</td>\n",
       "      <td>61.0333</td>\n",
       "      <td>53.2692</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>62.7097</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>71.25</td>\n",
       "      <td>94.1429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>epochs</th>\n",
       "      <td>43</td>\n",
       "      <td>44</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50</td>\n",
       "      <td>44</td>\n",
       "      <td>35</td>\n",
       "      <td>24</td>\n",
       "      <td>89</td>\n",
       "      <td>26</td>\n",
       "      <td>35</td>\n",
       "      <td>...</td>\n",
       "      <td>34</td>\n",
       "      <td>30</td>\n",
       "      <td>26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>filters_start</th>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>60</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>50</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>filters_step</th>\n",
       "      <td>25</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>60</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>...</td>\n",
       "      <td>60</td>\n",
       "      <td>40</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>init_stdd</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>...</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kernel_size</th>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>l2_reg</th>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lr_patience</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lr_step</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n_dft</th>\n",
       "      <td>512</td>\n",
       "      <td>512</td>\n",
       "      <td>512</td>\n",
       "      <td>512</td>\n",
       "      <td>512</td>\n",
       "      <td>512</td>\n",
       "      <td>512</td>\n",
       "      <td>512</td>\n",
       "      <td>512</td>\n",
       "      <td>512</td>\n",
       "      <td>...</td>\n",
       "      <td>512</td>\n",
       "      <td>512</td>\n",
       "      <td>512</td>\n",
       "      <td>512</td>\n",
       "      <td>256</td>\n",
       "      <td>512</td>\n",
       "      <td>256</td>\n",
       "      <td>1024</td>\n",
       "      <td>512</td>\n",
       "      <td>512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n_hop</th>\n",
       "      <td>256</td>\n",
       "      <td>256</td>\n",
       "      <td>256</td>\n",
       "      <td>256</td>\n",
       "      <td>256</td>\n",
       "      <td>256</td>\n",
       "      <td>256</td>\n",
       "      <td>256</td>\n",
       "      <td>256</td>\n",
       "      <td>256</td>\n",
       "      <td>...</td>\n",
       "      <td>256</td>\n",
       "      <td>256</td>\n",
       "      <td>256</td>\n",
       "      <td>256</td>\n",
       "      <td>128</td>\n",
       "      <td>256</td>\n",
       "      <td>128</td>\n",
       "      <td>512</td>\n",
       "      <td>256</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n_mels</th>\n",
       "      <td>80</td>\n",
       "      <td>120</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>126</td>\n",
       "      <td>120</td>\n",
       "      <td>120</td>\n",
       "      <td>126</td>\n",
       "      <td>126</td>\n",
       "      <td>...</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>250</td>\n",
       "      <td>80</td>\n",
       "      <td>120</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n_mfcc</th>\n",
       "      <td>40</td>\n",
       "      <td>60</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>63</td>\n",
       "      <td>60</td>\n",
       "      <td>60</td>\n",
       "      <td>63</td>\n",
       "      <td>63</td>\n",
       "      <td>...</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>125</td>\n",
       "      <td>40</td>\n",
       "      <td>125</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p_transform</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pool</th>\n",
       "      <td>max</td>\n",
       "      <td>max</td>\n",
       "      <td>max</td>\n",
       "      <td>max</td>\n",
       "      <td>max</td>\n",
       "      <td>max</td>\n",
       "      <td>max</td>\n",
       "      <td>max</td>\n",
       "      <td>avg</td>\n",
       "      <td>max</td>\n",
       "      <td>...</td>\n",
       "      <td>max</td>\n",
       "      <td>max</td>\n",
       "      <td>max</td>\n",
       "      <td>max</td>\n",
       "      <td>max</td>\n",
       "      <td>max</td>\n",
       "      <td>max</td>\n",
       "      <td>max</td>\n",
       "      <td>max</td>\n",
       "      <td>max</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pool_pad</th>\n",
       "      <td>same</td>\n",
       "      <td>same</td>\n",
       "      <td>same</td>\n",
       "      <td>same</td>\n",
       "      <td>same</td>\n",
       "      <td>same</td>\n",
       "      <td>same</td>\n",
       "      <td>same</td>\n",
       "      <td>valid</td>\n",
       "      <td>same</td>\n",
       "      <td>...</td>\n",
       "      <td>same</td>\n",
       "      <td>same</td>\n",
       "      <td>same</td>\n",
       "      <td>same</td>\n",
       "      <td>same</td>\n",
       "      <td>same</td>\n",
       "      <td>same</td>\n",
       "      <td>same</td>\n",
       "      <td>same</td>\n",
       "      <td>same</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>power_melgram</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>regularize</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>return_decibel_melgram</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shift</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_acc</th>\n",
       "      <td>0.949005</td>\n",
       "      <td>0.945092</td>\n",
       "      <td>0.939022</td>\n",
       "      <td>0.937717</td>\n",
       "      <td>0.941442</td>\n",
       "      <td>0.933231</td>\n",
       "      <td>0.935864</td>\n",
       "      <td>0.928642</td>\n",
       "      <td>0.937396</td>\n",
       "      <td>0.930816</td>\n",
       "      <td>...</td>\n",
       "      <td>0.93265</td>\n",
       "      <td>0.931383</td>\n",
       "      <td>0.923196</td>\n",
       "      <td>0.920568</td>\n",
       "      <td>0.929209</td>\n",
       "      <td>0.927299</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.885683</td>\n",
       "      <td>0.625548</td>\n",
       "      <td>0.615452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_loss</th>\n",
       "      <td>0.200943</td>\n",
       "      <td>0.226688</td>\n",
       "      <td>0.24595</td>\n",
       "      <td>0.256859</td>\n",
       "      <td>0.223383</td>\n",
       "      <td>0.123511</td>\n",
       "      <td>0.11611</td>\n",
       "      <td>0.21844</td>\n",
       "      <td>0.113927</td>\n",
       "      <td>0.12139</td>\n",
       "      <td>...</td>\n",
       "      <td>0.265896</td>\n",
       "      <td>0.256252</td>\n",
       "      <td>0.260596</td>\n",
       "      <td>0.241976</td>\n",
       "      <td>0.228661</td>\n",
       "      <td>0.25069</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.326288</td>\n",
       "      <td>0.88137</td>\n",
       "      <td>6.3797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_state</th>\n",
       "      <td>[train]</td>\n",
       "      <td>[train]</td>\n",
       "      <td>[train]</td>\n",
       "      <td>[train]</td>\n",
       "      <td>[train]</td>\n",
       "      <td>[train, test]</td>\n",
       "      <td>[train]</td>\n",
       "      <td>[train]</td>\n",
       "      <td>[train]</td>\n",
       "      <td>[train]</td>\n",
       "      <td>...</td>\n",
       "      <td>[train]</td>\n",
       "      <td>[train]</td>\n",
       "      <td>[train]</td>\n",
       "      <td>[train]</td>\n",
       "      <td>[train]</td>\n",
       "      <td>[train]</td>\n",
       "      <td>[train]</td>\n",
       "      <td>[train]</td>\n",
       "      <td>[train]</td>\n",
       "      <td>[train]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>val_acc</th>\n",
       "      <td>0.962481</td>\n",
       "      <td>0.958525</td>\n",
       "      <td>0.958313</td>\n",
       "      <td>0.957324</td>\n",
       "      <td>0.956829</td>\n",
       "      <td>0.954661</td>\n",
       "      <td>0.953791</td>\n",
       "      <td>0.953649</td>\n",
       "      <td>0.952872</td>\n",
       "      <td>0.952872</td>\n",
       "      <td>...</td>\n",
       "      <td>0.951176</td>\n",
       "      <td>0.950823</td>\n",
       "      <td>0.948703</td>\n",
       "      <td>0.948492</td>\n",
       "      <td>0.947432</td>\n",
       "      <td>0.94616</td>\n",
       "      <td>0.940366</td>\n",
       "      <td>0.920441</td>\n",
       "      <td>0.61676</td>\n",
       "      <td>0.599802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>val_loss</th>\n",
       "      <td>0.233833</td>\n",
       "      <td>0.266385</td>\n",
       "      <td>0.267767</td>\n",
       "      <td>0.283327</td>\n",
       "      <td>0.25919</td>\n",
       "      <td>0.143841</td>\n",
       "      <td>0.140824</td>\n",
       "      <td>0.222573</td>\n",
       "      <td>0.140272</td>\n",
       "      <td>0.134524</td>\n",
       "      <td>...</td>\n",
       "      <td>0.284709</td>\n",
       "      <td>0.27074</td>\n",
       "      <td>0.263299</td>\n",
       "      <td>0.244494</td>\n",
       "      <td>0.269057</td>\n",
       "      <td>0.265458</td>\n",
       "      <td>0.302892</td>\n",
       "      <td>0.307334</td>\n",
       "      <td>1.58544</td>\n",
       "      <td>15.2463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>val_state</th>\n",
       "      <td>[val, test]</td>\n",
       "      <td>[val, test]</td>\n",
       "      <td>[val, test]</td>\n",
       "      <td>[val, test]</td>\n",
       "      <td>[val, test]</td>\n",
       "      <td>[val]</td>\n",
       "      <td>[val, test]</td>\n",
       "      <td>[val, test]</td>\n",
       "      <td>[val, test]</td>\n",
       "      <td>[val, test]</td>\n",
       "      <td>...</td>\n",
       "      <td>[val, test]</td>\n",
       "      <td>[val, test]</td>\n",
       "      <td>[val, test]</td>\n",
       "      <td>[val, test]</td>\n",
       "      <td>[val, test]</td>\n",
       "      <td>[val, test]</td>\n",
       "      <td>[val, test]</td>\n",
       "      <td>[val, test]</td>\n",
       "      <td>[val, test]</td>\n",
       "      <td>[val, test]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vol_range</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>37 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      11                14                4   \\\n",
       "activation                           elu               elu               elu   \n",
       "batch_normalize                     True              True              True   \n",
       "batch_size                           128               128               128   \n",
       "cnn_pad                             same              same              same   \n",
       "cnn_stride                             1                 1                 1   \n",
       "current_time            2018-01-06-00-47  2018-01-06-12-01  2018-01-05-18-40   \n",
       "delta_delta                         True              True               NaN   \n",
       "dropout_prob                         0.1               0.1               0.1   \n",
       "elapsed                             3047              5186              2958   \n",
       "end_time                2018-01-06-01-38  2018-01-06-13-28  2018-01-05-19-30   \n",
       "epoch_dur                        70.8605           117.864               NaN   \n",
       "epochs                                43                44               NaN   \n",
       "filters_start                         50                50                50   \n",
       "filters_step                          25                50                50   \n",
       "init_stdd                           0.01              0.01              0.01   \n",
       "kernel_size                           10                10                10   \n",
       "l2_reg                            0.0005            0.0005            0.0005   \n",
       "lr_patience                            2                 2               NaN   \n",
       "lr_step                              0.2               0.2               NaN   \n",
       "n_dft                                512               512               512   \n",
       "n_hop                                256               256               256   \n",
       "n_mels                                80               120                80   \n",
       "n_mfcc                                40                60                40   \n",
       "p_transform                            1                 1                 1   \n",
       "pool                                 max               max               max   \n",
       "pool_pad                            same              same              same   \n",
       "power_melgram                          2                 2               NaN   \n",
       "regularize                          True              True              True   \n",
       "return_decibel_melgram              True              True               NaN   \n",
       "shift                                  1                 1                 1   \n",
       "train_acc                       0.949005          0.945092          0.939022   \n",
       "train_loss                      0.200943          0.226688           0.24595   \n",
       "train_state                      [train]           [train]           [train]   \n",
       "val_acc                         0.962481          0.958525          0.958313   \n",
       "val_loss                        0.233833          0.266385          0.267767   \n",
       "val_state                    [val, test]       [val, test]       [val, test]   \n",
       "vol_range                            0.1               0.1               0.1   \n",
       "\n",
       "                                      8                 13                20  \\\n",
       "activation                           elu               elu               elu   \n",
       "batch_normalize                     True              True              True   \n",
       "batch_size                           128               128                64   \n",
       "cnn_pad                             same              same              same   \n",
       "cnn_stride                             1                 1                 1   \n",
       "current_time            2018-01-05-21-44  2018-01-06-10-46  2018-01-07-20-36   \n",
       "delta_delta                          NaN              True              True   \n",
       "dropout_prob                         0.2               0.1               0.2   \n",
       "elapsed                             4538              3099              4061   \n",
       "end_time                2018-01-05-22-59  2018-01-06-11-38  2018-01-07-21-44   \n",
       "epoch_dur                          90.76           70.4318           116.029   \n",
       "epochs                                50                44                35   \n",
       "filters_start                         60                50                50   \n",
       "filters_step                          60                25                25   \n",
       "init_stdd                           0.01              0.01              0.01   \n",
       "kernel_size                           10                10                10   \n",
       "l2_reg                            0.0005            0.0005            0.0005   \n",
       "lr_patience                          NaN                 2                 2   \n",
       "lr_step                              NaN               0.2               0.2   \n",
       "n_dft                                512               512               512   \n",
       "n_hop                                256               256               256   \n",
       "n_mels                                80                80               126   \n",
       "n_mfcc                                40                40                63   \n",
       "p_transform                            1                 1                 1   \n",
       "pool                                 max               max               max   \n",
       "pool_pad                            same              same              same   \n",
       "power_melgram                        NaN                 1                 2   \n",
       "regularize                          True              True             False   \n",
       "return_decibel_melgram               NaN              True              True   \n",
       "shift                                  1                 1                 1   \n",
       "train_acc                       0.937717          0.941442          0.933231   \n",
       "train_loss                      0.256859          0.223383          0.123511   \n",
       "train_state                      [train]           [train]     [train, test]   \n",
       "val_acc                         0.957324          0.956829          0.954661   \n",
       "val_loss                        0.283327           0.25919          0.143841   \n",
       "val_state                    [val, test]       [val, test]             [val]   \n",
       "vol_range                            0.1               0.1               0.1   \n",
       "\n",
       "                                      16                15                22  \\\n",
       "activation                           elu               elu               elu   \n",
       "batch_normalize                     True              True              True   \n",
       "batch_size                            64                64                64   \n",
       "cnn_pad                             same              same              same   \n",
       "cnn_stride                             1                 1                 1   \n",
       "current_time            2018-01-06-23-16  2018-01-06-16-53  2018-01-08-09-23   \n",
       "delta_delta                         True              True              True   \n",
       "dropout_prob                        0.15              0.15               0.1   \n",
       "elapsed                             3133             11757              2209   \n",
       "end_time                2018-01-07-00-08  2018-01-06-20-09  2018-01-08-10-00   \n",
       "epoch_dur                        130.542           132.101           84.9615   \n",
       "epochs                                24                89                26   \n",
       "filters_start                         50                50                30   \n",
       "filters_step                          50                50                50   \n",
       "init_stdd                           0.01              0.01              0.01   \n",
       "kernel_size                           10                10                10   \n",
       "l2_reg                            0.0005            0.0005            0.0005   \n",
       "lr_patience                            2                 2                 2   \n",
       "lr_step                              0.2               0.2               0.2   \n",
       "n_dft                                512               512               512   \n",
       "n_hop                                256               256               256   \n",
       "n_mels                               120               120               126   \n",
       "n_mfcc                                60                60                63   \n",
       "p_transform                            1                 1                 1   \n",
       "pool                                 max               max               avg   \n",
       "pool_pad                            same              same             valid   \n",
       "power_melgram                          2                 2                 2   \n",
       "regularize                         False              True             False   \n",
       "return_decibel_melgram              True              True              True   \n",
       "shift                                  1                 1                 1   \n",
       "train_acc                       0.935864          0.928642          0.937396   \n",
       "train_loss                       0.11611           0.21844          0.113927   \n",
       "train_state                      [train]           [train]           [train]   \n",
       "val_acc                         0.953791          0.953649          0.952872   \n",
       "val_loss                        0.140824          0.222573          0.140272   \n",
       "val_state                    [val, test]       [val, test]       [val, test]   \n",
       "vol_range                            0.1               0.1               0.1   \n",
       "\n",
       "                                      17        ...                       7   \\\n",
       "activation                           elu        ...                      elu   \n",
       "batch_normalize                     True        ...                     True   \n",
       "batch_size                            64        ...                      128   \n",
       "cnn_pad                             same        ...                     same   \n",
       "cnn_stride                             1        ...                        1   \n",
       "current_time            2018-01-07-01-39        ...         2018-01-05-20-59   \n",
       "delta_delta                         True        ...                      NaN   \n",
       "dropout_prob                         0.2        ...                      0.1   \n",
       "elapsed                             3290        ...                     2491   \n",
       "end_time                2018-01-07-02-34        ...         2018-01-05-21-40   \n",
       "epoch_dur                             94        ...                  73.2647   \n",
       "epochs                                35        ...                       34   \n",
       "filters_start                         30        ...                       40   \n",
       "filters_step                          50        ...                       60   \n",
       "init_stdd                           0.01        ...                     0.01   \n",
       "kernel_size                           10        ...                       10   \n",
       "l2_reg                            0.0005        ...                   0.0005   \n",
       "lr_patience                            2        ...                      NaN   \n",
       "lr_step                              0.2        ...                      NaN   \n",
       "n_dft                                512        ...                      512   \n",
       "n_hop                                256        ...                      256   \n",
       "n_mels                               126        ...                       80   \n",
       "n_mfcc                                63        ...                       40   \n",
       "p_transform                            1        ...                        1   \n",
       "pool                                 max        ...                      max   \n",
       "pool_pad                            same        ...                     same   \n",
       "power_melgram                          2        ...                      NaN   \n",
       "regularize                         False        ...                     True   \n",
       "return_decibel_melgram              True        ...                      NaN   \n",
       "shift                                  1        ...                        1   \n",
       "train_acc                       0.930816        ...                  0.93265   \n",
       "train_loss                       0.12139        ...                 0.265896   \n",
       "train_state                      [train]        ...                  [train]   \n",
       "val_acc                         0.952872        ...                 0.951176   \n",
       "val_loss                        0.134524        ...                 0.284709   \n",
       "val_state                    [val, test]        ...              [val, test]   \n",
       "vol_range                            0.1        ...                      0.1   \n",
       "\n",
       "                                      6                 9                 3   \\\n",
       "activation                           elu               elu               elu   \n",
       "batch_normalize                     True              True              True   \n",
       "batch_size                           128               128               128   \n",
       "cnn_pad                             same              same              same   \n",
       "cnn_stride                             1                 1                 1   \n",
       "current_time            2018-01-05-20-21  2018-01-05-23-52  2018-01-05-18-05   \n",
       "delta_delta                          NaN               NaN               NaN   \n",
       "dropout_prob                         0.1               0.1               0.1   \n",
       "elapsed                             1831              1385              1802   \n",
       "end_time                2018-01-05-20-51  2018-01-06-00-15  2018-01-05-18-35   \n",
       "epoch_dur                        61.0333           53.2692               NaN   \n",
       "epochs                                30                26               NaN   \n",
       "filters_start                         40                40                40   \n",
       "filters_step                          40                10                10   \n",
       "init_stdd                           0.01              0.01              0.01   \n",
       "kernel_size                           10                10                10   \n",
       "l2_reg                            0.0005            0.0005            0.0005   \n",
       "lr_patience                          NaN               NaN               NaN   \n",
       "lr_step                              NaN               NaN               NaN   \n",
       "n_dft                                512               512               512   \n",
       "n_hop                                256               256               256   \n",
       "n_mels                                80                80                80   \n",
       "n_mfcc                                40                40                40   \n",
       "p_transform                            1                 1                 1   \n",
       "pool                                 max               max               max   \n",
       "pool_pad                            same              same              same   \n",
       "power_melgram                        NaN               NaN               NaN   \n",
       "regularize                          True              True              True   \n",
       "return_decibel_melgram               NaN               NaN               NaN   \n",
       "shift                                  1                 1                 1   \n",
       "train_acc                       0.931383          0.923196          0.920568   \n",
       "train_loss                      0.256252          0.260596          0.241976   \n",
       "train_state                      [train]           [train]           [train]   \n",
       "val_acc                         0.950823          0.948703          0.948492   \n",
       "val_loss                         0.27074          0.263299          0.244494   \n",
       "val_state                    [val, test]       [val, test]       [val, test]   \n",
       "vol_range                            0.1               0.1               0.1   \n",
       "\n",
       "                                      1                 5            0   \\\n",
       "activation                           elu               elu          elu   \n",
       "batch_normalize                     True              True         True   \n",
       "batch_size                           128               128          128   \n",
       "cnn_pad                             same              same         same   \n",
       "cnn_stride                             1                 1            1   \n",
       "current_time            2018-01-05-14-21  2018-01-05-19-42          NaN   \n",
       "delta_delta                          NaN               NaN          NaN   \n",
       "dropout_prob                         0.1               0.1          0.1   \n",
       "elapsed                             8094              1944          NaN   \n",
       "end_time                2018-01-05-16-35  2018-01-05-20-14          NaN   \n",
       "epoch_dur                            NaN           62.7097          NaN   \n",
       "epochs                               NaN                31          NaN   \n",
       "filters_start                         40                50           40   \n",
       "filters_step                          10                20           10   \n",
       "init_stdd                           0.01              0.01         0.01   \n",
       "kernel_size                            6                10            4   \n",
       "l2_reg                            0.0005            0.0005       0.0005   \n",
       "lr_patience                          NaN               NaN          NaN   \n",
       "lr_step                              NaN               NaN          NaN   \n",
       "n_dft                                256               512          256   \n",
       "n_hop                                128               256          128   \n",
       "n_mels                               250                80          120   \n",
       "n_mfcc                               125                40          125   \n",
       "p_transform                            1                 1            1   \n",
       "pool                                 max               max          max   \n",
       "pool_pad                            same              same         same   \n",
       "power_melgram                        NaN               NaN          NaN   \n",
       "regularize                          True              True         True   \n",
       "return_decibel_melgram               NaN               NaN          NaN   \n",
       "shift                                0.3                 1          0.3   \n",
       "train_acc                       0.929209          0.927299          NaN   \n",
       "train_loss                      0.228661           0.25069          NaN   \n",
       "train_state                      [train]           [train]      [train]   \n",
       "val_acc                         0.947432           0.94616     0.940366   \n",
       "val_loss                        0.269057          0.265458     0.302892   \n",
       "val_state                    [val, test]       [val, test]  [val, test]   \n",
       "vol_range                            0.1               0.1          0.1   \n",
       "\n",
       "                                      2                 12                19  \n",
       "activation                           elu               elu               elu  \n",
       "batch_normalize                     True              True             False  \n",
       "batch_size                           128               128                64  \n",
       "cnn_pad                             same              same              same  \n",
       "cnn_stride                             1                 1                 1  \n",
       "current_time            2018-01-05-17-41  2018-01-06-10-17  2018-01-07-11-45  \n",
       "delta_delta                          NaN              True              True  \n",
       "dropout_prob                         0.1              0.15               0.2  \n",
       "elapsed                             1008              1425               659  \n",
       "end_time                2018-01-05-17-58  2018-01-06-10-41  2018-01-07-11-56  \n",
       "epoch_dur                            NaN             71.25           94.1429  \n",
       "epochs                               NaN                20                 7  \n",
       "filters_start                         40                50                50  \n",
       "filters_step                          10                25                25  \n",
       "init_stdd                           0.01              0.01              0.01  \n",
       "kernel_size                           10                10                10  \n",
       "l2_reg                            0.0005            0.0005            0.0005  \n",
       "lr_patience                          NaN                 2                 2  \n",
       "lr_step                              NaN               0.2               0.2  \n",
       "n_dft                               1024               512               512  \n",
       "n_hop                                512               256               256  \n",
       "n_mels                                80                80               126  \n",
       "n_mfcc                                40                40                63  \n",
       "p_transform                            1                 1                 1  \n",
       "pool                                 max               max               max  \n",
       "pool_pad                            same              same              same  \n",
       "power_melgram                        NaN                 2                 2  \n",
       "regularize                          True              True             False  \n",
       "return_decibel_melgram               NaN             False              True  \n",
       "shift                                  1                 1                 1  \n",
       "train_acc                       0.885683          0.625548          0.615452  \n",
       "train_loss                      0.326288           0.88137            6.3797  \n",
       "train_state                      [train]           [train]           [train]  \n",
       "val_acc                         0.920441           0.61676          0.599802  \n",
       "val_loss                        0.307334           1.58544           15.2463  \n",
       "val_state                    [val, test]       [val, test]       [val, test]  \n",
       "vol_range                            0.1               0.1               0.1  \n",
       "\n",
       "[37 rows x 23 columns]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "runs_df.sort_values(\"val_acc\", ascending=False).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-08T15:31:34.473813Z",
     "start_time": "2018-01-08T15:31:34.407874Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>21</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>22</th>\n",
       "      <th>16</th>\n",
       "      <th>20</th>\n",
       "      <th>15</th>\n",
       "      <th>11</th>\n",
       "      <th>3</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>14</th>\n",
       "      <th>4</th>\n",
       "      <th>1</th>\n",
       "      <th>6</th>\n",
       "      <th>8</th>\n",
       "      <th>7</th>\n",
       "      <th>0</th>\n",
       "      <th>2</th>\n",
       "      <th>12</th>\n",
       "      <th>19</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>activation</th>\n",
       "      <td>elu</td>\n",
       "      <td>elu</td>\n",
       "      <td>elu</td>\n",
       "      <td>elu</td>\n",
       "      <td>elu</td>\n",
       "      <td>elu</td>\n",
       "      <td>elu</td>\n",
       "      <td>elu</td>\n",
       "      <td>elu</td>\n",
       "      <td>elu</td>\n",
       "      <td>...</td>\n",
       "      <td>elu</td>\n",
       "      <td>elu</td>\n",
       "      <td>elu</td>\n",
       "      <td>elu</td>\n",
       "      <td>elu</td>\n",
       "      <td>elu</td>\n",
       "      <td>elu</td>\n",
       "      <td>elu</td>\n",
       "      <td>elu</td>\n",
       "      <td>elu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>batch_normalize</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>batch_size</th>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>...</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cnn_pad</th>\n",
       "      <td>same</td>\n",
       "      <td>same</td>\n",
       "      <td>same</td>\n",
       "      <td>same</td>\n",
       "      <td>same</td>\n",
       "      <td>same</td>\n",
       "      <td>same</td>\n",
       "      <td>same</td>\n",
       "      <td>same</td>\n",
       "      <td>same</td>\n",
       "      <td>...</td>\n",
       "      <td>same</td>\n",
       "      <td>same</td>\n",
       "      <td>same</td>\n",
       "      <td>same</td>\n",
       "      <td>same</td>\n",
       "      <td>same</td>\n",
       "      <td>same</td>\n",
       "      <td>same</td>\n",
       "      <td>same</td>\n",
       "      <td>same</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cnn_stride</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>current_time</th>\n",
       "      <td>2018-01-08-08-23</td>\n",
       "      <td>2018-01-07-01-39</td>\n",
       "      <td>2018-01-07-10-38</td>\n",
       "      <td>2018-01-08-09-23</td>\n",
       "      <td>2018-01-06-23-16</td>\n",
       "      <td>2018-01-07-20-36</td>\n",
       "      <td>2018-01-06-16-53</td>\n",
       "      <td>2018-01-06-00-47</td>\n",
       "      <td>2018-01-05-18-05</td>\n",
       "      <td>2018-01-06-00-18</td>\n",
       "      <td>...</td>\n",
       "      <td>2018-01-06-12-01</td>\n",
       "      <td>2018-01-05-18-40</td>\n",
       "      <td>2018-01-05-14-21</td>\n",
       "      <td>2018-01-05-20-21</td>\n",
       "      <td>2018-01-05-21-44</td>\n",
       "      <td>2018-01-05-20-59</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-01-05-17-41</td>\n",
       "      <td>2018-01-06-10-17</td>\n",
       "      <td>2018-01-07-11-45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>delta_delta</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dropout_prob</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>elapsed</th>\n",
       "      <td>3264</td>\n",
       "      <td>3290</td>\n",
       "      <td>3236</td>\n",
       "      <td>2209</td>\n",
       "      <td>3133</td>\n",
       "      <td>4061</td>\n",
       "      <td>11757</td>\n",
       "      <td>3047</td>\n",
       "      <td>1802</td>\n",
       "      <td>1671</td>\n",
       "      <td>...</td>\n",
       "      <td>5186</td>\n",
       "      <td>2958</td>\n",
       "      <td>8094</td>\n",
       "      <td>1831</td>\n",
       "      <td>4538</td>\n",
       "      <td>2491</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1008</td>\n",
       "      <td>1425</td>\n",
       "      <td>659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>end_time</th>\n",
       "      <td>2018-01-08-09-18</td>\n",
       "      <td>2018-01-07-02-34</td>\n",
       "      <td>2018-01-07-11-32</td>\n",
       "      <td>2018-01-08-10-00</td>\n",
       "      <td>2018-01-07-00-08</td>\n",
       "      <td>2018-01-07-21-44</td>\n",
       "      <td>2018-01-06-20-09</td>\n",
       "      <td>2018-01-06-01-38</td>\n",
       "      <td>2018-01-05-18-35</td>\n",
       "      <td>2018-01-06-00-46</td>\n",
       "      <td>...</td>\n",
       "      <td>2018-01-06-13-28</td>\n",
       "      <td>2018-01-05-19-30</td>\n",
       "      <td>2018-01-05-16-35</td>\n",
       "      <td>2018-01-05-20-51</td>\n",
       "      <td>2018-01-05-22-59</td>\n",
       "      <td>2018-01-05-21-40</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-01-05-17-58</td>\n",
       "      <td>2018-01-06-10-41</td>\n",
       "      <td>2018-01-07-11-56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>epoch_dur</th>\n",
       "      <td>93.2571</td>\n",
       "      <td>94</td>\n",
       "      <td>87.4595</td>\n",
       "      <td>84.9615</td>\n",
       "      <td>130.542</td>\n",
       "      <td>116.029</td>\n",
       "      <td>132.101</td>\n",
       "      <td>70.8605</td>\n",
       "      <td>NaN</td>\n",
       "      <td>53.9032</td>\n",
       "      <td>...</td>\n",
       "      <td>117.864</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>61.0333</td>\n",
       "      <td>90.76</td>\n",
       "      <td>73.2647</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>71.25</td>\n",
       "      <td>94.1429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>epochs</th>\n",
       "      <td>35</td>\n",
       "      <td>35</td>\n",
       "      <td>37</td>\n",
       "      <td>26</td>\n",
       "      <td>24</td>\n",
       "      <td>35</td>\n",
       "      <td>89</td>\n",
       "      <td>43</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31</td>\n",
       "      <td>...</td>\n",
       "      <td>44</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30</td>\n",
       "      <td>50</td>\n",
       "      <td>34</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>filters_start</th>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>...</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>60</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>filters_step</th>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>40</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>25</td>\n",
       "      <td>50</td>\n",
       "      <td>25</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>10</td>\n",
       "      <td>40</td>\n",
       "      <td>60</td>\n",
       "      <td>60</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>init_stdd</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>...</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kernel_size</th>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>l2_reg</th>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lr_patience</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lr_step</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n_dft</th>\n",
       "      <td>512</td>\n",
       "      <td>512</td>\n",
       "      <td>512</td>\n",
       "      <td>512</td>\n",
       "      <td>512</td>\n",
       "      <td>512</td>\n",
       "      <td>512</td>\n",
       "      <td>512</td>\n",
       "      <td>512</td>\n",
       "      <td>512</td>\n",
       "      <td>...</td>\n",
       "      <td>512</td>\n",
       "      <td>512</td>\n",
       "      <td>256</td>\n",
       "      <td>512</td>\n",
       "      <td>512</td>\n",
       "      <td>512</td>\n",
       "      <td>256</td>\n",
       "      <td>1024</td>\n",
       "      <td>512</td>\n",
       "      <td>512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n_hop</th>\n",
       "      <td>256</td>\n",
       "      <td>256</td>\n",
       "      <td>256</td>\n",
       "      <td>256</td>\n",
       "      <td>256</td>\n",
       "      <td>256</td>\n",
       "      <td>256</td>\n",
       "      <td>256</td>\n",
       "      <td>256</td>\n",
       "      <td>256</td>\n",
       "      <td>...</td>\n",
       "      <td>256</td>\n",
       "      <td>256</td>\n",
       "      <td>128</td>\n",
       "      <td>256</td>\n",
       "      <td>256</td>\n",
       "      <td>256</td>\n",
       "      <td>128</td>\n",
       "      <td>512</td>\n",
       "      <td>256</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n_mels</th>\n",
       "      <td>126</td>\n",
       "      <td>126</td>\n",
       "      <td>126</td>\n",
       "      <td>126</td>\n",
       "      <td>120</td>\n",
       "      <td>126</td>\n",
       "      <td>120</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>...</td>\n",
       "      <td>120</td>\n",
       "      <td>80</td>\n",
       "      <td>250</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>120</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n_mfcc</th>\n",
       "      <td>63</td>\n",
       "      <td>63</td>\n",
       "      <td>63</td>\n",
       "      <td>63</td>\n",
       "      <td>60</td>\n",
       "      <td>63</td>\n",
       "      <td>60</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>...</td>\n",
       "      <td>60</td>\n",
       "      <td>40</td>\n",
       "      <td>125</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>125</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p_transform</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pool</th>\n",
       "      <td>avg</td>\n",
       "      <td>max</td>\n",
       "      <td>max</td>\n",
       "      <td>avg</td>\n",
       "      <td>max</td>\n",
       "      <td>max</td>\n",
       "      <td>max</td>\n",
       "      <td>max</td>\n",
       "      <td>max</td>\n",
       "      <td>max</td>\n",
       "      <td>...</td>\n",
       "      <td>max</td>\n",
       "      <td>max</td>\n",
       "      <td>max</td>\n",
       "      <td>max</td>\n",
       "      <td>max</td>\n",
       "      <td>max</td>\n",
       "      <td>max</td>\n",
       "      <td>max</td>\n",
       "      <td>max</td>\n",
       "      <td>max</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pool_pad</th>\n",
       "      <td>same</td>\n",
       "      <td>same</td>\n",
       "      <td>same</td>\n",
       "      <td>valid</td>\n",
       "      <td>same</td>\n",
       "      <td>same</td>\n",
       "      <td>same</td>\n",
       "      <td>same</td>\n",
       "      <td>same</td>\n",
       "      <td>same</td>\n",
       "      <td>...</td>\n",
       "      <td>same</td>\n",
       "      <td>same</td>\n",
       "      <td>same</td>\n",
       "      <td>same</td>\n",
       "      <td>same</td>\n",
       "      <td>same</td>\n",
       "      <td>same</td>\n",
       "      <td>same</td>\n",
       "      <td>same</td>\n",
       "      <td>same</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>power_melgram</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>regularize</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>return_decibel_melgram</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shift</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_acc</th>\n",
       "      <td>0.930457</td>\n",
       "      <td>0.930816</td>\n",
       "      <td>0.931043</td>\n",
       "      <td>0.937396</td>\n",
       "      <td>0.935864</td>\n",
       "      <td>0.933231</td>\n",
       "      <td>0.928642</td>\n",
       "      <td>0.949005</td>\n",
       "      <td>0.920568</td>\n",
       "      <td>0.931289</td>\n",
       "      <td>...</td>\n",
       "      <td>0.945092</td>\n",
       "      <td>0.939022</td>\n",
       "      <td>0.929209</td>\n",
       "      <td>0.931383</td>\n",
       "      <td>0.937717</td>\n",
       "      <td>0.93265</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.885683</td>\n",
       "      <td>0.625548</td>\n",
       "      <td>0.615452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_loss</th>\n",
       "      <td>0.122492</td>\n",
       "      <td>0.12139</td>\n",
       "      <td>0.122794</td>\n",
       "      <td>0.113927</td>\n",
       "      <td>0.11611</td>\n",
       "      <td>0.123511</td>\n",
       "      <td>0.21844</td>\n",
       "      <td>0.200943</td>\n",
       "      <td>0.241976</td>\n",
       "      <td>0.237216</td>\n",
       "      <td>...</td>\n",
       "      <td>0.226688</td>\n",
       "      <td>0.24595</td>\n",
       "      <td>0.228661</td>\n",
       "      <td>0.256252</td>\n",
       "      <td>0.256859</td>\n",
       "      <td>0.265896</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.326288</td>\n",
       "      <td>0.88137</td>\n",
       "      <td>6.3797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_state</th>\n",
       "      <td>[train]</td>\n",
       "      <td>[train]</td>\n",
       "      <td>[train]</td>\n",
       "      <td>[train]</td>\n",
       "      <td>[train]</td>\n",
       "      <td>[train, test]</td>\n",
       "      <td>[train]</td>\n",
       "      <td>[train]</td>\n",
       "      <td>[train]</td>\n",
       "      <td>[train]</td>\n",
       "      <td>...</td>\n",
       "      <td>[train]</td>\n",
       "      <td>[train]</td>\n",
       "      <td>[train]</td>\n",
       "      <td>[train]</td>\n",
       "      <td>[train]</td>\n",
       "      <td>[train]</td>\n",
       "      <td>[train]</td>\n",
       "      <td>[train]</td>\n",
       "      <td>[train]</td>\n",
       "      <td>[train]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>val_acc</th>\n",
       "      <td>0.952024</td>\n",
       "      <td>0.952872</td>\n",
       "      <td>0.952448</td>\n",
       "      <td>0.952872</td>\n",
       "      <td>0.953791</td>\n",
       "      <td>0.954661</td>\n",
       "      <td>0.953649</td>\n",
       "      <td>0.962481</td>\n",
       "      <td>0.948492</td>\n",
       "      <td>0.952095</td>\n",
       "      <td>...</td>\n",
       "      <td>0.958525</td>\n",
       "      <td>0.958313</td>\n",
       "      <td>0.947432</td>\n",
       "      <td>0.950823</td>\n",
       "      <td>0.957324</td>\n",
       "      <td>0.951176</td>\n",
       "      <td>0.940366</td>\n",
       "      <td>0.920441</td>\n",
       "      <td>0.61676</td>\n",
       "      <td>0.599802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>val_loss</th>\n",
       "      <td>0.131799</td>\n",
       "      <td>0.134524</td>\n",
       "      <td>0.13635</td>\n",
       "      <td>0.140272</td>\n",
       "      <td>0.140824</td>\n",
       "      <td>0.143841</td>\n",
       "      <td>0.222573</td>\n",
       "      <td>0.233833</td>\n",
       "      <td>0.244494</td>\n",
       "      <td>0.245938</td>\n",
       "      <td>...</td>\n",
       "      <td>0.266385</td>\n",
       "      <td>0.267767</td>\n",
       "      <td>0.269057</td>\n",
       "      <td>0.27074</td>\n",
       "      <td>0.283327</td>\n",
       "      <td>0.284709</td>\n",
       "      <td>0.302892</td>\n",
       "      <td>0.307334</td>\n",
       "      <td>1.58544</td>\n",
       "      <td>15.2463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>val_state</th>\n",
       "      <td>[val, test]</td>\n",
       "      <td>[val, test]</td>\n",
       "      <td>[val, test]</td>\n",
       "      <td>[val, test]</td>\n",
       "      <td>[val, test]</td>\n",
       "      <td>[val]</td>\n",
       "      <td>[val, test]</td>\n",
       "      <td>[val, test]</td>\n",
       "      <td>[val, test]</td>\n",
       "      <td>[val, test]</td>\n",
       "      <td>...</td>\n",
       "      <td>[val, test]</td>\n",
       "      <td>[val, test]</td>\n",
       "      <td>[val, test]</td>\n",
       "      <td>[val, test]</td>\n",
       "      <td>[val, test]</td>\n",
       "      <td>[val, test]</td>\n",
       "      <td>[val, test]</td>\n",
       "      <td>[val, test]</td>\n",
       "      <td>[val, test]</td>\n",
       "      <td>[val, test]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vol_range</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>37 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      21                17                18  \\\n",
       "activation                           elu               elu               elu   \n",
       "batch_normalize                     True              True              True   \n",
       "batch_size                            64                64                64   \n",
       "cnn_pad                             same              same              same   \n",
       "cnn_stride                             1                 1                 1   \n",
       "current_time            2018-01-08-08-23  2018-01-07-01-39  2018-01-07-10-38   \n",
       "delta_delta                         True              True              True   \n",
       "dropout_prob                         0.2               0.2               0.2   \n",
       "elapsed                             3264              3290              3236   \n",
       "end_time                2018-01-08-09-18  2018-01-07-02-34  2018-01-07-11-32   \n",
       "epoch_dur                        93.2571                94           87.4595   \n",
       "epochs                                35                35                37   \n",
       "filters_start                         30                30                30   \n",
       "filters_step                          50                50                40   \n",
       "init_stdd                           0.01              0.01              0.01   \n",
       "kernel_size                           10                10                10   \n",
       "l2_reg                            0.0005            0.0005            0.0005   \n",
       "lr_patience                            2                 2                 2   \n",
       "lr_step                              0.2               0.2               0.2   \n",
       "n_dft                                512               512               512   \n",
       "n_hop                                256               256               256   \n",
       "n_mels                               126               126               126   \n",
       "n_mfcc                                63                63                63   \n",
       "p_transform                            1                 1                 1   \n",
       "pool                                 avg               max               max   \n",
       "pool_pad                            same              same              same   \n",
       "power_melgram                          2                 2                 2   \n",
       "regularize                         False             False             False   \n",
       "return_decibel_melgram              True              True              True   \n",
       "shift                                  1                 1                 1   \n",
       "train_acc                       0.930457          0.930816          0.931043   \n",
       "train_loss                      0.122492           0.12139          0.122794   \n",
       "train_state                      [train]           [train]           [train]   \n",
       "val_acc                         0.952024          0.952872          0.952448   \n",
       "val_loss                        0.131799          0.134524           0.13635   \n",
       "val_state                    [val, test]       [val, test]       [val, test]   \n",
       "vol_range                            0.1               0.1               0.1   \n",
       "\n",
       "                                      22                16                20  \\\n",
       "activation                           elu               elu               elu   \n",
       "batch_normalize                     True              True              True   \n",
       "batch_size                            64                64                64   \n",
       "cnn_pad                             same              same              same   \n",
       "cnn_stride                             1                 1                 1   \n",
       "current_time            2018-01-08-09-23  2018-01-06-23-16  2018-01-07-20-36   \n",
       "delta_delta                         True              True              True   \n",
       "dropout_prob                         0.1              0.15               0.2   \n",
       "elapsed                             2209              3133              4061   \n",
       "end_time                2018-01-08-10-00  2018-01-07-00-08  2018-01-07-21-44   \n",
       "epoch_dur                        84.9615           130.542           116.029   \n",
       "epochs                                26                24                35   \n",
       "filters_start                         30                50                50   \n",
       "filters_step                          50                50                25   \n",
       "init_stdd                           0.01              0.01              0.01   \n",
       "kernel_size                           10                10                10   \n",
       "l2_reg                            0.0005            0.0005            0.0005   \n",
       "lr_patience                            2                 2                 2   \n",
       "lr_step                              0.2               0.2               0.2   \n",
       "n_dft                                512               512               512   \n",
       "n_hop                                256               256               256   \n",
       "n_mels                               126               120               126   \n",
       "n_mfcc                                63                60                63   \n",
       "p_transform                            1                 1                 1   \n",
       "pool                                 avg               max               max   \n",
       "pool_pad                           valid              same              same   \n",
       "power_melgram                          2                 2                 2   \n",
       "regularize                         False             False             False   \n",
       "return_decibel_melgram              True              True              True   \n",
       "shift                                  1                 1                 1   \n",
       "train_acc                       0.937396          0.935864          0.933231   \n",
       "train_loss                      0.113927           0.11611          0.123511   \n",
       "train_state                      [train]           [train]     [train, test]   \n",
       "val_acc                         0.952872          0.953791          0.954661   \n",
       "val_loss                        0.140272          0.140824          0.143841   \n",
       "val_state                    [val, test]       [val, test]             [val]   \n",
       "vol_range                            0.1               0.1               0.1   \n",
       "\n",
       "                                      15                11                3   \\\n",
       "activation                           elu               elu               elu   \n",
       "batch_normalize                     True              True              True   \n",
       "batch_size                            64               128               128   \n",
       "cnn_pad                             same              same              same   \n",
       "cnn_stride                             1                 1                 1   \n",
       "current_time            2018-01-06-16-53  2018-01-06-00-47  2018-01-05-18-05   \n",
       "delta_delta                         True              True               NaN   \n",
       "dropout_prob                        0.15               0.1               0.1   \n",
       "elapsed                            11757              3047              1802   \n",
       "end_time                2018-01-06-20-09  2018-01-06-01-38  2018-01-05-18-35   \n",
       "epoch_dur                        132.101           70.8605               NaN   \n",
       "epochs                                89                43               NaN   \n",
       "filters_start                         50                50                40   \n",
       "filters_step                          50                25                10   \n",
       "init_stdd                           0.01              0.01              0.01   \n",
       "kernel_size                           10                10                10   \n",
       "l2_reg                            0.0005            0.0005            0.0005   \n",
       "lr_patience                            2                 2               NaN   \n",
       "lr_step                              0.2               0.2               NaN   \n",
       "n_dft                                512               512               512   \n",
       "n_hop                                256               256               256   \n",
       "n_mels                               120                80                80   \n",
       "n_mfcc                                60                40                40   \n",
       "p_transform                            1                 1                 1   \n",
       "pool                                 max               max               max   \n",
       "pool_pad                            same              same              same   \n",
       "power_melgram                          2                 2               NaN   \n",
       "regularize                          True              True              True   \n",
       "return_decibel_melgram              True              True               NaN   \n",
       "shift                                  1                 1                 1   \n",
       "train_acc                       0.928642          0.949005          0.920568   \n",
       "train_loss                       0.21844          0.200943          0.241976   \n",
       "train_state                      [train]           [train]           [train]   \n",
       "val_acc                         0.953649          0.962481          0.948492   \n",
       "val_loss                        0.222573          0.233833          0.244494   \n",
       "val_state                    [val, test]       [val, test]       [val, test]   \n",
       "vol_range                            0.1               0.1               0.1   \n",
       "\n",
       "                                      10        ...                       14  \\\n",
       "activation                           elu        ...                      elu   \n",
       "batch_normalize                     True        ...                     True   \n",
       "batch_size                           128        ...                      128   \n",
       "cnn_pad                             same        ...                     same   \n",
       "cnn_stride                             1        ...                        1   \n",
       "current_time            2018-01-06-00-18        ...         2018-01-06-12-01   \n",
       "delta_delta                         True        ...                     True   \n",
       "dropout_prob                         0.1        ...                      0.1   \n",
       "elapsed                             1671        ...                     5186   \n",
       "end_time                2018-01-06-00-46        ...         2018-01-06-13-28   \n",
       "epoch_dur                        53.9032        ...                  117.864   \n",
       "epochs                                31        ...                       44   \n",
       "filters_start                         40        ...                       50   \n",
       "filters_step                          10        ...                       50   \n",
       "init_stdd                           0.01        ...                     0.01   \n",
       "kernel_size                           10        ...                       10   \n",
       "l2_reg                            0.0005        ...                   0.0005   \n",
       "lr_patience                          NaN        ...                        2   \n",
       "lr_step                              0.2        ...                      0.2   \n",
       "n_dft                                512        ...                      512   \n",
       "n_hop                                256        ...                      256   \n",
       "n_mels                                80        ...                      120   \n",
       "n_mfcc                                40        ...                       60   \n",
       "p_transform                            1        ...                        1   \n",
       "pool                                 max        ...                      max   \n",
       "pool_pad                            same        ...                     same   \n",
       "power_melgram                        NaN        ...                        2   \n",
       "regularize                          True        ...                     True   \n",
       "return_decibel_melgram               NaN        ...                     True   \n",
       "shift                                  1        ...                        1   \n",
       "train_acc                       0.931289        ...                 0.945092   \n",
       "train_loss                      0.237216        ...                 0.226688   \n",
       "train_state                      [train]        ...                  [train]   \n",
       "val_acc                         0.952095        ...                 0.958525   \n",
       "val_loss                        0.245938        ...                 0.266385   \n",
       "val_state                    [val, test]        ...              [val, test]   \n",
       "vol_range                            0.1        ...                      0.1   \n",
       "\n",
       "                                      4                 1                 6   \\\n",
       "activation                           elu               elu               elu   \n",
       "batch_normalize                     True              True              True   \n",
       "batch_size                           128               128               128   \n",
       "cnn_pad                             same              same              same   \n",
       "cnn_stride                             1                 1                 1   \n",
       "current_time            2018-01-05-18-40  2018-01-05-14-21  2018-01-05-20-21   \n",
       "delta_delta                          NaN               NaN               NaN   \n",
       "dropout_prob                         0.1               0.1               0.1   \n",
       "elapsed                             2958              8094              1831   \n",
       "end_time                2018-01-05-19-30  2018-01-05-16-35  2018-01-05-20-51   \n",
       "epoch_dur                            NaN               NaN           61.0333   \n",
       "epochs                               NaN               NaN                30   \n",
       "filters_start                         50                40                40   \n",
       "filters_step                          50                10                40   \n",
       "init_stdd                           0.01              0.01              0.01   \n",
       "kernel_size                           10                 6                10   \n",
       "l2_reg                            0.0005            0.0005            0.0005   \n",
       "lr_patience                          NaN               NaN               NaN   \n",
       "lr_step                              NaN               NaN               NaN   \n",
       "n_dft                                512               256               512   \n",
       "n_hop                                256               128               256   \n",
       "n_mels                                80               250                80   \n",
       "n_mfcc                                40               125                40   \n",
       "p_transform                            1                 1                 1   \n",
       "pool                                 max               max               max   \n",
       "pool_pad                            same              same              same   \n",
       "power_melgram                        NaN               NaN               NaN   \n",
       "regularize                          True              True              True   \n",
       "return_decibel_melgram               NaN               NaN               NaN   \n",
       "shift                                  1               0.3                 1   \n",
       "train_acc                       0.939022          0.929209          0.931383   \n",
       "train_loss                       0.24595          0.228661          0.256252   \n",
       "train_state                      [train]           [train]           [train]   \n",
       "val_acc                         0.958313          0.947432          0.950823   \n",
       "val_loss                        0.267767          0.269057           0.27074   \n",
       "val_state                    [val, test]       [val, test]       [val, test]   \n",
       "vol_range                            0.1               0.1               0.1   \n",
       "\n",
       "                                      8                 7            0   \\\n",
       "activation                           elu               elu          elu   \n",
       "batch_normalize                     True              True         True   \n",
       "batch_size                           128               128          128   \n",
       "cnn_pad                             same              same         same   \n",
       "cnn_stride                             1                 1            1   \n",
       "current_time            2018-01-05-21-44  2018-01-05-20-59          NaN   \n",
       "delta_delta                          NaN               NaN          NaN   \n",
       "dropout_prob                         0.2               0.1          0.1   \n",
       "elapsed                             4538              2491          NaN   \n",
       "end_time                2018-01-05-22-59  2018-01-05-21-40          NaN   \n",
       "epoch_dur                          90.76           73.2647          NaN   \n",
       "epochs                                50                34          NaN   \n",
       "filters_start                         60                40           40   \n",
       "filters_step                          60                60           10   \n",
       "init_stdd                           0.01              0.01         0.01   \n",
       "kernel_size                           10                10            4   \n",
       "l2_reg                            0.0005            0.0005       0.0005   \n",
       "lr_patience                          NaN               NaN          NaN   \n",
       "lr_step                              NaN               NaN          NaN   \n",
       "n_dft                                512               512          256   \n",
       "n_hop                                256               256          128   \n",
       "n_mels                                80                80          120   \n",
       "n_mfcc                                40                40          125   \n",
       "p_transform                            1                 1            1   \n",
       "pool                                 max               max          max   \n",
       "pool_pad                            same              same         same   \n",
       "power_melgram                        NaN               NaN          NaN   \n",
       "regularize                          True              True         True   \n",
       "return_decibel_melgram               NaN               NaN          NaN   \n",
       "shift                                  1                 1          0.3   \n",
       "train_acc                       0.937717           0.93265          NaN   \n",
       "train_loss                      0.256859          0.265896          NaN   \n",
       "train_state                      [train]           [train]      [train]   \n",
       "val_acc                         0.957324          0.951176     0.940366   \n",
       "val_loss                        0.283327          0.284709     0.302892   \n",
       "val_state                    [val, test]       [val, test]  [val, test]   \n",
       "vol_range                            0.1               0.1          0.1   \n",
       "\n",
       "                                      2                 12                19  \n",
       "activation                           elu               elu               elu  \n",
       "batch_normalize                     True              True             False  \n",
       "batch_size                           128               128                64  \n",
       "cnn_pad                             same              same              same  \n",
       "cnn_stride                             1                 1                 1  \n",
       "current_time            2018-01-05-17-41  2018-01-06-10-17  2018-01-07-11-45  \n",
       "delta_delta                          NaN              True              True  \n",
       "dropout_prob                         0.1              0.15               0.2  \n",
       "elapsed                             1008              1425               659  \n",
       "end_time                2018-01-05-17-58  2018-01-06-10-41  2018-01-07-11-56  \n",
       "epoch_dur                            NaN             71.25           94.1429  \n",
       "epochs                               NaN                20                 7  \n",
       "filters_start                         40                50                50  \n",
       "filters_step                          10                25                25  \n",
       "init_stdd                           0.01              0.01              0.01  \n",
       "kernel_size                           10                10                10  \n",
       "l2_reg                            0.0005            0.0005            0.0005  \n",
       "lr_patience                          NaN                 2                 2  \n",
       "lr_step                              NaN               0.2               0.2  \n",
       "n_dft                               1024               512               512  \n",
       "n_hop                                512               256               256  \n",
       "n_mels                                80                80               126  \n",
       "n_mfcc                                40                40                63  \n",
       "p_transform                            1                 1                 1  \n",
       "pool                                 max               max               max  \n",
       "pool_pad                            same              same              same  \n",
       "power_melgram                        NaN                 2                 2  \n",
       "regularize                          True              True             False  \n",
       "return_decibel_melgram               NaN             False              True  \n",
       "shift                                  1                 1                 1  \n",
       "train_acc                       0.885683          0.625548          0.615452  \n",
       "train_loss                      0.326288           0.88137            6.3797  \n",
       "train_state                      [train]           [train]           [train]  \n",
       "val_acc                         0.920441           0.61676          0.599802  \n",
       "val_loss                        0.307334           1.58544           15.2463  \n",
       "val_state                    [val, test]       [val, test]       [val, test]  \n",
       "vol_range                            0.1               0.1               0.1  \n",
       "\n",
       "[37 rows x 23 columns]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "runs_df.sort_values(\"val_loss\").T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-02T22:09:53.000122Z",
     "start_time": "2017-12-02T22:09:52.971125Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot_history(log_df):\n",
    "\n",
    "    measures = np.unique(\n",
    "        [m.replace('val_', '') for m in log_df.columns if m != \"epoch\"])\n",
    "    num_meas = len(measures)\n",
    "    x = arange(len(log_df))\n",
    "    fix, axes = subplots(\n",
    "        nrows=num_meas,\n",
    "        ncols=1,\n",
    "        squeeze=True,\n",
    "        sharex=True,\n",
    "        figsize=(10, 2.5 * num_meas),\n",
    "        tight_layout=True)\n",
    "    if num_meas == 1:\n",
    "        axes = [axes]\n",
    "    for i, meas in enumerate(measures):\n",
    "        if meas == \"lr\":\n",
    "            continue\n",
    "        axes[i].plot(x, log_df[meas], label=meas)\n",
    "        if \"val_\" + meas in log_df.columns:\n",
    "            axes[i].plot(x, log_df[\"val_\" + meas], label=\"val_\" + meas)\n",
    "        axes[i].legend()\n",
    "        if meas in [\"acc\", \"sparse_top_k_categorical_accuracy\"]:\n",
    "            axes[i].set_ylim((.05 - 0.01, 1.01))\n",
    "    axes[-1].set_xlabel(\"epoch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-02T22:09:54.015229Z",
     "start_time": "2017-12-02T22:09:53.636496Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/matplotlib/figure.py:1999: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.\n",
      "  warnings.warn(\"This figure includes Axes that are not compatible \"\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAs8AAAFgCAYAAABE0JQRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f3b31a8f828>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_history(pandas.read_csv(\"logs/ff/training.log\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-02T22:09:57.438702Z",
     "start_time": "2017-12-02T22:09:56.931534Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/matplotlib/figure.py:1999: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.\n",
      "  warnings.warn(\"This figure includes Axes that are not compatible \"\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAs8AAAIUCAYAAADli8FbAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQAYAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f3b31ffce80>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_history(pandas.read_csv(\"logs/cnn/training.log\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
