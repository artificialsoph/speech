{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-08T05:04:57.403659Z",
     "start_time": "2017-12-08T05:04:55.887357Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import keras.backend as K\n",
    "import kapre\n",
    "import pandas\n",
    "import seaborn\n",
    "import pandas as pd\n",
    "import scipy.io.wavfile as wav\n",
    "seaborn.set_style(\"whitegrid\")\n",
    "\n",
    "%pylab inline\n",
    "# https://github.com/keunwoochoi/kapre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-08T05:04:58.621064Z",
     "start_time": "2017-12-08T05:04:58.512801Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fn</th>\n",
       "      <th>raw_label</th>\n",
       "      <th>state</th>\n",
       "      <th>label</th>\n",
       "      <th>label_weight</th>\n",
       "      <th>label_i</th>\n",
       "      <th>raw_label_i</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>222096</th>\n",
       "      <td>data/test/audio/clip_764ae2ee6.wav</td>\n",
       "      <td>NaN</td>\n",
       "      <td>submission</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36969</th>\n",
       "      <td>data/train/audio/down/aa753bb9_nohash_0.wav</td>\n",
       "      <td>down</td>\n",
       "      <td>val</td>\n",
       "      <td>down</td>\n",
       "      <td>2.368270</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205958</th>\n",
       "      <td>data/test/audio/clip_ada6c5e5a.wav</td>\n",
       "      <td>NaN</td>\n",
       "      <td>submission</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118554</th>\n",
       "      <td>data/test/audio/clip_d69a642dc.wav</td>\n",
       "      <td>NaN</td>\n",
       "      <td>submission</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221240</th>\n",
       "      <td>data/test/audio/clip_02c5ea061.wav</td>\n",
       "      <td>NaN</td>\n",
       "      <td>submission</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76266</th>\n",
       "      <td>data/test/audio/clip_30bdab2f2.wav</td>\n",
       "      <td>NaN</td>\n",
       "      <td>submission</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57453</th>\n",
       "      <td>data/train/audio/marvin/325a0c39_nohash_2.wav</td>\n",
       "      <td>marvin</td>\n",
       "      <td>train</td>\n",
       "      <td>unknown</td>\n",
       "      <td>0.136133</td>\n",
       "      <td>11.0</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82130</th>\n",
       "      <td>data/test/audio/clip_242dd784d.wav</td>\n",
       "      <td>NaN</td>\n",
       "      <td>submission</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198554</th>\n",
       "      <td>data/test/audio/clip_e4db3be01.wav</td>\n",
       "      <td>NaN</td>\n",
       "      <td>submission</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118556</th>\n",
       "      <td>data/test/audio/clip_a30801bd5.wav</td>\n",
       "      <td>NaN</td>\n",
       "      <td>submission</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   fn raw_label       state  \\\n",
       "222096             data/test/audio/clip_764ae2ee6.wav       NaN  submission   \n",
       "36969     data/train/audio/down/aa753bb9_nohash_0.wav      down         val   \n",
       "205958             data/test/audio/clip_ada6c5e5a.wav       NaN  submission   \n",
       "118554             data/test/audio/clip_d69a642dc.wav       NaN  submission   \n",
       "221240             data/test/audio/clip_02c5ea061.wav       NaN  submission   \n",
       "76266              data/test/audio/clip_30bdab2f2.wav       NaN  submission   \n",
       "57453   data/train/audio/marvin/325a0c39_nohash_2.wav    marvin       train   \n",
       "82130              data/test/audio/clip_242dd784d.wav       NaN  submission   \n",
       "198554             data/test/audio/clip_e4db3be01.wav       NaN  submission   \n",
       "118556             data/test/audio/clip_a30801bd5.wav       NaN  submission   \n",
       "\n",
       "          label  label_weight  label_i  raw_label_i  \n",
       "222096      NaN           NaN      NaN          NaN  \n",
       "36969      down      2.368270      3.0          3.0  \n",
       "205958      NaN           NaN      NaN          NaN  \n",
       "118554      NaN           NaN      NaN          NaN  \n",
       "221240      NaN           NaN      NaN          NaN  \n",
       "76266       NaN           NaN      NaN          NaN  \n",
       "57453   unknown      0.136133     11.0         30.0  \n",
       "82130       NaN           NaN      NaN          NaN  \n",
       "198554      NaN           NaN      NaN          NaN  \n",
       "118556      NaN           NaN      NaN          NaN  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex_df = pd.read_pickle(\"data/ex_df.pkl\")\n",
    "ex_df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-08T05:05:00.298541Z",
     "start_time": "2017-12-08T05:05:00.267591Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "submission    158538\n",
       "train          52888\n",
       "test            7095\n",
       "val             7058\n",
       "bg                 6\n",
       "Name: state, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex_df.state.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-08T05:05:01.154864Z",
     "start_time": "2017-12-08T05:05:01.086931Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/scipy/io/wavfile.py:273: WavFileWarning: Chunk (non-data) not understood, skipping it.\n",
      "  WavFileWarning)\n"
     ]
    }
   ],
   "source": [
    "bg_waves = [wav.read(fn)[1] for fn in ex_df[ex_df.state == \"bg\"].fn]\n",
    "maxlen = 16000\n",
    "\n",
    "def center_wave(wav_fn, vol_range=.1, displacement=.1, p_transform=.5):\n",
    "    \n",
    "    if wav_fn == \"silence\":\n",
    "        bg_wave = random.choice(bg_waves)\n",
    "        bg_start = np.random.randint(len(bg_wave)-maxlen)\n",
    "        wave = bg_wave[bg_start:bg_start+maxlen]\n",
    "\n",
    "    else:\n",
    "        wave = wav.read(wav_fn)[1]\n",
    "        \n",
    "        left_pad = (maxlen - wave.shape[0]) // 2\n",
    "        right_pad = maxlen - wave.shape[0] - left_pad\n",
    "        \n",
    "        wave = np.pad(\n",
    "            wave, (left_pad, right_pad), 'constant', constant_values=0)\n",
    "       \n",
    "        if vol_range > 0:\n",
    "            if np.random.rand() < p_transform:\n",
    "                \n",
    "                bg_vol = vol_range * np.random.rand(1)\n",
    "                wave = (1-bg_vol)*wave + bg_vol*center_wave(\"silence\", maxlen)\n",
    "                wave = np.clip(wave, -1, 1)\n",
    "        \n",
    "        if displacement > 0:\n",
    "            if np.random.rand() < p_transform:\n",
    "                displ = int(displacement*(2*np.random.rand()-1)*maxlen)\n",
    "                wave = np.roll(wave,displ)\n",
    "\n",
    "    return wave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-08T05:05:03.657342Z",
     "start_time": "2017-12-08T05:05:03.618891Z"
    }
   },
   "outputs": [],
   "source": [
    "def ex_generator(batch_size=32,\n",
    "                 shuffle=True,\n",
    "                 state=\"train\",\n",
    "                 vol_range=0,\n",
    "                 displacement=0,\n",
    "                 p_transform=0):\n",
    "\n",
    "    maxlen = 16000\n",
    "\n",
    "    epoch_df = ex_df[ex_df.state == state]\n",
    "    num_ex = len(epoch_df)\n",
    "    indices = np.arange(num_ex)\n",
    "\n",
    "    # epoch loop runs\n",
    "    while True:\n",
    "\n",
    "        # shuffle anew every epoch\n",
    "        if shuffle:\n",
    "            epoch_df = epoch_df.sample(frac=1)\n",
    "\n",
    "        # batch loop\n",
    "        for i in np.arange(0, num_ex, batch_size):\n",
    "\n",
    "            x = []\n",
    "\n",
    "            batch_df = epoch_df.iloc[i:i + batch_size:, :]\n",
    "\n",
    "            # example loop\n",
    "            for fn in batch_df.fn:\n",
    "\n",
    "                #get the processed file\n",
    "                item = center_wave(fn, vol_range=vol_range, displacement=displacement, p_transform=p_transform)\n",
    "\n",
    "                x.append(item.reshape((1,1,maxlen)))\n",
    "\n",
    "            x = np.concatenate(x,)\n",
    "            y = batch_df.raw_label_i.values[:, np.newaxis]\n",
    "            cw = batch_df.label_weight.values\n",
    "\n",
    "            yield x, y, cw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-08T05:06:28.207532Z",
     "start_time": "2017-12-08T05:06:27.742928Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 1, 16000)          0         \n",
      "_________________________________________________________________\n",
      "melspectrogram_1 (Melspectro (None, 125, 125, 1)       82173     \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 125, 125, 64)      640       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 125, 125, 64)      256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 63, 63, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 63, 63, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 63, 63, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 63, 63, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 32, 32, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 32, 32, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 16384)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               4194560   \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 32)                8224      \n",
      "=================================================================\n",
      "Total params: 4,360,221\n",
      "Trainable params: 4,277,664\n",
      "Non-trainable params: 82,557\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "dropout_prob = .5\n",
    "init_stddev = 0.01\n",
    "num_cat = 12\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "kernel_size = (3, 3)\n",
    "\n",
    "cnn_layers = [\n",
    "    keras.layers.InputLayer(input_shape=(1, 16000)),\n",
    "    \n",
    "    kapre.time_frequency.Melspectrogram(\n",
    "        sr=16000,\n",
    "        n_mels=125,\n",
    "        n_dft=256,\n",
    "        return_decibel_melgram=True),\n",
    "    \n",
    "#     kapre.time_frequency.Spectrogram(n_dft=512, n_hop=256, \n",
    "#           return_decibel_spectrogram=False, power_spectrogram=2.0, \n",
    "#           trainable_kernel=False),\n",
    "\n",
    "    keras.layers.Conv2D(\n",
    "        64,\n",
    "        kernel_size=kernel_size,\n",
    "        padding=\"same\",\n",
    "        activation=\"relu\",\n",
    "        kernel_initializer=keras.initializers.TruncatedNormal(\n",
    "            stddev=init_stddev)),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.MaxPooling2D(pool_size=(2, 2), padding='same'),\n",
    "    keras.layers.Dropout(dropout_prob),\n",
    "    \n",
    "    keras.layers.Conv2D(\n",
    "        64,\n",
    "        kernel_size=kernel_size,\n",
    "        padding=\"same\",\n",
    "        activation=\"relu\",\n",
    "        kernel_initializer=keras.initializers.TruncatedNormal(\n",
    "            stddev=init_stddev)),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.MaxPooling2D(pool_size=(2, 2), padding='same'),\n",
    "    keras.layers.Dropout(.9 * dropout_prob),\n",
    "    \n",
    "    keras.layers.Conv2D(\n",
    "        64,\n",
    "        kernel_size=kernel_size,\n",
    "        padding=\"same\",\n",
    "        activation=\"relu\",\n",
    "        kernel_initializer=keras.initializers.TruncatedNormal(\n",
    "            stddev=init_stddev)),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.MaxPooling2D(pool_size=(2, 2), padding='same'),\n",
    "    keras.layers.Dropout(.8 * dropout_prob),\n",
    "    \n",
    "#     keras.layers.Conv2D(\n",
    "#         64,\n",
    "#         kernel_size=kernel_size,\n",
    "#         padding=\"same\",\n",
    "#         activation=\"relu\",\n",
    "#         kernel_initializer=keras.initializers.TruncatedNormal(\n",
    "#             stddev=init_stddev)),\n",
    "#     keras.layers.BatchNormalization(),\n",
    "#     keras.layers.MaxPooling2D(pool_size=(2, 2), padding='same'),\n",
    "#     keras.layers.Dropout(.7 * dropout_prob),\n",
    "    \n",
    "#     keras.layers.Conv2D(\n",
    "#         64,\n",
    "#         kernel_size=kernel_size,\n",
    "#         padding=\"same\",\n",
    "#         activation=\"relu\",\n",
    "#         kernel_initializer=keras.initializers.TruncatedNormal(\n",
    "#             stddev=init_stddev)),\n",
    "#     keras.layers.BatchNormalization(),\n",
    "#     keras.layers.MaxPooling2D(pool_size=(2, 2), padding='same'),\n",
    "#     keras.layers.Dropout(.6 * dropout_prob),\n",
    "    \n",
    "    keras.layers.Flatten(),\n",
    "\n",
    "    # Hidden Layer 1\n",
    "    keras.layers.Dense(\n",
    "        256,\n",
    "        activation=\"elu\",\n",
    "        kernel_initializer=keras.initializers.TruncatedNormal(\n",
    "            stddev=init_stddev)),\n",
    "    keras.layers.Dropout(dropout_prob),\n",
    "\n",
    "    # Classification Layer\n",
    "    keras.layers.Dense(\n",
    "        int(ex_df.raw_label_i.max()+1),\n",
    "        activation=\"softmax\",\n",
    "        kernel_initializer=keras.initializers.TruncatedNormal(\n",
    "            stddev=init_stddev)),\n",
    "]\n",
    "cnn_model = keras.Sequential(cnn_layers)\n",
    "cnn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-08T05:14:58.558523Z",
     "start_time": "2017-12-08T05:14:58.536667Z"
    }
   },
   "outputs": [],
   "source": [
    "def acc_12(y_true, y_pred):\n",
    "    \"\"\" given y vectors based on 32 categories, returns accuracy based on first 12\"\"\"\n",
    "    y_pred = K.cast(K.argmax(y_pred, axis=-1), K.floatx())\n",
    "    y_true = K.max(y_true, axis=-1)\n",
    "    y_true = K.minimum(y_true, 11.)\n",
    "    y_pred = K.minimum(y_pred, 11.)\n",
    "    return K.mean(K.equal(y_true, y_pred))\n",
    "\n",
    "\n",
    "def comb_loss(y_true_32, y_pred_32):\n",
    "    \"\"\" given y vectors based on 32 categories, returns accuracy based on first 12\"\"\"\n",
    "    mask = K.greater_equal(K.reshape(K.arange(0, 32), (-1, 32)), 11)\n",
    "    masked_y = K.cast(mask, \"float32\")*y_pred_32\n",
    "    top_21 = K.sum(masked_y, axis=1, keepdims=True)\n",
    "    y_pred_12 = K.concatenate((y_pred_32[:, 0:11], top_21), axis=1)\n",
    "    y_true_12 = K.minimum(y_true_32, 11.)\n",
    "\n",
    "    return (K.sparse_categorical_crossentropy(y_true_12, y_pred_12) +\n",
    "            K.sparse_categorical_crossentropy(y_true_32, y_pred_32)) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-08T05:14:58.952994Z",
     "start_time": "2017-12-08T05:14:58.947233Z"
    }
   },
   "outputs": [],
   "source": [
    "y_pred_32 = K.ones((64,32))*.1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-08T05:14:59.352451Z",
     "start_time": "2017-12-08T05:14:59.342991Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'mul_11:0' shape=(64, 32) dtype=float32>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask = K.greater_equal(K.reshape(K.arange(0, 32), (-1, 32)), 11)\n",
    "K.cast(mask, \"float32\")*y_pred_32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-08T05:15:00.052729Z",
     "start_time": "2017-12-08T05:14:59.842564Z"
    }
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "callbacks = [\n",
    "    keras.callbacks.TensorBoard(\n",
    "        log_dir='logs/tb',\n",
    "        histogram_freq=0,\n",
    "        batch_size=batch_size,\n",
    "        write_graph=False,\n",
    "        write_grads=False,\n",
    "        write_images=False,\n",
    "    ),\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        filepath='logs/cnn/mel.weights.{epoch:02d}-{val_loss:.3f}.hdf5',\n",
    "        monitor='val_loss',\n",
    "        verbose=1,\n",
    "        save_best_only=True,\n",
    "        save_weights_only=False,\n",
    "        mode='auto',\n",
    "        period=1),\n",
    "    keras.callbacks.CSVLogger('logs/cnn/spec-training.log'),\n",
    "    keras.callbacks.EarlyStopping(patience=6, verbose=1),\n",
    "    keras.callbacks.ReduceLROnPlateau(\n",
    "        factor=0.2, patience=1, verbose=1, min_lr=1e-8)\n",
    "]\n",
    "\n",
    "cnn_model = keras.Sequential(cnn_layers)\n",
    "cnn_model.compile(\n",
    "    loss=comb_loss,\n",
    "    optimizer='nadam',\n",
    "    metrics=['accuracy', acc_12])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-08T05:21:09.554795Z",
     "start_time": "2017-12-08T05:15:03.356327Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1652/1652 [============================>.] - ETA: 0s - loss: 2.4783 - acc: 0.0778 - acc_12: 0.0801Epoch 00001: val_loss improved from inf to 2.10405, saving model to logs/cnn/mel.weights.01-2.104.hdf5\n",
      "1653/1652 [==============================] - 311s 188ms/step - loss: 2.4787 - acc: 0.0778 - acc_12: 0.0800 - val_loss: 2.1041 - val_acc: 0.0782 - val_acc_12: 0.1218\n",
      "Epoch 2/100\n",
      " 369/1652 [=====>........................] - ETA: 3:04 - loss: 2.3518 - acc: 0.0690 - acc_12: 0.0927"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-1361d61a3bd6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m         p_transform=0),\n\u001b[1;32m     20\u001b[0m     \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mex_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"train\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m )\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     85\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     86\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 87\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/models.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1225\u001b[0m                                         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1226\u001b[0m                                         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1227\u001b[0;31m                                         initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1228\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1229\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     85\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     86\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 87\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   2145\u001b[0m                     outs = self.train_on_batch(x, y,\n\u001b[1;32m   2146\u001b[0m                                                \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2147\u001b[0;31m                                                class_weight=class_weight)\n\u001b[0m\u001b[1;32m   2148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2149\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1837\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1838\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1839\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1840\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1841\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2355\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2356\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2357\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2358\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    893\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 895\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    896\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1122\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1124\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1125\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1126\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1319\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1321\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1322\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1323\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1325\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1327\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1328\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1329\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1304\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1305\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1306\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1307\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1308\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "cnn_model.fit_generator(\n",
    "    generator=ex_generator(\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        state=\"train\",\n",
    "        vol_range=0,\n",
    "        displacement=0,\n",
    "        p_transform=0),\n",
    "    steps_per_epoch=sum(ex_df.state == \"train\") / batch_size,\n",
    "    epochs=100,\n",
    "    verbose=1,\n",
    "    callbacks=callbacks,\n",
    "    validation_data=ex_generator(\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        state=\"train\",\n",
    "        vol_range=0,\n",
    "        displacement=0,\n",
    "        p_transform=0),\n",
    "    validation_steps=sum(ex_df.state == \"train\") / batch_size,\n",
    "    shuffle=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
